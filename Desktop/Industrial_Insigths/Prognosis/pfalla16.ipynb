{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-05 21:02:23,042 - INFO - Conexión a la base de datos configurada correctamente.\n",
      "2025-01-05 21:02:23,350 - INFO - Prueba de conexión exitosa.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuración inicial completada exitosamente.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELDA 1: Configuración Inicial y Documentación\n",
    "=============================================\n",
    "Objetivo:\n",
    "- Configurar el entorno para el módulo de prognosis industrial\n",
    "- Integrar conexión con PostgreSQL para la gestión de datos\n",
    "\n",
    "Descripción:\n",
    "Esta celda configura:\n",
    "1. Conexión a PostgreSQL\n",
    "2. Herramientas de logging y visualización\n",
    "3. Parámetros iniciales del proyecto\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Importaciones necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import logging\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "# Configuración inicial\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "# Configuración de conexión a PostgreSQL\n",
    "DB_CONFIG = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"elico\",  #contraseña correcta\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\",\n",
    "    \"database\": \"prognosis_db\"\n",
    "}\n",
    "DATABASE_URL = f\"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    "\n",
    "def create_db_engine():\n",
    "    \"\"\"Crea y retorna un motor de conexión a PostgreSQL\"\"\"\n",
    "    try:\n",
    "        engine = create_engine(DATABASE_URL)\n",
    "        logging.info(\"Conexión a la base de datos configurada correctamente.\")\n",
    "        return engine\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error al conectar con la base de datos: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Prueba de conexión\n",
    "engine = create_db_engine()\n",
    "if engine:\n",
    "    try:\n",
    "        with engine.connect() as conn:\n",
    "            logging.info(\"Prueba de conexión exitosa.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error al probar la conexión: {str(e)}\")\n",
    "\n",
    "print(\"Configuración inicial completada exitosamente.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PRUEBA DE PREPROCESAMIENTO ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-05 21:02:29,559 - __main__ - INFO - Cargando datos desde el archivo...\n",
      "2025-01-05 21:02:29,559 - INFO - Cargando datos desde el archivo...\n",
      "2025-01-05 21:02:42,189 - __main__ - INFO - Datos cargados: 7141 filas y 57 columnas.\n",
      "2025-01-05 21:02:42,189 - INFO - Datos cargados: 7141 filas y 57 columnas.\n",
      "2025-01-05 21:02:42,195 - __main__ - INFO - Iniciando limpieza de datos...\n",
      "2025-01-05 21:02:42,195 - INFO - Iniciando limpieza de datos...\n",
      "2025-01-05 21:02:42,365 - __main__ - INFO - Limpieza de datos completada.\n",
      "2025-01-05 21:02:42,365 - INFO - Limpieza de datos completada.\n",
      "2025-01-05 21:02:42,482 - __main__ - INFO - Normalización de datos completada.\n",
      "2025-01-05 21:02:42,482 - INFO - Normalización de datos completada.\n",
      "2025-01-05 21:02:42,486 - __main__ - INFO - Validación de datos exitosa.\n",
      "2025-01-05 21:02:42,486 - INFO - Validación de datos exitosa.\n",
      "2025-01-05 21:03:11,223 - __main__ - INFO - Datos insertados exitosamente en la tabla 'normalized_data_table'.\n",
      "2025-01-05 21:03:11,223 - INFO - Datos insertados exitosamente en la tabla 'normalized_data_table'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reporte de calidad de datos:\n",
      "missing_values: {'tension_l1_v': np.int64(0), 'tension_l2_v': np.int64(0), 'tension_l3_v': np.int64(0), 'tension_l1_l2_v': np.int64(0), 'tension_l2_l3_v': np.int64(0), 'tension_l3_l1_v': np.int64(0), 'timestamp': np.int64(0), 'corriente_l1_a': np.int64(0), 'corriente_l2_a': np.int64(0), 'corriente_l3_a': np.int64(0), 'factor_de_potencia_l1': np.int64(0), 'factor_de_potencia_l2': np.int64(0), 'factor_de_potencia_l3': np.int64(0), 'flicker_pst_l1_pst': np.int64(0), 'flicker_pst_l2_pst': np.int64(0), 'flicker_pst_l3_pst': np.int64(0), 'distorsion_armonica_vl1_v_thd': np.int64(0), 'distorsion_armonica_vl2_v_thd': np.int64(0), 'distorsion_armonica_vl3_v_thd': np.int64(0), 'distorsion_armonica_il1_i_thd': np.int64(0), 'distorsion_armonica_il2_i_thd': np.int64(0), 'distorsion_armonica_il3_i_thd': np.int64(0), 'armonicos_il1_armonico_2_il1': np.int64(0), 'armonicos_il1_armonico_3_il1': np.int64(0), 'armonicos_il1_armonico_5_il1': np.int64(0), 'armonicos_il1_armonico_6_il1': np.int64(0), 'armonicos_il1_armonico_7_il1': np.int64(0), 'armonicos_il1_armonico_11_il1': np.int64(0), 'armonicos_il1_armonico_13_il1': np.int64(0), 'armonicos_il2_armonico_2_il2': np.int64(0), 'armonicos_il2_armonico_3_il2': np.int64(0), 'armonicos_il2_armonico_5_il2': np.int64(0), 'armonicos_il2_armonico_7_il2': np.int64(0), 'armonicos_il2_armonico_9_il2': np.int64(0), 'armonicos_il2_armonico_11_il2': np.int64(0), 'armonicos_il2_armonico_13_il2': np.int64(0), 'armonicos_vl1_armonico_2_vl1': np.int64(0), 'armonicos_vl1_armonico_3_vl1': np.int64(0), 'armonicos_vl1_armonico_5_vl1': np.int64(0), 'armonicos_vl1_armonico_7_vl1': np.int64(0), 'armonicos_vl1_armonico_9_vl1': np.int64(0), 'armonicos_vl1_armonico_11_vl1': np.int64(0), 'armonicos_vl1_armonico_13_vl1': np.int64(0), 'armonicos_vl2_armonico_2_vl2': np.int64(0), 'armonicos_vl2_armonico_3_vl2': np.int64(0), 'armonicos_vl2_armonico_5_vl2': np.int64(0), 'armonicos_vl2_armonico_7_vl2': np.int64(0), 'armonicos_vl2_armonico_9_vl2': np.int64(0), 'armonicos_vl2_armonico_11_vl2': np.int64(0), 'armonicos_vl2_armonico_13_vl2': np.int64(0), 'armonicos_vl3_armonico_2_vl3': np.int64(0), 'armonicos_vl3_armonico_3_vl3': np.int64(0), 'armonicos_vl3_armonico_5_vl3': np.int64(0), 'armonicos_vl3_armonico_7_vl3': np.int64(0), 'armonicos_vl3_armonico_9_vl3': np.int64(0), 'armonicos_vl3_armonico_11_vl3': np.int64(0), 'armonicos_vl3_armonico_13_vl3': np.int64(0)}\n",
      "irrelevant_columns: []\n",
      "data_types: {'tension_l1_v': 'float64', 'tension_l2_v': 'float64', 'tension_l3_v': 'float64', 'tension_l1_l2_v': 'float64', 'tension_l2_l3_v': 'float64', 'tension_l3_l1_v': 'float64', 'timestamp': 'datetime64[ns]', 'corriente_l1_a': 'float64', 'corriente_l2_a': 'float64', 'corriente_l3_a': 'float64', 'factor_de_potencia_l1': 'float64', 'factor_de_potencia_l2': 'float64', 'factor_de_potencia_l3': 'float64', 'flicker_pst_l1_pst': 'float64', 'flicker_pst_l2_pst': 'float64', 'flicker_pst_l3_pst': 'float64', 'distorsion_armonica_vl1_v_thd': 'float64', 'distorsion_armonica_vl2_v_thd': 'float64', 'distorsion_armonica_vl3_v_thd': 'float64', 'distorsion_armonica_il1_i_thd': 'float64', 'distorsion_armonica_il2_i_thd': 'float64', 'distorsion_armonica_il3_i_thd': 'float64', 'armonicos_il1_armonico_2_il1': 'float64', 'armonicos_il1_armonico_3_il1': 'float64', 'armonicos_il1_armonico_5_il1': 'float64', 'armonicos_il1_armonico_6_il1': 'float64', 'armonicos_il1_armonico_7_il1': 'float64', 'armonicos_il1_armonico_11_il1': 'float64', 'armonicos_il1_armonico_13_il1': 'float64', 'armonicos_il2_armonico_2_il2': 'float64', 'armonicos_il2_armonico_3_il2': 'float64', 'armonicos_il2_armonico_5_il2': 'float64', 'armonicos_il2_armonico_7_il2': 'float64', 'armonicos_il2_armonico_9_il2': 'float64', 'armonicos_il2_armonico_11_il2': 'float64', 'armonicos_il2_armonico_13_il2': 'float64', 'armonicos_vl1_armonico_2_vl1': 'float64', 'armonicos_vl1_armonico_3_vl1': 'float64', 'armonicos_vl1_armonico_5_vl1': 'float64', 'armonicos_vl1_armonico_7_vl1': 'float64', 'armonicos_vl1_armonico_9_vl1': 'float64', 'armonicos_vl1_armonico_11_vl1': 'float64', 'armonicos_vl1_armonico_13_vl1': 'float64', 'armonicos_vl2_armonico_2_vl2': 'float64', 'armonicos_vl2_armonico_3_vl2': 'float64', 'armonicos_vl2_armonico_5_vl2': 'float64', 'armonicos_vl2_armonico_7_vl2': 'float64', 'armonicos_vl2_armonico_9_vl2': 'float64', 'armonicos_vl2_armonico_11_vl2': 'float64', 'armonicos_vl2_armonico_13_vl2': 'float64', 'armonicos_vl3_armonico_2_vl3': 'float64', 'armonicos_vl3_armonico_3_vl3': 'float64', 'armonicos_vl3_armonico_5_vl3': 'float64', 'armonicos_vl3_armonico_7_vl3': 'float64', 'armonicos_vl3_armonico_9_vl3': 'float64', 'armonicos_vl3_armonico_11_vl3': 'float64', 'armonicos_vl3_armonico_13_vl3': 'float64'}\n",
      "warnings: []\n",
      "variable_mapping: {'tension_l1_v': 'Tensión: L1 (V)', 'tension_l2_v': 'Tensión: L2 (V)', 'tension_l3_v': 'Tensión: L3 (V)', 'tension_l1_l2_v': 'Tensión: L1 - L2 (V)', 'tension_l2_l3_v': 'Tensión: L2 - L3 (V)', 'tension_l3_l1_v': 'Tensión: L3 - L1 (V)', 'timestamp': 'timestamp', 'corriente_l1_a': 'Corriente: L1 (A)', 'corriente_l2_a': 'Corriente: L2 (A)', 'corriente_l3_a': 'Corriente: L3 (A)', 'factor_de_potencia_l1': 'Factor de potencia: L1 +', 'factor_de_potencia_l2': 'Factor de potencia: L2 +', 'factor_de_potencia_l3': 'Factor de potencia: L3 +', 'flicker_pst_l1_pst': 'Flicker (Pst): L1 (Pst)', 'flicker_pst_l2_pst': 'Flicker (Pst): L2 (Pst)', 'flicker_pst_l3_pst': 'Flicker (Pst): L3 (Pst)', 'distorsion_armonica_vl1_v_thd': 'Distorsión armónica: VL1 (%V THD)', 'distorsion_armonica_vl2_v_thd': 'Distorsión armónica: VL2 (%V THD)', 'distorsion_armonica_vl3_v_thd': 'Distorsión armónica: VL3 (%V THD)', 'distorsion_armonica_il1_i_thd': 'Distorsión armónica: IL1 (%I THD)', 'distorsion_armonica_il2_i_thd': 'Distorsión armónica: IL2 (%I THD)', 'distorsion_armonica_il3_i_thd': 'Distorsión armónica: IL3 (%I THD)', 'armonicos_il1_armonico_2_il1': 'Armónicos IL1: Armónico 2 (%IL1)', 'armonicos_il1_armonico_3_il1': 'Armónicos IL1: Armónico 3 (%IL1)', 'armonicos_il1_armonico_5_il1': 'Armónicos IL1: Armónico 5 (%IL1)', 'armonicos_il1_armonico_6_il1': 'Armónicos IL1: Armónico 6 (%IL1)', 'armonicos_il1_armonico_7_il1': 'Armónicos IL1: Armónico 7 (%IL1)', 'armonicos_il1_armonico_11_il1': 'Armónicos IL1: Armónico 11 (%IL1)', 'armonicos_il1_armonico_13_il1': 'Armónicos IL1: Armónico 13 (%IL1)', 'armonicos_il2_armonico_2_il2': 'Armónicos IL2: Armónico 2 (%IL2)', 'armonicos_il2_armonico_3_il2': 'Armónicos IL2: Armónico 3 (%IL2)', 'armonicos_il2_armonico_5_il2': 'Armónicos IL2: Armónico 5 (%IL2)', 'armonicos_il2_armonico_7_il2': 'Armónicos IL2: Armónico 7 (%IL2)', 'armonicos_il2_armonico_9_il2': 'Armónicos IL2: Armónico 9 (%IL2)', 'armonicos_il2_armonico_11_il2': 'Armónicos IL2: Armónico 11 (%IL2)', 'armonicos_il2_armonico_13_il2': 'Armónicos IL2: Armónico 13 (%IL2)', 'armonicos_vl1_armonico_2_vl1': 'Armónicos VL1: Armónico 2 (%VL1)', 'armonicos_vl1_armonico_3_vl1': 'Armónicos VL1: Armónico 3 (%VL1)', 'armonicos_vl1_armonico_5_vl1': 'Armónicos VL1: Armónico 5 (%VL1)', 'armonicos_vl1_armonico_7_vl1': 'Armónicos VL1: Armónico 7 (%VL1)', 'armonicos_vl1_armonico_9_vl1': 'Armónicos VL1: Armónico 9 (%VL1)', 'armonicos_vl1_armonico_11_vl1': 'Armónicos VL1: Armónico 11 (%VL1)', 'armonicos_vl1_armonico_13_vl1': 'Armónicos VL1: Armónico 13 (%VL1)', 'armonicos_vl2_armonico_2_vl2': 'Armónicos VL2: Armónico 2 (%VL2)', 'armonicos_vl2_armonico_3_vl2': 'Armónicos VL2: Armónico 3 (%VL2)', 'armonicos_vl2_armonico_5_vl2': 'Armónicos VL2: Armónico 5 (%VL2)', 'armonicos_vl2_armonico_7_vl2': 'Armónicos VL2: Armónico 7 (%VL2)', 'armonicos_vl2_armonico_9_vl2': 'Armónicos VL2: Armónico 9 (%VL2)', 'armonicos_vl2_armonico_11_vl2': 'Armónicos VL2: Armónico 11 (%VL2)', 'armonicos_vl2_armonico_13_vl2': 'Armónicos VL2: Armónico 13 (%VL2)', 'armonicos_vl3_armonico_2_vl3': 'Armónicos VL3: Armónico 2 (%VL3)', 'armonicos_vl3_armonico_3_vl3': 'Armónicos VL3: Armónico 3 (%VL3)', 'armonicos_vl3_armonico_5_vl3': 'Armónicos VL3: Armónico 5 (%VL3)', 'armonicos_vl3_armonico_7_vl3': 'Armónicos VL3: Armónico 7 (%VL3)', 'armonicos_vl3_armonico_9_vl3': 'Armónicos VL3: Armónico 9 (%VL3)', 'armonicos_vl3_armonico_11_vl3': 'Armónicos VL3: Armónico 11 (%VL3)', 'armonicos_vl3_armonico_13_vl3': 'Armónicos VL3: Armónico 13 (%VL3)'}\n",
      "constant_variables: []\n",
      "\n",
      "Preprocesamiento completado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CELDA 2: Limpieza, Normalización y Preprocesamiento de Datos\n",
    "===========================================================\n",
    "Objetivo:\n",
    "- Realizar la limpieza inicial, normalización y preprocesamiento de datos.\n",
    "- Garantizar que los datos sean utilizables para la creación de la línea base y la predicción de fallas.\n",
    "- Asegurar el manejo correcto de caracteres especiales en variables.\n",
    "\n",
    "Descripción:\n",
    "Esta celda implementa:\n",
    "1. Carga de datos desde archivo o ETL.\n",
    "2. Limpieza estándar (manejo de valores nulos, tipos de datos y columnas irrelevantes).\n",
    "3. Normalización de variables numéricas.\n",
    "4. Validación de la estructura de los datos.\n",
    "5. Preparación para su inserción en la base de datos PostgreSQL.\n",
    "6. Manejo robusto de caracteres especiales en nombres de variables.\n",
    "\n",
    "Características principales:\n",
    "- Soporte para datos provenientes de archivos o ETL.\n",
    "- Modularidad para limpieza estándar reutilizable.\n",
    "- Normalización de variables numéricas.\n",
    "- Validación de integridad y estructura de los datos.\n",
    "- Reporte detallado de los cambios realizados.\n",
    "- Mapeo y trazabilidad de nombres de variables.\n",
    "\"\"\"\n",
    "\n",
    "# Importaciones necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from sqlalchemy import text, create_engine\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from typing import Tuple, Dict, Any\n",
    "import unicodedata\n",
    "from psycopg2 import connect\n",
    "\n",
    "# Configuración de conexión a PostgreSQL\n",
    "DB_CONFIG = {\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"elico\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\",\n",
    "    \"database\": \"prognosis_db\"\n",
    "}\n",
    "\n",
    "class DatabaseSetup:\n",
    "    @staticmethod\n",
    "    def create_database_if_not_exists(config: Dict[str, str]):\n",
    "        \"\"\"Crea la base de datos si no existe.\"\"\"\n",
    "        try:\n",
    "            connection = connect(\n",
    "                dbname=\"postgres\",\n",
    "                user=config[\"user\"],\n",
    "                password=config[\"password\"],\n",
    "                host=config[\"host\"],\n",
    "                port=config[\"port\"]\n",
    "            )\n",
    "            connection.autocommit = True\n",
    "            cursor = connection.cursor()\n",
    "            cursor.execute(f\"SELECT 1 FROM pg_database WHERE datname = '{config['database']}';\")\n",
    "            if not cursor.fetchone():\n",
    "                cursor.execute(f\"CREATE DATABASE {config['database']};\")\n",
    "                logging.info(f\"Base de datos '{config['database']}' creada exitosamente.\")\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error al crear la base de datos: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "class DataPreprocessor:\n",
    "    def __init__(self, db_engine, file_path: str = None):\n",
    "        \"\"\"Inicializa la clase de preprocesamiento de datos.\"\"\"\n",
    "        self.db_engine = db_engine\n",
    "        self.file_path = file_path\n",
    "        self.cleaned_data = None\n",
    "        self.normalized_data = None\n",
    "        self.quality_report = {\n",
    "            'missing_values': {},\n",
    "            'irrelevant_columns': [],\n",
    "            'data_types': {},\n",
    "            'warnings': [],\n",
    "            'variable_mapping': {}\n",
    "        }\n",
    "        self.scaler = StandardScaler()\n",
    "        self._setup_logging()\n",
    "\n",
    "    def _setup_logging(self):\n",
    "        \"\"\"Configura el sistema de logging.\"\"\"\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        if not self.logger.handlers:\n",
    "            handler = logging.StreamHandler()\n",
    "            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "            handler.setFormatter(formatter)\n",
    "            self.logger.addHandler(handler)\n",
    "            self.logger.setLevel(logging.INFO)\n",
    "\n",
    "    def _normalize_column_name(self, column: str) -> str:\n",
    "        \"\"\"Normaliza el nombre de una columna manteniendo trazabilidad.\"\"\"\n",
    "        try:\n",
    "            # Convertir a minúsculas y eliminar acentos\n",
    "            normalized = column.lower()\n",
    "            normalized = unicodedata.normalize('NFKD', normalized)\n",
    "            normalized = u\"\".join([c for c in normalized if not unicodedata.combining(c)])\n",
    "            \n",
    "            # Reemplazar caracteres especiales con guión bajo\n",
    "            normalized = ''.join(c if c.isalnum() else '_' for c in normalized)\n",
    "            normalized = '_'.join(filter(None, normalized.split('_')))\n",
    "            \n",
    "            # Guardar mapeo original\n",
    "            self.quality_report['variable_mapping'][normalized] = column\n",
    "            \n",
    "            return normalized\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error normalizando nombre de columna: {str(e)}\")\n",
    "            return column\n",
    "\n",
    "    def load_data(self) -> pd.DataFrame:\n",
    "        \"\"\"Carga datos desde un archivo Excel o una ETL.\"\"\"\n",
    "        try:\n",
    "            if not self.file_path:\n",
    "                raise ValueError(\"No se proporcionó la ruta del archivo.\")\n",
    "\n",
    "            self.logger.info(\"Cargando datos desde el archivo...\")\n",
    "            data = pd.read_excel(self.file_path)\n",
    "            self.logger.info(f\"Datos cargados: {data.shape[0]} filas y {data.shape[1]} columnas.\")\n",
    "            return data\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error al cargar datos: {str(e)}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def clean_data(self, data: pd.DataFrame) -> Tuple[pd.DataFrame, Dict[str, Any]]:\n",
    "        \"\"\"Limpia los datos eliminando valores nulos, ajustando tipos de datos y reportando cambios.\"\"\"\n",
    "        try:\n",
    "            self.logger.info(\"Iniciando limpieza de datos...\")\n",
    "            \n",
    "            # Normalizar nombres de columnas\n",
    "            data = data.copy()\n",
    "            data.columns = [self._normalize_column_name(col) for col in data.columns]\n",
    "                # NUEVO: Análisis detallado de variables constantes\n",
    "            constant_vars = []\n",
    "            for col in data.columns:\n",
    "                unique_values = data[col].nunique()\n",
    "                if unique_values <= 1:\n",
    "                    constant_vars.append({\n",
    "                        \"variable\": col,\n",
    "                        \"value\": data[col].iloc[0],\n",
    "                        \"unique_count\": unique_values\n",
    "                    })\n",
    "                    \n",
    "            # Actualizar quality_report con información detallada\n",
    "            self.quality_report['constant_variables'] = constant_vars\n",
    "            \n",
    "            # Identificar y eliminar columnas irrelevantes con más detalle\n",
    "            irrelevant_cols = [col['variable'] for col in constant_vars]\n",
    "            if irrelevant_cols:\n",
    "                self.logger.warning(f\"Variables constantes detectadas: {irrelevant_cols}\")\n",
    "                self.quality_report['irrelevant_columns'] = irrelevant_cols\n",
    "                data.drop(columns=irrelevant_cols, inplace=True)\n",
    "                # Guardar tipos de datos originales\n",
    "            self.quality_report['data_types'] = {col: str(data[col].dtype) for col in data.columns}\n",
    "                # Manejo de valores nulos\n",
    "            for col in data.columns:\n",
    "                missing = data[col].isnull().sum()\n",
    "                self.quality_report['missing_values'][col] = missing\n",
    "                if missing > 0:\n",
    "                    if pd.api.types.is_numeric_dtype(data[col]):\n",
    "                        data[col].fillna(data[col].median(), inplace=True)\n",
    "                    else:\n",
    "                        data[col].fillna(\"Desconocido\", inplace=True)\n",
    "                self.cleaned_data = data\n",
    "            self.logger.info(\"Limpieza de datos completada.\")\n",
    "            return data, self.quality_report\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error durante la limpieza de datos: {str(e)}\")\n",
    "            return pd.DataFrame(), self.quality_report\n",
    "\n",
    "    def normalize_data(self):\n",
    "        \"\"\"Normaliza las variables numéricas.\"\"\"\n",
    "        try:\n",
    "            if self.cleaned_data is None or self.cleaned_data.empty:\n",
    "                raise ValueError(\"Los datos no están limpios o están vacíos.\")\n",
    "\n",
    "            numeric_cols = self.cleaned_data.select_dtypes(include=[np.number]).columns\n",
    "            self.normalized_data = self.cleaned_data.copy()\n",
    "            self.normalized_data[numeric_cols] = self.scaler.fit_transform(self.cleaned_data[numeric_cols])\n",
    "\n",
    "            self.logger.info(\"Normalización de datos completada.\")\n",
    "            return self.normalized_data\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error durante la normalización de datos: {str(e)}\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def validate_data(self) -> bool:\n",
    "        \"\"\"Valida que los datos estén listos para la inserción en la base de datos.\"\"\"\n",
    "        try:\n",
    "            if self.normalized_data is None or self.normalized_data.empty:\n",
    "                raise ValueError(\"Los datos no están listos o están vacíos.\")\n",
    "\n",
    "            if 'timestamp' not in self.normalized_data.columns:\n",
    "                raise ValueError(\"Los datos no contienen una columna de 'timestamp'.\")\n",
    "\n",
    "            self.logger.info(\"Validación de datos exitosa.\")\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error durante la validación de datos: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def insert_into_db(self, table_name: str):\n",
    "        \"\"\"Inserta los datos normalizados en la base de datos PostgreSQL.\"\"\"\n",
    "        try:\n",
    "            if not self.validate_data():\n",
    "                raise ValueError(\"Los datos no pasaron la validación.\")\n",
    "\n",
    "            with self.db_engine.connect() as conn:\n",
    "                with conn.begin():\n",
    "                    # Crear tabla de mapeo\n",
    "                    conn.execute(text(\"\"\"\n",
    "                        CREATE TABLE IF NOT EXISTS variable_mapping (\n",
    "                            normalized_name VARCHAR PRIMARY KEY,\n",
    "                            original_name VARCHAR NOT NULL,\n",
    "                            data_type VARCHAR,\n",
    "                            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "                        );\n",
    "                    \"\"\"))\n",
    "                    \n",
    "                    # Insertar mapeo de variables\n",
    "                    for norm_name, orig_name in self.quality_report['variable_mapping'].items():\n",
    "                        conn.execute(text(\"\"\"\n",
    "                            INSERT INTO variable_mapping \n",
    "                            (normalized_name, original_name, data_type)\n",
    "                            VALUES (:norm, :orig, :dtype)\n",
    "                            ON CONFLICT (normalized_name) DO UPDATE \n",
    "                            SET original_name = EXCLUDED.original_name,\n",
    "                                data_type = EXCLUDED.data_type\n",
    "                        \"\"\"), {\n",
    "                            'norm': norm_name,\n",
    "                            'orig': orig_name,\n",
    "                            'dtype': self.quality_report['data_types'].get(norm_name)\n",
    "                        })\n",
    "\n",
    "                    # Crear e insertar datos normalizados\n",
    "                    self.normalized_data.to_sql(\n",
    "                        table_name, \n",
    "                        conn, \n",
    "                        if_exists='replace', \n",
    "                        index=False,\n",
    "                        method='multi'\n",
    "                    )\n",
    "\n",
    "            self.logger.info(f\"Datos insertados exitosamente en la tabla '{table_name}'.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error al insertar datos en la base de datos: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "def test_preprocessing():\n",
    "    \"\"\"Prueba el flujo completo de limpieza, normalización y preprocesamiento.\"\"\"\n",
    "    try:\n",
    "        print(\"\\n=== PRUEBA DE PREPROCESAMIENTO ===\\n\")\n",
    "\n",
    "        # Configuración inicial\n",
    "        file_path = \"filtered_consolidated_data_cleaned.xlsx\"\n",
    "        table_name = \"normalized_data_table\"\n",
    "\n",
    "        # Crear la base de datos si no existe\n",
    "        DatabaseSetup.create_database_if_not_exists(DB_CONFIG)\n",
    "\n",
    "        # Crear el motor de conexión\n",
    "        DATABASE_URL = f\"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    "        engine = create_engine(DATABASE_URL)\n",
    "\n",
    "        # Crear instancia del preprocesador\n",
    "        preprocessor = DataPreprocessor(db_engine=engine, file_path=file_path)\n",
    "\n",
    "        # Ejecutar el flujo completo\n",
    "        raw_data = preprocessor.load_data()\n",
    "        cleaned_data, report = preprocessor.clean_data(raw_data)\n",
    "        normalized_data = preprocessor.normalize_data()\n",
    "        preprocessor.insert_into_db(table_name)\n",
    "\n",
    "        # Mostrar reporte de calidad\n",
    "        print(\"\\nReporte de calidad de datos:\")\n",
    "        for key, value in report.items():\n",
    "            print(f\"{key}: {value}\")\n",
    "\n",
    "        print(\"\\nPreprocesamiento completado exitosamente.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error en la prueba de preprocesamiento: {str(e)}\")\n",
    "\n",
    "# Ejecutar prueba\n",
    "if __name__ == \"__main__\":\n",
    "    test_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-05 21:03:11,361 - __main__ - INFO - Conexión con la base de datos validada correctamente.\n",
      "2025-01-05 21:03:11,361 - INFO - Conexión con la base de datos validada correctamente.\n",
      "2025-01-05 21:03:11,366 - __main__ - INFO - Tablas creadas/verificadas exitosamente.\n",
      "2025-01-05 21:03:11,366 - INFO - Tablas creadas/verificadas exitosamente.\n",
      "2025-01-05 21:03:11,759 - __main__ - INFO - Datos cargados: 7141 filas y 56 columnas.\n",
      "2025-01-05 21:03:11,759 - INFO - Datos cargados: 7141 filas y 56 columnas.\n",
      "2025-01-05 21:03:11,763 - __main__ - INFO - Iniciando análisis de variables...\n",
      "2025-01-05 21:03:11,763 - INFO - Iniciando análisis de variables...\n",
      "2025-01-05 21:03:11,767 - __main__ - INFO - \n",
      "Analizando tension_l1_v:\n",
      "2025-01-05 21:03:11,767 - INFO - \n",
      "Analizando tension_l1_v:\n",
      "2025-01-05 21:03:11,770 - __main__ - INFO - - Valores únicos: 1081\n",
      "2025-01-05 21:03:11,770 - INFO - - Valores únicos: 1081\n",
      "2025-01-05 21:03:11,773 - __main__ - INFO - - Muestra valores: [-0.12807509 -0.00177156  0.01859997  0.01452567  0.04712013]\n",
      "2025-01-05 21:03:11,773 - INFO - - Muestra valores: [-0.12807509 -0.00177156  0.01859997  0.01452567  0.04712013]\n",
      "2025-01-05 21:03:11,776 - __main__ - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:11,776 - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:11,820 - __main__ - INFO - - variance_score: 0.10493877605586985\n",
      "2025-01-05 21:03:11,820 - INFO - - variance_score: 0.10493877605586985\n",
      "2025-01-05 21:03:11,824 - __main__ - INFO - - stability_score: 0.832746354912534\n",
      "2025-01-05 21:03:11,824 - INFO - - stability_score: 0.832746354912534\n",
      "2025-01-05 21:03:11,828 - __main__ - INFO - - trend_score: 0.0001771165335542092\n",
      "2025-01-05 21:03:11,828 - INFO - - trend_score: 0.0001771165335542092\n",
      "2025-01-05 21:03:11,831 - __main__ - INFO - - correlation_score: 0.3793455234753713\n",
      "2025-01-05 21:03:11,831 - INFO - - correlation_score: 0.3793455234753713\n",
      "2025-01-05 21:03:11,835 - __main__ - INFO - - final_score: 0.3572100672923063\n",
      "2025-01-05 21:03:11,835 - INFO - - final_score: 0.3572100672923063\n",
      "2025-01-05 21:03:11,840 - __main__ - INFO - \n",
      "Analizando tension_l2_v:\n",
      "2025-01-05 21:03:11,840 - INFO - \n",
      "Analizando tension_l2_v:\n",
      "2025-01-05 21:03:11,843 - __main__ - INFO - - Valores únicos: 1209\n",
      "2025-01-05 21:03:11,843 - INFO - - Valores únicos: 1209\n",
      "2025-01-05 21:03:11,846 - __main__ - INFO - - Muestra valores: [-0.3452989  -0.24742332 -0.2256732  -0.2437983  -0.17854792]\n",
      "2025-01-05 21:03:11,846 - INFO - - Muestra valores: [-0.3452989  -0.24742332 -0.2256732  -0.2437983  -0.17854792]\n",
      "2025-01-05 21:03:11,848 - __main__ - INFO - - Varianza: 1.0001400560224092\n",
      "2025-01-05 21:03:11,848 - INFO - - Varianza: 1.0001400560224092\n",
      "2025-01-05 21:03:11,880 - __main__ - INFO - - variance_score: 0.1173644590671107\n",
      "2025-01-05 21:03:11,880 - INFO - - variance_score: 0.1173644590671107\n",
      "2025-01-05 21:03:11,883 - __main__ - INFO - - stability_score: 0.8515004860529449\n",
      "2025-01-05 21:03:11,883 - INFO - - stability_score: 0.8515004860529449\n",
      "2025-01-05 21:03:11,886 - __main__ - INFO - - trend_score: 0.00018035800644369194\n",
      "2025-01-05 21:03:11,886 - INFO - - trend_score: 0.00018035800644369194\n",
      "2025-01-05 21:03:11,889 - __main__ - INFO - - correlation_score: 0.3774879390831\n",
      "2025-01-05 21:03:11,889 - INFO - - correlation_score: 0.3774879390831\n",
      "2025-01-05 21:03:11,893 - __main__ - INFO - - final_score: 0.3661931429539254\n",
      "2025-01-05 21:03:11,893 - INFO - - final_score: 0.3661931429539254\n",
      "2025-01-05 21:03:11,898 - __main__ - INFO - \n",
      "Analizando tension_l3_v:\n",
      "2025-01-05 21:03:11,898 - INFO - \n",
      "Analizando tension_l3_v:\n",
      "2025-01-05 21:03:11,901 - __main__ - INFO - - Valores únicos: 1117\n",
      "2025-01-05 21:03:11,901 - INFO - - Valores únicos: 1117\n",
      "2025-01-05 21:03:11,903 - __main__ - INFO - - Muestra valores: [-0.20918497 -0.11063077 -0.0712091  -0.07909343 -0.01207658]\n",
      "2025-01-05 21:03:11,903 - INFO - - Muestra valores: [-0.20918497 -0.11063077 -0.0712091  -0.07909343 -0.01207658]\n",
      "2025-01-05 21:03:11,908 - __main__ - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:11,908 - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:11,936 - __main__ - INFO - - variance_score: 0.10843349940278134\n",
      "2025-01-05 21:03:11,936 - INFO - - variance_score: 0.10843349940278134\n",
      "2025-01-05 21:03:11,939 - __main__ - INFO - - stability_score: 0.8381299367175267\n",
      "2025-01-05 21:03:11,939 - INFO - - stability_score: 0.8381299367175267\n",
      "2025-01-05 21:03:11,943 - __main__ - INFO - - trend_score: 0.00018582926270602765\n",
      "2025-01-05 21:03:11,943 - INFO - - trend_score: 0.00018582926270602765\n",
      "2025-01-05 21:03:11,946 - __main__ - INFO - - correlation_score: 0.3845031329517377\n",
      "2025-01-05 21:03:11,946 - INFO - - correlation_score: 0.3845031329517377\n",
      "2025-01-05 21:03:11,948 - __main__ - INFO - - final_score: 0.36090682327898116\n",
      "2025-01-05 21:03:11,948 - INFO - - final_score: 0.36090682327898116\n",
      "2025-01-05 21:03:11,954 - __main__ - INFO - \n",
      "Analizando tension_l1_l2_v:\n",
      "2025-01-05 21:03:11,954 - INFO - \n",
      "Analizando tension_l1_l2_v:\n",
      "2025-01-05 21:03:11,958 - __main__ - INFO - - Valores únicos: 1845\n",
      "2025-01-05 21:03:11,958 - INFO - - Valores únicos: 1845\n",
      "2025-01-05 21:03:11,961 - __main__ - INFO - - Muestra valores: [-0.27120459 -0.16768446 -0.15474444 -0.16121445 -0.13317774]\n",
      "2025-01-05 21:03:11,961 - INFO - - Muestra valores: [-0.27120459 -0.16768446 -0.15474444 -0.16121445 -0.13317774]\n",
      "2025-01-05 21:03:11,963 - __main__ - INFO - - Varianza: 1.0001400560224092\n",
      "2025-01-05 21:03:11,963 - INFO - - Varianza: 1.0001400560224092\n",
      "2025-01-05 21:03:11,996 - __main__ - INFO - - variance_score: 0.17910457152921358\n",
      "2025-01-05 21:03:11,996 - INFO - - variance_score: 0.17910457152921358\n",
      "2025-01-05 21:03:11,999 - __main__ - INFO - - stability_score: 0.847895922230951\n",
      "2025-01-05 21:03:11,999 - INFO - - stability_score: 0.847895922230951\n",
      "2025-01-05 21:03:12,001 - __main__ - INFO - - trend_score: 0.00018276273567480558\n",
      "2025-01-05 21:03:12,001 - INFO - - trend_score: 0.00018276273567480558\n",
      "2025-01-05 21:03:12,004 - __main__ - INFO - - correlation_score: 0.3792386370130845\n",
      "2025-01-05 21:03:12,004 - INFO - - correlation_score: 0.3792386370130845\n",
      "2025-01-05 21:03:12,010 - __main__ - INFO - - final_score: 0.38398442807780125\n",
      "2025-01-05 21:03:12,010 - INFO - - final_score: 0.38398442807780125\n",
      "2025-01-05 21:03:12,014 - __main__ - INFO - \n",
      "Analizando tension_l2_l3_v:\n",
      "2025-01-05 21:03:12,014 - INFO - \n",
      "Analizando tension_l2_l3_v:\n",
      "2025-01-05 21:03:12,017 - __main__ - INFO - - Valores únicos: 1834\n",
      "2025-01-05 21:03:12,017 - INFO - - Valores únicos: 1834\n",
      "2025-01-05 21:03:12,021 - __main__ - INFO - - Muestra valores: [-0.28752514 -0.19424433 -0.15736587 -0.17038179 -0.17255111]\n",
      "2025-01-05 21:03:12,021 - INFO - - Muestra valores: [-0.28752514 -0.19424433 -0.15736587 -0.17038179 -0.17255111]\n",
      "2025-01-05 21:03:12,027 - __main__ - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:12,027 - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:12,061 - __main__ - INFO - - variance_score: 0.17803673939543505\n",
      "2025-01-05 21:03:12,061 - INFO - - variance_score: 0.17803673939543505\n",
      "2025-01-05 21:03:12,063 - __main__ - INFO - - stability_score: 0.8451333075448301\n",
      "2025-01-05 21:03:12,063 - INFO - - stability_score: 0.8451333075448301\n",
      "2025-01-05 21:03:12,067 - __main__ - INFO - - trend_score: 0.0001865329588892789\n",
      "2025-01-05 21:03:12,067 - INFO - - trend_score: 0.0001865329588892789\n",
      "2025-01-05 21:03:12,069 - __main__ - INFO - - correlation_score: 0.38150274029932685\n",
      "2025-01-05 21:03:12,069 - INFO - - correlation_score: 0.38150274029932685\n",
      "2025-01-05 21:03:12,072 - __main__ - INFO - - final_score: 0.38328886873372275\n",
      "2025-01-05 21:03:12,072 - INFO - - final_score: 0.38328886873372275\n",
      "2025-01-05 21:03:12,078 - __main__ - INFO - \n",
      "Analizando tension_l3_l1_v:\n",
      "2025-01-05 21:03:12,078 - INFO - \n",
      "Analizando tension_l3_l1_v:\n",
      "2025-01-05 21:03:12,081 - __main__ - INFO - - Valores únicos: 1710\n",
      "2025-01-05 21:03:12,081 - INFO - - Valores únicos: 1710\n",
      "2025-01-05 21:03:12,085 - __main__ - INFO - - Muestra valores: [-0.12931982  0.00016958  0.028945    0.04093476  0.0984856 ]\n",
      "2025-01-05 21:03:12,085 - INFO - - Muestra valores: [-0.12931982  0.00016958  0.028945    0.04093476  0.0984856 ]\n",
      "2025-01-05 21:03:12,089 - __main__ - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:12,089 - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:12,117 - __main__ - INFO - - variance_score: 0.1659993589782955\n",
      "2025-01-05 21:03:12,117 - INFO - - variance_score: 0.1659993589782955\n",
      "2025-01-05 21:03:12,120 - __main__ - INFO - - stability_score: 0.8299486625888456\n",
      "2025-01-05 21:03:12,120 - INFO - - stability_score: 0.8299486625888456\n",
      "2025-01-05 21:03:12,123 - __main__ - INFO - - trend_score: 0.00017361767329398633\n",
      "2025-01-05 21:03:12,123 - INFO - - trend_score: 0.00017361767329398633\n",
      "2025-01-05 21:03:12,126 - __main__ - INFO - - correlation_score: 0.3807105982673414\n",
      "2025-01-05 21:03:12,126 - INFO - - correlation_score: 0.3807105982673414\n",
      "2025-01-05 21:03:12,128 - __main__ - INFO - - final_score: 0.3749612496582694\n",
      "2025-01-05 21:03:12,128 - INFO - - final_score: 0.3749612496582694\n",
      "2025-01-05 21:03:12,134 - __main__ - INFO - \n",
      "Analizando corriente_l1_a:\n",
      "2025-01-05 21:03:12,134 - INFO - \n",
      "Analizando corriente_l1_a:\n",
      "2025-01-05 21:03:12,137 - __main__ - INFO - - Valores únicos: 3686\n",
      "2025-01-05 21:03:12,137 - INFO - - Valores únicos: 3686\n",
      "2025-01-05 21:03:12,140 - __main__ - INFO - - Muestra valores: [2.79051869 2.567747   2.525351   2.61823678 2.65408067]\n",
      "2025-01-05 21:03:12,140 - INFO - - Muestra valores: [2.79051869 2.567747   2.525351   2.61823678 2.65408067]\n",
      "2025-01-05 21:03:12,144 - __main__ - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:12,144 - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:12,176 - __main__ - INFO - - variance_score: 0.35782084046432583\n",
      "2025-01-05 21:03:12,176 - INFO - - variance_score: 0.35782084046432583\n",
      "2025-01-05 21:03:12,179 - __main__ - INFO - - stability_score: 0.9325740337402634\n",
      "2025-01-05 21:03:12,179 - INFO - - stability_score: 0.9325740337402634\n",
      "2025-01-05 21:03:12,181 - __main__ - INFO - - trend_score: 0.0001858119311916857\n",
      "2025-01-05 21:03:12,181 - INFO - - trend_score: 0.0001858119311916857\n",
      "2025-01-05 21:03:12,184 - __main__ - INFO - - correlation_score: 0.23115045487341268\n",
      "2025-01-05 21:03:12,184 - INFO - - correlation_score: 0.23115045487341268\n",
      "2025-01-05 21:03:12,186 - __main__ - INFO - - final_score: 0.4333857156222976\n",
      "2025-01-05 21:03:12,186 - INFO - - final_score: 0.4333857156222976\n",
      "2025-01-05 21:03:12,192 - __main__ - INFO - \n",
      "Analizando corriente_l2_a:\n",
      "2025-01-05 21:03:12,192 - INFO - \n",
      "Analizando corriente_l2_a:\n",
      "2025-01-05 21:03:12,194 - __main__ - INFO - - Valores únicos: 4317\n",
      "2025-01-05 21:03:12,194 - INFO - - Valores únicos: 4317\n",
      "2025-01-05 21:03:12,196 - __main__ - INFO - - Muestra valores: [1.19902406 1.0201858  0.99320218 1.07357892 1.08994133]\n",
      "2025-01-05 21:03:12,196 - INFO - - Muestra valores: [1.19902406 1.0201858  0.99320218 1.07357892 1.08994133]\n",
      "2025-01-05 21:03:12,202 - __main__ - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:12,202 - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:12,236 - __main__ - INFO - - variance_score: 0.41907557468380213\n",
      "2025-01-05 21:03:12,236 - INFO - - variance_score: 0.41907557468380213\n",
      "2025-01-05 21:03:12,239 - __main__ - INFO - - stability_score: 0.9060061187523033\n",
      "2025-01-05 21:03:12,239 - INFO - - stability_score: 0.9060061187523033\n",
      "2025-01-05 21:03:12,242 - __main__ - INFO - - trend_score: 0.00010935935952180421\n",
      "2025-01-05 21:03:12,242 - INFO - - trend_score: 0.00010935935952180421\n",
      "2025-01-05 21:03:12,245 - __main__ - INFO - - correlation_score: 0.37479672473671327\n",
      "2025-01-05 21:03:12,245 - INFO - - correlation_score: 0.37479672473671327\n",
      "2025-01-05 21:03:12,247 - __main__ - INFO - - final_score: 0.4725057248500786\n",
      "2025-01-05 21:03:12,247 - INFO - - final_score: 0.4725057248500786\n",
      "2025-01-05 21:03:12,252 - __main__ - INFO - \n",
      "Analizando corriente_l3_a:\n",
      "2025-01-05 21:03:12,252 - INFO - \n",
      "Analizando corriente_l3_a:\n",
      "2025-01-05 21:03:12,255 - __main__ - INFO - - Valores únicos: 4595\n",
      "2025-01-05 21:03:12,255 - INFO - - Valores únicos: 4595\n",
      "2025-01-05 21:03:12,260 - __main__ - INFO - - Muestra valores: [1.29754111 1.10028682 1.07412657 1.14719485 1.1655371 ]\n",
      "2025-01-05 21:03:12,260 - INFO - - Muestra valores: [1.29754111 1.10028682 1.07412657 1.14719485 1.1655371 ]\n",
      "2025-01-05 21:03:12,262 - __main__ - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:12,262 - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:12,298 - __main__ - INFO - - variance_score: 0.44606260497384076\n",
      "2025-01-05 21:03:12,298 - INFO - - variance_score: 0.44606260497384076\n",
      "2025-01-05 21:03:12,301 - __main__ - INFO - - stability_score: 0.8983448369662759\n",
      "2025-01-05 21:03:12,301 - INFO - - stability_score: 0.8983448369662759\n",
      "2025-01-05 21:03:12,304 - __main__ - INFO - - trend_score: 0.000112222403865451\n",
      "2025-01-05 21:03:12,304 - INFO - - trend_score: 0.000112222403865451\n",
      "2025-01-05 21:03:12,307 - __main__ - INFO - - correlation_score: 0.36801696472343054\n",
      "2025-01-05 21:03:12,307 - INFO - - correlation_score: 0.36801696472343054\n",
      "2025-01-05 21:03:12,310 - __main__ - INFO - - final_score: 0.47694807000749423\n",
      "2025-01-05 21:03:12,310 - INFO - - final_score: 0.47694807000749423\n",
      "2025-01-05 21:03:12,315 - __main__ - INFO - \n",
      "Analizando factor_de_potencia_l1:\n",
      "2025-01-05 21:03:12,315 - INFO - \n",
      "Analizando factor_de_potencia_l1:\n",
      "2025-01-05 21:03:12,318 - __main__ - INFO - - Valores únicos: 232\n",
      "2025-01-05 21:03:12,318 - INFO - - Valores únicos: 232\n",
      "2025-01-05 21:03:12,322 - __main__ - INFO - - Muestra valores: [ 0.1025862  -0.27015874 -0.3322829  -0.16661848 -0.14591043]\n",
      "2025-01-05 21:03:12,322 - INFO - - Muestra valores: [ 0.1025862  -0.27015874 -0.3322829  -0.16661848 -0.14591043]\n",
      "2025-01-05 21:03:12,325 - __main__ - INFO - - Varianza: 1.0001400560224092\n",
      "2025-01-05 21:03:12,325 - INFO - - Varianza: 1.0001400560224092\n",
      "2025-01-05 21:03:12,359 - __main__ - INFO - - variance_score: 0.02252155045787401\n",
      "2025-01-05 21:03:12,359 - INFO - - variance_score: 0.02252155045787401\n",
      "2025-01-05 21:03:12,361 - __main__ - INFO - - stability_score: 0.850566019634562\n",
      "2025-01-05 21:03:12,361 - INFO - - stability_score: 0.850566019634562\n",
      "2025-01-05 21:03:12,364 - __main__ - INFO - - trend_score: 0.00014048395710334618\n",
      "2025-01-05 21:03:12,364 - INFO - - trend_score: 0.00014048395710334618\n",
      "2025-01-05 21:03:12,368 - __main__ - INFO - - correlation_score: 0.24429595115874944\n",
      "2025-01-05 21:03:12,368 - INFO - - correlation_score: 0.24429595115874944\n",
      "2025-01-05 21:03:12,371 - __main__ - INFO - - final_score: 0.3108135580509014\n",
      "2025-01-05 21:03:12,371 - INFO - - final_score: 0.3108135580509014\n",
      "2025-01-05 21:03:12,374 - __main__ - INFO - \n",
      "Analizando factor_de_potencia_l2:\n",
      "2025-01-05 21:03:12,374 - INFO - \n",
      "Analizando factor_de_potencia_l2:\n",
      "2025-01-05 21:03:12,377 - __main__ - INFO - - Valores únicos: 194\n",
      "2025-01-05 21:03:12,377 - INFO - - Valores únicos: 194\n",
      "2025-01-05 21:03:12,384 - __main__ - INFO - - Muestra valores: [-0.80798194 -1.21484853 -1.31058184 -1.09518188 -1.0233819 ]\n",
      "2025-01-05 21:03:12,384 - INFO - - Muestra valores: [-0.80798194 -1.21484853 -1.31058184 -1.09518188 -1.0233819 ]\n",
      "2025-01-05 21:03:12,386 - __main__ - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:12,386 - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:12,416 - __main__ - INFO - - variance_score: 0.018832675813911886\n",
      "2025-01-05 21:03:12,416 - INFO - - variance_score: 0.018832675813911886\n",
      "2025-01-05 21:03:12,418 - __main__ - INFO - - stability_score: 0.8774616229750836\n",
      "2025-01-05 21:03:12,418 - INFO - - stability_score: 0.8774616229750836\n",
      "2025-01-05 21:03:12,422 - __main__ - INFO - - trend_score: 5.957019051852859e-06\n",
      "2025-01-05 21:03:12,422 - INFO - - trend_score: 5.957019051852859e-06\n",
      "2025-01-05 21:03:12,427 - __main__ - INFO - - correlation_score: 0.18753651193729404\n",
      "2025-01-05 21:03:12,427 - INFO - - correlation_score: 0.18753651193729404\n",
      "2025-01-05 21:03:12,430 - __main__ - INFO - - final_score: 0.30639678342796783\n",
      "2025-01-05 21:03:12,430 - INFO - - final_score: 0.30639678342796783\n",
      "2025-01-05 21:03:12,436 - __main__ - INFO - \n",
      "Analizando factor_de_potencia_l3:\n",
      "2025-01-05 21:03:12,436 - INFO - \n",
      "Analizando factor_de_potencia_l3:\n",
      "2025-01-05 21:03:12,440 - __main__ - INFO - - Valores únicos: 192\n",
      "2025-01-05 21:03:12,440 - INFO - - Valores únicos: 192\n",
      "2025-01-05 21:03:12,445 - __main__ - INFO - - Muestra valores: [-0.76694628 -1.16785339 -1.25376206 -0.99603606 -0.96739984]\n",
      "2025-01-05 21:03:12,445 - INFO - - Muestra valores: [-0.76694628 -1.16785339 -1.25376206 -0.99603606 -0.96739984]\n",
      "2025-01-05 21:03:12,448 - __main__ - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:12,448 - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:12,488 - __main__ - INFO - - variance_score: 0.018638524516861245\n",
      "2025-01-05 21:03:12,488 - INFO - - variance_score: 0.018638524516861245\n",
      "2025-01-05 21:03:12,491 - __main__ - INFO - - stability_score: 0.8408698062456194\n",
      "2025-01-05 21:03:12,491 - INFO - - stability_score: 0.8408698062456194\n",
      "2025-01-05 21:03:12,494 - __main__ - INFO - - trend_score: 2.1660327100115693e-05\n",
      "2025-01-05 21:03:12,494 - INFO - - trend_score: 2.1660327100115693e-05\n",
      "2025-01-05 21:03:12,499 - __main__ - INFO - - correlation_score: 0.1968250307876406\n",
      "2025-01-05 21:03:12,499 - INFO - - correlation_score: 0.1968250307876406\n",
      "2025-01-05 21:03:12,504 - __main__ - INFO - - final_score: 0.29722183745169234\n",
      "2025-01-05 21:03:12,504 - INFO - - final_score: 0.29722183745169234\n",
      "2025-01-05 21:03:12,509 - __main__ - INFO - \n",
      "Analizando flicker_pst_l1_pst:\n",
      "2025-01-05 21:03:12,509 - INFO - \n",
      "Analizando flicker_pst_l1_pst:\n",
      "2025-01-05 21:03:12,514 - __main__ - INFO - - Valores únicos: 10\n",
      "2025-01-05 21:03:12,514 - INFO - - Valores únicos: 10\n",
      "2025-01-05 21:03:12,519 - __main__ - INFO - - Muestra valores: [ 0.24157218  1.361791   -0.87864663  2.34198247  5.91267995]\n",
      "2025-01-05 21:03:12,519 - INFO - - Muestra valores: [ 0.24157218  1.361791   -0.87864663  2.34198247  5.91267995]\n",
      "2025-01-05 21:03:12,525 - __main__ - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:12,525 - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:12,559 - __main__ - INFO - - variance_score: 0.00097075648525319\n",
      "2025-01-05 21:03:12,559 - INFO - - variance_score: 0.00097075648525319\n",
      "2025-01-05 21:03:12,564 - __main__ - INFO - - stability_score: 0.22762805321222968\n",
      "2025-01-05 21:03:12,564 - INFO - - stability_score: 0.22762805321222968\n",
      "2025-01-05 21:03:12,567 - __main__ - INFO - - trend_score: 3.0076700359830343e-05\n",
      "2025-01-05 21:03:12,567 - INFO - - trend_score: 3.0076700359830343e-05\n",
      "2025-01-05 21:03:12,569 - __main__ - INFO - - correlation_score: 0.1402171607002387\n",
      "2025-01-05 21:03:12,569 - INFO - - correlation_score: 0.1402171607002387\n",
      "2025-01-05 21:03:12,572 - __main__ - INFO - - final_score: 0.09662909038936457\n",
      "2025-01-05 21:03:12,572 - INFO - - final_score: 0.09662909038936457\n",
      "2025-01-05 21:03:12,580 - __main__ - INFO - \n",
      "Analizando flicker_pst_l2_pst:\n",
      "2025-01-05 21:03:12,580 - INFO - \n",
      "Analizando flicker_pst_l2_pst:\n",
      "2025-01-05 21:03:12,583 - __main__ - INFO - - Valores únicos: 9\n",
      "2025-01-05 21:03:12,583 - INFO - - Valores únicos: 9\n",
      "2025-01-05 21:03:12,589 - __main__ - INFO - - Muestra valores: [ 1.09683218e+00 -1.08033044e+00  8.25087011e-03  2.04934083e+00\n",
      "  1.26630086e+01]\n",
      "2025-01-05 21:03:12,589 - INFO - - Muestra valores: [ 1.09683218e+00 -1.08033044e+00  8.25087011e-03  2.04934083e+00\n",
      "  1.26630086e+01]\n",
      "2025-01-05 21:03:12,593 - __main__ - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:12,593 - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:12,635 - __main__ - INFO - - variance_score: 0.000873680836727871\n",
      "2025-01-05 21:03:12,635 - INFO - - variance_score: 0.000873680836727871\n",
      "2025-01-05 21:03:12,638 - __main__ - INFO - - stability_score: 0.1846074221603049\n",
      "2025-01-05 21:03:12,638 - INFO - - stability_score: 0.1846074221603049\n",
      "2025-01-05 21:03:12,640 - __main__ - INFO - - trend_score: 8.010048424582674e-05\n",
      "2025-01-05 21:03:12,640 - INFO - - trend_score: 8.010048424582674e-05\n",
      "2025-01-05 21:03:12,644 - __main__ - INFO - - correlation_score: 0.12111001661049935\n",
      "2025-01-05 21:03:12,644 - INFO - - correlation_score: 0.12111001661049935\n",
      "2025-01-05 21:03:12,646 - __main__ - INFO - - final_score: 0.07988235431805886\n",
      "2025-01-05 21:03:12,646 - INFO - - final_score: 0.07988235431805886\n",
      "2025-01-05 21:03:12,652 - __main__ - INFO - \n",
      "Analizando flicker_pst_l3_pst:\n",
      "2025-01-05 21:03:12,652 - INFO - \n",
      "Analizando flicker_pst_l3_pst:\n",
      "2025-01-05 21:03:12,654 - __main__ - INFO - - Valores únicos: 10\n",
      "2025-01-05 21:03:12,654 - INFO - - Valores únicos: 10\n",
      "2025-01-05 21:03:12,657 - __main__ - INFO - - Muestra valores: [-0.91008471  0.2001648   1.31041431  2.28188263 11.23326929]\n",
      "2025-01-05 21:03:12,657 - INFO - - Muestra valores: [-0.91008471  0.2001648   1.31041431  2.28188263 11.23326929]\n",
      "2025-01-05 21:03:12,662 - __main__ - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:12,662 - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:12,691 - __main__ - INFO - - variance_score: 0.00097075648525319\n",
      "2025-01-05 21:03:12,691 - INFO - - variance_score: 0.00097075648525319\n",
      "2025-01-05 21:03:12,694 - __main__ - INFO - - stability_score: 0.18802430069833231\n",
      "2025-01-05 21:03:12,694 - INFO - - stability_score: 0.18802430069833231\n",
      "2025-01-05 21:03:12,695 - __main__ - INFO - - trend_score: 5.1886571169677206e-05\n",
      "2025-01-05 21:03:12,695 - INFO - - trend_score: 5.1886571169677206e-05\n",
      "2025-01-05 21:03:12,698 - __main__ - INFO - - correlation_score: 0.13738505140104637\n",
      "2025-01-05 21:03:12,698 - INFO - - correlation_score: 0.13738505140104637\n",
      "2025-01-05 21:03:12,702 - __main__ - INFO - - final_score: 0.08418590474951887\n",
      "2025-01-05 21:03:12,702 - INFO - - final_score: 0.08418590474951887\n",
      "2025-01-05 21:03:12,705 - __main__ - INFO - \n",
      "Analizando distorsion_armonica_vl1_v_thd:\n",
      "2025-01-05 21:03:12,705 - INFO - \n",
      "Analizando distorsion_armonica_vl1_v_thd:\n",
      "2025-01-05 21:03:12,710 - __main__ - INFO - - Valores únicos: 16\n",
      "2025-01-05 21:03:12,710 - INFO - - Valores únicos: 16\n",
      "2025-01-05 21:03:12,713 - __main__ - INFO - - Muestra valores: [ 0.19015887  0.50720872  0.82425857 -0.12689098 -0.44394083]\n",
      "2025-01-05 21:03:12,713 - INFO - - Muestra valores: [ 0.19015887  0.50720872  0.82425857 -0.12689098 -0.44394083]\n",
      "2025-01-05 21:03:12,716 - __main__ - INFO - - Varianza: 1.0001400560224092\n",
      "2025-01-05 21:03:12,716 - INFO - - Varianza: 1.0001400560224092\n",
      "2025-01-05 21:03:12,749 - __main__ - INFO - - variance_score: 0.0015532103764051045\n",
      "2025-01-05 21:03:12,749 - INFO - - variance_score: 0.0015532103764051045\n",
      "2025-01-05 21:03:12,752 - __main__ - INFO - - stability_score: 0.8535374241310614\n",
      "2025-01-05 21:03:12,752 - INFO - - stability_score: 0.8535374241310614\n",
      "2025-01-05 21:03:12,755 - __main__ - INFO - - trend_score: 0.00015401783965802662\n",
      "2025-01-05 21:03:12,755 - INFO - - trend_score: 0.00015401783965802662\n",
      "2025-01-05 21:03:12,758 - __main__ - INFO - - correlation_score: 0.30714138490936366\n",
      "2025-01-05 21:03:12,758 - INFO - - correlation_score: 0.30714138490936366\n",
      "2025-01-05 21:03:12,761 - __main__ - INFO - - final_score: 0.3179862709020443\n",
      "2025-01-05 21:03:12,761 - INFO - - final_score: 0.3179862709020443\n",
      "2025-01-05 21:03:12,764 - __main__ - INFO - \n",
      "Analizando distorsion_armonica_vl2_v_thd:\n",
      "2025-01-05 21:03:12,764 - INFO - \n",
      "Analizando distorsion_armonica_vl2_v_thd:\n",
      "2025-01-05 21:03:12,768 - __main__ - INFO - - Valores únicos: 18\n",
      "2025-01-05 21:03:12,768 - INFO - - Valores únicos: 18\n",
      "2025-01-05 21:03:12,772 - __main__ - INFO - - Muestra valores: [-0.00639582  0.25760733  0.52161048 -0.27039897 -0.53440211]\n",
      "2025-01-05 21:03:12,772 - INFO - - Muestra valores: [-0.00639582  0.25760733  0.52161048 -0.27039897 -0.53440211]\n",
      "2025-01-05 21:03:12,774 - __main__ - INFO - - Varianza: 1.0001400560224092\n",
      "2025-01-05 21:03:12,774 - INFO - - Varianza: 1.0001400560224092\n",
      "2025-01-05 21:03:12,811 - __main__ - INFO - - variance_score: 0.0017473616734557426\n",
      "2025-01-05 21:03:12,811 - INFO - - variance_score: 0.0017473616734557426\n",
      "2025-01-05 21:03:12,814 - __main__ - INFO - - stability_score: 0.8585342398626443\n",
      "2025-01-05 21:03:12,814 - INFO - - stability_score: 0.8585342398626443\n",
      "2025-01-05 21:03:12,816 - __main__ - INFO - - trend_score: 0.00016922976010479935\n",
      "2025-01-05 21:03:12,816 - INFO - - trend_score: 0.00016922976010479935\n",
      "2025-01-05 21:03:12,819 - __main__ - INFO - - correlation_score: 0.3226298578263756\n",
      "2025-01-05 21:03:12,819 - INFO - - correlation_score: 0.3226298578263756\n",
      "2025-01-05 21:03:12,821 - __main__ - INFO - - final_score: 0.32264429797812605\n",
      "2025-01-05 21:03:12,821 - INFO - - final_score: 0.32264429797812605\n",
      "2025-01-05 21:03:12,828 - __main__ - INFO - \n",
      "Analizando distorsion_armonica_vl3_v_thd:\n",
      "2025-01-05 21:03:12,828 - INFO - \n",
      "Analizando distorsion_armonica_vl3_v_thd:\n",
      "2025-01-05 21:03:12,832 - __main__ - INFO - - Valores únicos: 15\n",
      "2025-01-05 21:03:12,832 - INFO - - Valores únicos: 15\n",
      "2025-01-05 21:03:12,834 - __main__ - INFO - - Muestra valores: [ 0.10924134  0.44275668  0.77627202 -0.22427401 -0.55778935]\n",
      "2025-01-05 21:03:12,834 - INFO - - Muestra valores: [ 0.10924134  0.44275668  0.77627202 -0.22427401 -0.55778935]\n",
      "2025-01-05 21:03:12,837 - __main__ - INFO - - Varianza: 1.0001400560224092\n",
      "2025-01-05 21:03:12,837 - INFO - - Varianza: 1.0001400560224092\n",
      "2025-01-05 21:03:12,873 - __main__ - INFO - - variance_score: 0.0014561347278797853\n",
      "2025-01-05 21:03:12,873 - INFO - - variance_score: 0.0014561347278797853\n",
      "2025-01-05 21:03:12,876 - __main__ - INFO - - stability_score: 0.8483844102076719\n",
      "2025-01-05 21:03:12,876 - INFO - - stability_score: 0.8483844102076719\n",
      "2025-01-05 21:03:12,882 - __main__ - INFO - - trend_score: 0.00017428485553388535\n",
      "2025-01-05 21:03:12,882 - INFO - - trend_score: 0.00017428485553388535\n",
      "2025-01-05 21:03:12,885 - __main__ - INFO - - correlation_score: 0.316144140037231\n",
      "2025-01-05 21:03:12,885 - INFO - - correlation_score: 0.316144140037231\n",
      "2025-01-05 21:03:12,888 - __main__ - INFO - - final_score: 0.3182158484592185\n",
      "2025-01-05 21:03:12,888 - INFO - - final_score: 0.3182158484592185\n",
      "2025-01-05 21:03:12,892 - __main__ - INFO - \n",
      "Analizando distorsion_armonica_il1_i_thd:\n",
      "2025-01-05 21:03:12,892 - INFO - \n",
      "Analizando distorsion_armonica_il1_i_thd:\n",
      "2025-01-05 21:03:12,895 - __main__ - INFO - - Valores únicos: 161\n",
      "2025-01-05 21:03:12,895 - INFO - - Valores únicos: 161\n",
      "2025-01-05 21:03:12,899 - __main__ - INFO - - Muestra valores: [-0.79716417 -0.73470523 -0.60978736 -0.50568912 -0.42241054]\n",
      "2025-01-05 21:03:12,899 - INFO - - Muestra valores: [-0.79716417 -0.73470523 -0.60978736 -0.50568912 -0.42241054]\n",
      "2025-01-05 21:03:12,902 - __main__ - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:12,902 - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:12,939 - __main__ - INFO - - variance_score: 0.01562917941257636\n",
      "2025-01-05 21:03:12,939 - INFO - - variance_score: 0.01562917941257636\n",
      "2025-01-05 21:03:12,943 - __main__ - INFO - - stability_score: 0.9327403135632828\n",
      "2025-01-05 21:03:12,943 - INFO - - stability_score: 0.9327403135632828\n",
      "2025-01-05 21:03:12,945 - __main__ - INFO - - trend_score: 0.00030229287857084\n",
      "2025-01-05 21:03:12,945 - INFO - - trend_score: 0.00030229287857084\n",
      "2025-01-05 21:03:12,949 - __main__ - INFO - - correlation_score: 0.38030825995358414\n",
      "2025-01-05 21:03:12,949 - INFO - - correlation_score: 0.38030825995358414\n",
      "2025-01-05 21:03:12,951 - __main__ - INFO - - final_score: 0.3606329584591888\n",
      "2025-01-05 21:03:12,951 - INFO - - final_score: 0.3606329584591888\n",
      "2025-01-05 21:03:12,956 - __main__ - INFO - \n",
      "Analizando distorsion_armonica_il2_i_thd:\n",
      "2025-01-05 21:03:12,956 - INFO - \n",
      "Analizando distorsion_armonica_il2_i_thd:\n",
      "2025-01-05 21:03:12,961 - __main__ - INFO - - Valores únicos: 135\n",
      "2025-01-05 21:03:12,961 - INFO - - Valores únicos: 135\n",
      "2025-01-05 21:03:12,964 - __main__ - INFO - - Muestra valores: [-0.38387552 -0.2352678  -0.01235623  0.13625149  0.32201113]\n",
      "2025-01-05 21:03:12,964 - INFO - - Muestra valores: [-0.38387552 -0.2352678  -0.01235623  0.13625149  0.32201113]\n",
      "2025-01-05 21:03:12,966 - __main__ - INFO - - Varianza: 1.0001400560224092\n",
      "2025-01-05 21:03:12,966 - INFO - - Varianza: 1.0001400560224092\n",
      "2025-01-05 21:03:13,002 - __main__ - INFO - - variance_score: 0.013105212550918068\n",
      "2025-01-05 21:03:13,002 - INFO - - variance_score: 0.013105212550918068\n",
      "2025-01-05 21:03:13,005 - __main__ - INFO - - stability_score: 0.8619937515232636\n",
      "2025-01-05 21:03:13,005 - INFO - - stability_score: 0.8619937515232636\n",
      "2025-01-05 21:03:13,007 - __main__ - INFO - - trend_score: 0.00016059285019371728\n",
      "2025-01-05 21:03:13,007 - INFO - - trend_score: 0.00016059285019371728\n",
      "2025-01-05 21:03:13,010 - __main__ - INFO - - correlation_score: 0.34412393955166715\n",
      "2025-01-05 21:03:13,010 - INFO - - correlation_score: 0.34412393955166715\n",
      "2025-01-05 21:03:13,013 - __main__ - INFO - - final_score: 0.3313865957026267\n",
      "2025-01-05 21:03:13,013 - INFO - - final_score: 0.3313865957026267\n",
      "2025-01-05 21:03:13,017 - __main__ - INFO - \n",
      "Analizando distorsion_armonica_il3_i_thd:\n",
      "2025-01-05 21:03:13,017 - INFO - \n",
      "Analizando distorsion_armonica_il3_i_thd:\n",
      "2025-01-05 21:03:13,020 - __main__ - INFO - - Valores únicos: 142\n",
      "2025-01-05 21:03:13,020 - INFO - - Valores únicos: 142\n",
      "2025-01-05 21:03:13,022 - __main__ - INFO - - Muestra valores: [-0.58454021 -0.50532809 -0.46572203 -0.22808566 -0.10926747]\n",
      "2025-01-05 21:03:13,022 - INFO - - Muestra valores: [-0.58454021 -0.50532809 -0.46572203 -0.22808566 -0.10926747]\n",
      "2025-01-05 21:03:13,024 - __main__ - INFO - - Varianza: 1.0001400560224092\n",
      "2025-01-05 21:03:13,024 - INFO - - Varianza: 1.0001400560224092\n",
      "2025-01-05 21:03:13,052 - __main__ - INFO - - variance_score: 0.013784742090595301\n",
      "2025-01-05 21:03:13,052 - INFO - - variance_score: 0.013784742090595301\n",
      "2025-01-05 21:03:13,056 - __main__ - INFO - - stability_score: 0.8526466131327722\n",
      "2025-01-05 21:03:13,056 - INFO - - stability_score: 0.8526466131327722\n",
      "2025-01-05 21:03:13,062 - __main__ - INFO - - trend_score: 0.0001381843511743243\n",
      "2025-01-05 21:03:13,062 - INFO - - trend_score: 0.0001381843511743243\n",
      "2025-01-05 21:03:13,085 - __main__ - INFO - - correlation_score: 0.304121854417527\n",
      "2025-01-05 21:03:13,085 - INFO - - correlation_score: 0.304121854417527\n",
      "2025-01-05 21:03:13,160 - __main__ - INFO - - final_score: 0.3207814143207505\n",
      "2025-01-05 21:03:13,160 - INFO - - final_score: 0.3207814143207505\n",
      "2025-01-05 21:03:13,221 - __main__ - INFO - \n",
      "Analizando armonicos_il1_armonico_2_il1:\n",
      "2025-01-05 21:03:13,221 - INFO - \n",
      "Analizando armonicos_il1_armonico_2_il1:\n",
      "2025-01-05 21:03:13,223 - __main__ - INFO - - Valores únicos: 65\n",
      "2025-01-05 21:03:13,223 - INFO - - Valores únicos: 65\n",
      "2025-01-05 21:03:13,231 - __main__ - INFO - - Muestra valores: [-1.23878011 -0.93519148 -0.14119047  1.0031051   0.97975213]\n",
      "2025-01-05 21:03:13,231 - INFO - - Muestra valores: [-1.23878011 -0.93519148 -0.14119047  1.0031051   0.97975213]\n",
      "2025-01-05 21:03:13,251 - __main__ - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:13,251 - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:13,397 - __main__ - INFO - - variance_score: 0.006309917154145734\n",
      "2025-01-05 21:03:13,397 - INFO - - variance_score: 0.006309917154145734\n",
      "2025-01-05 21:03:13,402 - __main__ - INFO - - stability_score: 0.9626489866475653\n",
      "2025-01-05 21:03:13,402 - INFO - - stability_score: 0.9626489866475653\n",
      "2025-01-05 21:03:13,407 - __main__ - INFO - - trend_score: 0.00035743429153535706\n",
      "2025-01-05 21:03:13,407 - INFO - - trend_score: 0.00035743429153535706\n",
      "2025-01-05 21:03:13,414 - __main__ - INFO - - correlation_score: 0.2955881849870266\n",
      "2025-01-05 21:03:13,414 - INFO - - correlation_score: 0.2955881849870266\n",
      "2025-01-05 21:03:13,417 - __main__ - INFO - - final_score: 0.3498767949962256\n",
      "2025-01-05 21:03:13,417 - INFO - - final_score: 0.3498767949962256\n",
      "2025-01-05 21:03:13,422 - __main__ - INFO - \n",
      "Analizando armonicos_il1_armonico_3_il1:\n",
      "2025-01-05 21:03:13,422 - INFO - \n",
      "Analizando armonicos_il1_armonico_3_il1:\n",
      "2025-01-05 21:03:13,425 - __main__ - INFO - - Valores únicos: 76\n",
      "2025-01-05 21:03:13,425 - INFO - - Valores únicos: 76\n",
      "2025-01-05 21:03:13,428 - __main__ - INFO - - Muestra valores: [-0.97638304 -0.93811694 -0.89985084 -0.86158474 -0.82331864]\n",
      "2025-01-05 21:03:13,428 - INFO - - Muestra valores: [-0.97638304 -0.93811694 -0.89985084 -0.86158474 -0.82331864]\n",
      "2025-01-05 21:03:13,433 - __main__ - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:13,433 - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:13,469 - __main__ - INFO - - variance_score: 0.007377749287924245\n",
      "2025-01-05 21:03:13,469 - INFO - - variance_score: 0.007377749287924245\n",
      "2025-01-05 21:03:13,472 - __main__ - INFO - - stability_score: 0.9110612125244789\n",
      "2025-01-05 21:03:13,472 - INFO - - stability_score: 0.9110612125244789\n",
      "2025-01-05 21:03:13,475 - __main__ - INFO - - trend_score: 0.000358537591604882\n",
      "2025-01-05 21:03:13,475 - INFO - - trend_score: 0.000358537591604882\n",
      "2025-01-05 21:03:13,480 - __main__ - INFO - - correlation_score: 0.35549042587580487\n",
      "2025-01-05 21:03:13,480 - INFO - - correlation_score: 0.35549042587580487\n",
      "2025-01-05 21:03:13,482 - __main__ - INFO - - final_score: 0.34670148123720285\n",
      "2025-01-05 21:03:13,482 - INFO - - final_score: 0.34670148123720285\n",
      "2025-01-05 21:03:13,487 - __main__ - INFO - \n",
      "Analizando armonicos_il1_armonico_5_il1:\n",
      "2025-01-05 21:03:13,487 - INFO - \n",
      "Analizando armonicos_il1_armonico_5_il1:\n",
      "2025-01-05 21:03:13,490 - __main__ - INFO - - Valores únicos: 132\n",
      "2025-01-05 21:03:13,490 - INFO - - Valores únicos: 132\n",
      "2025-01-05 21:03:13,496 - __main__ - INFO - - Muestra valores: [-0.31097452 -0.18651325 -0.21762857 -0.03093667  0.0935246 ]\n",
      "2025-01-05 21:03:13,496 - INFO - - Muestra valores: [-0.31097452 -0.18651325 -0.21762857 -0.03093667  0.0935246 ]\n",
      "2025-01-05 21:03:13,499 - __main__ - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:13,499 - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:13,527 - __main__ - INFO - - variance_score: 0.012813985605342108\n",
      "2025-01-05 21:03:13,527 - INFO - - variance_score: 0.012813985605342108\n",
      "2025-01-05 21:03:13,530 - __main__ - INFO - - stability_score: 0.8874706124977706\n",
      "2025-01-05 21:03:13,530 - INFO - - stability_score: 0.8874706124977706\n",
      "2025-01-05 21:03:13,533 - __main__ - INFO - - trend_score: 0.00018617079002799673\n",
      "2025-01-05 21:03:13,533 - INFO - - trend_score: 0.00018617079002799673\n",
      "2025-01-05 21:03:13,535 - __main__ - INFO - - correlation_score: 0.3725664353185352\n",
      "2025-01-05 21:03:13,535 - INFO - - correlation_score: 0.3725664353185352\n",
      "2025-01-05 21:03:13,538 - __main__ - INFO - - final_score: 0.3446359006526465\n",
      "2025-01-05 21:03:13,538 - INFO - - final_score: 0.3446359006526465\n",
      "2025-01-05 21:03:13,542 - __main__ - INFO - \n",
      "Analizando armonicos_il1_armonico_6_il1:\n",
      "2025-01-05 21:03:13,542 - INFO - \n",
      "Analizando armonicos_il1_armonico_6_il1:\n",
      "2025-01-05 21:03:13,546 - __main__ - INFO - - Valores únicos: 11\n",
      "2025-01-05 21:03:13,546 - INFO - - Valores únicos: 11\n",
      "2025-01-05 21:03:13,552 - __main__ - INFO - - Muestra valores: [-0.17430966  5.54044632  6.25479082  6.96913532  6.61196307]\n",
      "2025-01-05 21:03:13,552 - INFO - - Muestra valores: [-0.17430966  5.54044632  6.25479082  6.96913532  6.61196307]\n",
      "2025-01-05 21:03:13,558 - __main__ - INFO - - Varianza: 1.0001400560224094\n",
      "2025-01-05 21:03:13,558 - INFO - - Varianza: 1.0001400560224094\n",
      "2025-01-05 21:03:13,588 - __main__ - INFO - - variance_score: 0.0010678321337785094\n",
      "2025-01-05 21:03:13,588 - INFO - - variance_score: 0.0010678321337785094\n",
      "2025-01-05 21:03:13,593 - __main__ - INFO - - stability_score: 0.8324985931411106\n",
      "2025-01-05 21:03:13,593 - INFO - - stability_score: 0.8324985931411106\n",
      "2025-01-05 21:03:13,598 - __main__ - INFO - - trend_score: 1.0037062935936662e-05\n",
      "2025-01-05 21:03:13,598 - INFO - - trend_score: 1.0037062935936662e-05\n",
      "2025-01-05 21:03:13,601 - __main__ - INFO - - correlation_score: 0.09497451678574127\n",
      "2025-01-05 21:03:13,601 - INFO - - correlation_score: 0.09497451678574127\n",
      "2025-01-05 21:03:13,603 - __main__ - INFO - - final_score: 0.2690668383522022\n",
      "2025-01-05 21:03:13,603 - INFO - - final_score: 0.2690668383522022\n",
      "2025-01-05 21:03:13,607 - __main__ - INFO - \n",
      "Analizando armonicos_il1_armonico_7_il1:\n",
      "2025-01-05 21:03:13,607 - INFO - \n",
      "Analizando armonicos_il1_armonico_7_il1:\n",
      "2025-01-05 21:03:13,705 - __main__ - INFO - - Valores únicos: 48\n",
      "2025-01-05 21:03:13,705 - INFO - - Valores únicos: 48\n",
      "2025-01-05 21:03:13,708 - __main__ - INFO - - Muestra valores: [-0.38325786 -0.31209521 -0.09860726  0.04371804  0.18604334]\n",
      "2025-01-05 21:03:13,708 - INFO - - Muestra valores: [-0.38325786 -0.31209521 -0.09860726  0.04371804  0.18604334]\n",
      "2025-01-05 21:03:13,712 - __main__ - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:13,712 - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:13,786 - __main__ - INFO - - variance_score: 0.004659631129215312\n",
      "2025-01-05 21:03:13,786 - INFO - - variance_score: 0.004659631129215312\n",
      "2025-01-05 21:03:13,854 - __main__ - INFO - - stability_score: 0.8749726633729449\n",
      "2025-01-05 21:03:13,854 - INFO - - stability_score: 0.8749726633729449\n",
      "2025-01-05 21:03:13,865 - __main__ - INFO - - trend_score: 0.00025257528703820045\n",
      "2025-01-05 21:03:13,865 - INFO - - trend_score: 0.00025257528703820045\n",
      "2025-01-05 21:03:13,883 - __main__ - INFO - - correlation_score: 0.37960695102948844\n",
      "2025-01-05 21:03:13,883 - INFO - - correlation_score: 0.37960695102948844\n",
      "2025-01-05 21:03:13,890 - __main__ - INFO - - final_score: 0.3398615936139534\n",
      "2025-01-05 21:03:13,890 - INFO - - final_score: 0.3398615936139534\n",
      "2025-01-05 21:03:13,897 - __main__ - INFO - \n",
      "Analizando armonicos_il1_armonico_11_il1:\n",
      "2025-01-05 21:03:13,897 - INFO - \n",
      "Analizando armonicos_il1_armonico_11_il1:\n",
      "2025-01-05 21:03:13,901 - __main__ - INFO - - Valores únicos: 3\n",
      "2025-01-05 21:03:13,901 - INFO - - Valores únicos: 3\n",
      "2025-01-05 21:03:13,904 - __main__ - INFO - - Muestra valores: [-0.07209177 11.68149954 14.0322178 ]\n",
      "2025-01-05 21:03:13,904 - INFO - - Muestra valores: [-0.07209177 11.68149954 14.0322178 ]\n",
      "2025-01-05 21:03:13,912 - __main__ - INFO - - Varianza: 1.0001400560224092\n",
      "2025-01-05 21:03:13,912 - INFO - - Varianza: 1.0001400560224092\n",
      "2025-01-05 21:03:13,920 - __main__ - WARNING - Variable armonicos_il1_armonico_11_il1 tiene muy pocos valores únicos (3)\n",
      "2025-01-05 21:03:13,920 - WARNING - Variable armonicos_il1_armonico_11_il1 tiene muy pocos valores únicos (3)\n",
      "2025-01-05 21:03:13,931 - __main__ - WARNING - Variable armonicos_il1_armonico_11_il1 no pasó validación inicial\n",
      "2025-01-05 21:03:13,931 - WARNING - Variable armonicos_il1_armonico_11_il1 no pasó validación inicial\n",
      "2025-01-05 21:03:13,935 - __main__ - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:13,935 - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:13,943 - __main__ - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:13,943 - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:13,945 - __main__ - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:13,945 - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:13,947 - __main__ - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:13,947 - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:13,949 - __main__ - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:13,949 - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:13,951 - __main__ - WARNING - Variable descartada: armonicos_il1_armonico_11_il1\n",
      "2025-01-05 21:03:13,951 - WARNING - Variable descartada: armonicos_il1_armonico_11_il1\n",
      "2025-01-05 21:03:13,953 - __main__ - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:13,953 - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:13,962 - __main__ - INFO - \n",
      "Analizando armonicos_il1_armonico_13_il1:\n",
      "2025-01-05 21:03:13,962 - INFO - \n",
      "Analizando armonicos_il1_armonico_13_il1:\n",
      "2025-01-05 21:03:13,965 - __main__ - INFO - - Valores únicos: 6\n",
      "2025-01-05 21:03:13,965 - INFO - - Valores únicos: 6\n",
      "2025-01-05 21:03:13,969 - __main__ - INFO - - Muestra valores: [ 2.86888814  3.49773982 -0.27537029  5.38429487  6.64199824]\n",
      "2025-01-05 21:03:13,969 - INFO - - Muestra valores: [ 2.86888814  3.49773982 -0.27537029  5.38429487  6.64199824]\n",
      "2025-01-05 21:03:13,972 - __main__ - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:13,972 - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:13,974 - __main__ - WARNING - Variable armonicos_il1_armonico_13_il1 tiene ratio de valores únicos muy bajo (0.000840)\n",
      "2025-01-05 21:03:13,974 - WARNING - Variable armonicos_il1_armonico_13_il1 tiene ratio de valores únicos muy bajo (0.000840)\n",
      "2025-01-05 21:03:13,981 - __main__ - WARNING - Variable armonicos_il1_armonico_13_il1 no pasó validación inicial\n",
      "2025-01-05 21:03:13,981 - WARNING - Variable armonicos_il1_armonico_13_il1 no pasó validación inicial\n",
      "2025-01-05 21:03:13,989 - __main__ - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:13,989 - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:13,993 - __main__ - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:13,993 - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:13,994 - __main__ - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:13,994 - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:14,002 - __main__ - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:14,002 - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:14,015 - __main__ - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:14,015 - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:14,038 - __main__ - WARNING - Variable descartada: armonicos_il1_armonico_13_il1\n",
      "2025-01-05 21:03:14,038 - WARNING - Variable descartada: armonicos_il1_armonico_13_il1\n",
      "2025-01-05 21:03:14,056 - __main__ - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:14,056 - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:14,121 - __main__ - INFO - \n",
      "Analizando armonicos_il2_armonico_2_il2:\n",
      "2025-01-05 21:03:14,121 - INFO - \n",
      "Analizando armonicos_il2_armonico_2_il2:\n",
      "2025-01-05 21:03:14,127 - __main__ - INFO - - Valores únicos: 9\n",
      "2025-01-05 21:03:14,127 - INFO - - Valores únicos: 9\n",
      "2025-01-05 21:03:14,134 - __main__ - INFO - - Muestra valores: [-3.49216298e-02  3.80640915e+01  1.38192649e+01  1.72828116e+01\n",
      "  2.42099049e+01]\n",
      "2025-01-05 21:03:14,134 - INFO - - Muestra valores: [-3.49216298e-02  3.80640915e+01  1.38192649e+01  1.72828116e+01\n",
      "  2.42099049e+01]\n",
      "2025-01-05 21:03:14,138 - __main__ - INFO - - Varianza: 1.0001400560224092\n",
      "2025-01-05 21:03:14,138 - INFO - - Varianza: 1.0001400560224092\n",
      "2025-01-05 21:03:14,185 - __main__ - INFO - - variance_score: 0.0008736808367278713\n",
      "2025-01-05 21:03:14,185 - INFO - - variance_score: 0.0008736808367278713\n",
      "2025-01-05 21:03:14,190 - __main__ - INFO - - stability_score: 0.8367867999525037\n",
      "2025-01-05 21:03:14,190 - INFO - - stability_score: 0.8367867999525037\n",
      "2025-01-05 21:03:14,192 - __main__ - INFO - - trend_score: 7.842330568601994e-07\n",
      "2025-01-05 21:03:14,192 - INFO - - trend_score: 7.842330568601994e-07\n",
      "2025-01-05 21:03:14,196 - __main__ - INFO - - correlation_score: 0.07044119201458338\n",
      "2025-01-05 21:03:14,196 - INFO - - correlation_score: 0.07044119201458338\n",
      "2025-01-05 21:03:14,200 - __main__ - INFO - - final_score: 0.2653865394862975\n",
      "2025-01-05 21:03:14,200 - INFO - - final_score: 0.2653865394862975\n",
      "2025-01-05 21:03:14,207 - __main__ - INFO - \n",
      "Analizando armonicos_il2_armonico_3_il2:\n",
      "2025-01-05 21:03:14,207 - INFO - \n",
      "Analizando armonicos_il2_armonico_3_il2:\n",
      "2025-01-05 21:03:14,212 - __main__ - INFO - - Valores únicos: 41\n",
      "2025-01-05 21:03:14,212 - INFO - - Valores únicos: 41\n",
      "2025-01-05 21:03:14,215 - __main__ - INFO - - Muestra valores: [-0.01203012  0.18211022  0.08504005  0.37625056  0.5703909 ]\n",
      "2025-01-05 21:03:14,215 - INFO - - Muestra valores: [-0.01203012  0.18211022  0.08504005  0.37625056  0.5703909 ]\n",
      "2025-01-05 21:03:14,220 - __main__ - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:14,220 - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:14,310 - __main__ - INFO - - variance_score: 0.00398010158953808\n",
      "2025-01-05 21:03:14,310 - INFO - - variance_score: 0.00398010158953808\n",
      "2025-01-05 21:03:14,322 - __main__ - INFO - - stability_score: 0.8424867871829623\n",
      "2025-01-05 21:03:14,322 - INFO - - stability_score: 0.8424867871829623\n",
      "2025-01-05 21:03:14,340 - __main__ - INFO - - trend_score: 0.00011873516132906695\n",
      "2025-01-05 21:03:14,340 - INFO - - trend_score: 0.00011873516132906695\n",
      "2025-01-05 21:03:14,362 - __main__ - INFO - - correlation_score: 0.37112345062102037\n",
      "2025-01-05 21:03:14,362 - INFO - - correlation_score: 0.37112345062102037\n",
      "2025-01-05 21:03:14,372 - __main__ - INFO - - final_score: 0.32818850378821995\n",
      "2025-01-05 21:03:14,372 - INFO - - final_score: 0.32818850378821995\n",
      "2025-01-05 21:03:14,384 - __main__ - INFO - \n",
      "Analizando armonicos_il2_armonico_5_il2:\n",
      "2025-01-05 21:03:14,384 - INFO - \n",
      "Analizando armonicos_il2_armonico_5_il2:\n",
      "2025-01-05 21:03:14,395 - __main__ - INFO - - Valores únicos: 119\n",
      "2025-01-05 21:03:14,395 - INFO - - Valores únicos: 119\n",
      "2025-01-05 21:03:14,399 - __main__ - INFO - - Muestra valores: [-0.34701946 -0.22050792  0.03251517  0.20119724  0.41204981]\n",
      "2025-01-05 21:03:14,399 - INFO - - Muestra valores: [-0.34701946 -0.22050792  0.03251517  0.20119724  0.41204981]\n",
      "2025-01-05 21:03:14,404 - __main__ - INFO - - Varianza: 1.0001400560224092\n",
      "2025-01-05 21:03:14,404 - INFO - - Varianza: 1.0001400560224092\n",
      "2025-01-05 21:03:14,435 - __main__ - INFO - - variance_score: 0.011552002174512964\n",
      "2025-01-05 21:03:14,435 - INFO - - variance_score: 0.011552002174512964\n",
      "2025-01-05 21:03:14,438 - __main__ - INFO - - stability_score: 0.8608345023039612\n",
      "2025-01-05 21:03:14,438 - INFO - - stability_score: 0.8608345023039612\n",
      "2025-01-05 21:03:14,442 - __main__ - INFO - - trend_score: 0.0001525076641939011\n",
      "2025-01-05 21:03:14,442 - INFO - - trend_score: 0.0001525076641939011\n",
      "2025-01-05 21:03:14,444 - __main__ - INFO - - correlation_score: 0.3374404406594006\n",
      "2025-01-05 21:03:14,444 - INFO - - correlation_score: 0.3374404406594006\n",
      "2025-01-05 21:03:14,448 - __main__ - INFO - - final_score: 0.32923454100826116\n",
      "2025-01-05 21:03:14,448 - INFO - - final_score: 0.32923454100826116\n",
      "2025-01-05 21:03:14,453 - __main__ - INFO - \n",
      "Analizando armonicos_il2_armonico_7_il2:\n",
      "2025-01-05 21:03:14,453 - INFO - \n",
      "Analizando armonicos_il2_armonico_7_il2:\n",
      "2025-01-05 21:03:14,457 - __main__ - INFO - - Valores únicos: 58\n",
      "2025-01-05 21:03:14,457 - INFO - - Valores únicos: 58\n",
      "2025-01-05 21:03:14,471 - __main__ - INFO - - Muestra valores: [-0.54331667 -0.46605704 -0.23427813 -0.07975886  0.07476041]\n",
      "2025-01-05 21:03:14,471 - INFO - - Muestra valores: [-0.54331667 -0.46605704 -0.23427813 -0.07975886  0.07476041]\n",
      "2025-01-05 21:03:14,481 - __main__ - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:14,481 - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:14,517 - __main__ - INFO - - variance_score: 0.005630387614468501\n",
      "2025-01-05 21:03:14,517 - INFO - - variance_score: 0.005630387614468501\n",
      "2025-01-05 21:03:14,520 - __main__ - INFO - - stability_score: 0.8687575297394932\n",
      "2025-01-05 21:03:14,520 - INFO - - stability_score: 0.8687575297394932\n",
      "2025-01-05 21:03:14,523 - __main__ - INFO - - trend_score: 0.00022163150786418595\n",
      "2025-01-05 21:03:14,523 - INFO - - trend_score: 0.00022163150786418595\n",
      "2025-01-05 21:03:14,525 - __main__ - INFO - - correlation_score: 0.3479771535831767\n",
      "2025-01-05 21:03:14,525 - INFO - - correlation_score: 0.3479771535831767\n",
      "2025-01-05 21:03:14,527 - __main__ - INFO - - final_score: 0.3319561322243967\n",
      "2025-01-05 21:03:14,527 - INFO - - final_score: 0.3319561322243967\n",
      "2025-01-05 21:03:14,535 - __main__ - INFO - \n",
      "Analizando armonicos_il2_armonico_9_il2:\n",
      "2025-01-05 21:03:14,535 - INFO - \n",
      "Analizando armonicos_il2_armonico_9_il2:\n",
      "2025-01-05 21:03:14,539 - __main__ - INFO - - Valores únicos: 4\n",
      "2025-01-05 21:03:14,539 - INFO - - Valores únicos: 4\n",
      "2025-01-05 21:03:14,542 - __main__ - INFO - - Muestra valores: [-1.86752233e-02  7.01706772e+01  4.20949362e+01  2.10381305e+01]\n",
      "2025-01-05 21:03:14,542 - INFO - - Muestra valores: [-1.86752233e-02  7.01706772e+01  4.20949362e+01  2.10381305e+01]\n",
      "2025-01-05 21:03:14,545 - __main__ - INFO - - Varianza: 1.0001400560224092\n",
      "2025-01-05 21:03:14,545 - INFO - - Varianza: 1.0001400560224092\n",
      "2025-01-05 21:03:14,550 - __main__ - WARNING - Variable armonicos_il2_armonico_9_il2 tiene ratio de valores únicos muy bajo (0.000560)\n",
      "2025-01-05 21:03:14,550 - WARNING - Variable armonicos_il2_armonico_9_il2 tiene ratio de valores únicos muy bajo (0.000560)\n",
      "2025-01-05 21:03:14,552 - __main__ - WARNING - Variable armonicos_il2_armonico_9_il2 no pasó validación inicial\n",
      "2025-01-05 21:03:14,552 - WARNING - Variable armonicos_il2_armonico_9_il2 no pasó validación inicial\n",
      "2025-01-05 21:03:14,555 - __main__ - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:14,555 - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:14,557 - __main__ - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:14,557 - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:14,559 - __main__ - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:14,559 - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:14,561 - __main__ - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:14,561 - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:14,568 - __main__ - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:14,568 - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:14,573 - __main__ - WARNING - Variable descartada: armonicos_il2_armonico_9_il2\n",
      "2025-01-05 21:03:14,573 - WARNING - Variable descartada: armonicos_il2_armonico_9_il2\n",
      "2025-01-05 21:03:14,578 - __main__ - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:14,578 - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:14,588 - __main__ - INFO - \n",
      "Analizando armonicos_il2_armonico_11_il2:\n",
      "2025-01-05 21:03:14,588 - INFO - \n",
      "Analizando armonicos_il2_armonico_11_il2:\n",
      "2025-01-05 21:03:14,595 - __main__ - INFO - - Valores únicos: 9\n",
      "2025-01-05 21:03:14,595 - INFO - - Valores únicos: 9\n",
      "2025-01-05 21:03:14,600 - __main__ - INFO - - Muestra valores: [-0.19094339  7.85007359  7.27571524  4.97828181  5.55264017]\n",
      "2025-01-05 21:03:14,600 - INFO - - Muestra valores: [-0.19094339  7.85007359  7.27571524  4.97828181  5.55264017]\n",
      "2025-01-05 21:03:14,607 - __main__ - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:14,607 - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:14,644 - __main__ - INFO - - variance_score: 0.0008736808367278711\n",
      "2025-01-05 21:03:14,644 - INFO - - variance_score: 0.0008736808367278711\n",
      "2025-01-05 21:03:14,648 - __main__ - INFO - - stability_score: 0.9352523774945001\n",
      "2025-01-05 21:03:14,648 - INFO - - stability_score: 0.9352523774945001\n",
      "2025-01-05 21:03:14,650 - __main__ - INFO - - trend_score: 4.33724517691269e-05\n",
      "2025-01-05 21:03:14,650 - INFO - - trend_score: 4.33724517691269e-05\n",
      "2025-01-05 21:03:14,653 - __main__ - INFO - - correlation_score: 0.09071552125692092\n",
      "2025-01-05 21:03:14,653 - INFO - - correlation_score: 0.09071552125692092\n",
      "2025-01-05 21:03:14,655 - __main__ - INFO - - final_score: 0.2989895962411063\n",
      "2025-01-05 21:03:14,655 - INFO - - final_score: 0.2989895962411063\n",
      "2025-01-05 21:03:14,660 - __main__ - INFO - \n",
      "Analizando armonicos_il2_armonico_13_il2:\n",
      "2025-01-05 21:03:14,660 - INFO - \n",
      "Analizando armonicos_il2_armonico_13_il2:\n",
      "2025-01-05 21:03:14,662 - __main__ - INFO - - Valores únicos: 15\n",
      "2025-01-05 21:03:14,662 - INFO - - Valores únicos: 15\n",
      "2025-01-05 21:03:14,665 - __main__ - INFO - - Muestra valores: [0.06412233 0.30348332 0.5428443  0.78220528 1.02156627]\n",
      "2025-01-05 21:03:14,665 - INFO - - Muestra valores: [0.06412233 0.30348332 0.5428443  0.78220528 1.02156627]\n",
      "2025-01-05 21:03:14,668 - __main__ - INFO - - Varianza: 1.0001400560224092\n",
      "2025-01-05 21:03:14,668 - INFO - - Varianza: 1.0001400560224092\n",
      "2025-01-05 21:03:14,701 - __main__ - INFO - - variance_score: 0.0014561347278797853\n",
      "2025-01-05 21:03:14,701 - INFO - - variance_score: 0.0014561347278797853\n",
      "2025-01-05 21:03:14,704 - __main__ - INFO - - stability_score: 0.8394761373174205\n",
      "2025-01-05 21:03:14,704 - INFO - - stability_score: 0.8394761373174205\n",
      "2025-01-05 21:03:14,706 - __main__ - INFO - - trend_score: 6.145148500624655e-05\n",
      "2025-01-05 21:03:14,706 - INFO - - trend_score: 6.145148500624655e-05\n",
      "2025-01-05 21:03:14,710 - __main__ - INFO - - correlation_score: 0.3330384706906187\n",
      "2025-01-05 21:03:14,710 - INFO - - correlation_score: 0.3330384706906187\n",
      "2025-01-05 21:03:14,713 - __main__ - INFO - - final_score: 0.31889966604871506\n",
      "2025-01-05 21:03:14,713 - INFO - - final_score: 0.31889966604871506\n",
      "2025-01-05 21:03:14,718 - __main__ - INFO - \n",
      "Analizando armonicos_vl1_armonico_2_vl1:\n",
      "2025-01-05 21:03:14,718 - INFO - \n",
      "Analizando armonicos_vl1_armonico_2_vl1:\n",
      "2025-01-05 21:03:14,723 - __main__ - INFO - - Valores únicos: 3\n",
      "2025-01-05 21:03:14,723 - INFO - - Valores únicos: 3\n",
      "2025-01-05 21:03:14,727 - __main__ - INFO - - Muestra valores: [-2.76224941e-02  2.81512676e+01  5.63301576e+01]\n",
      "2025-01-05 21:03:14,727 - INFO - - Muestra valores: [-2.76224941e-02  2.81512676e+01  5.63301576e+01]\n",
      "2025-01-05 21:03:14,730 - __main__ - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:14,730 - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:14,736 - __main__ - WARNING - Variable armonicos_vl1_armonico_2_vl1 tiene muy pocos valores únicos (3)\n",
      "2025-01-05 21:03:14,736 - WARNING - Variable armonicos_vl1_armonico_2_vl1 tiene muy pocos valores únicos (3)\n",
      "2025-01-05 21:03:14,739 - __main__ - WARNING - Variable armonicos_vl1_armonico_2_vl1 no pasó validación inicial\n",
      "2025-01-05 21:03:14,739 - WARNING - Variable armonicos_vl1_armonico_2_vl1 no pasó validación inicial\n",
      "2025-01-05 21:03:14,742 - __main__ - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:14,742 - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:14,745 - __main__ - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:14,745 - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:14,748 - __main__ - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:14,748 - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:14,752 - __main__ - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:14,752 - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:14,755 - __main__ - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:14,755 - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:14,757 - __main__ - WARNING - Variable descartada: armonicos_vl1_armonico_2_vl1\n",
      "2025-01-05 21:03:14,757 - WARNING - Variable descartada: armonicos_vl1_armonico_2_vl1\n",
      "2025-01-05 21:03:14,759 - __main__ - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:14,759 - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:14,765 - __main__ - INFO - \n",
      "Analizando armonicos_vl1_armonico_3_vl1:\n",
      "2025-01-05 21:03:14,765 - INFO - \n",
      "Analizando armonicos_vl1_armonico_3_vl1:\n",
      "2025-01-05 21:03:14,769 - __main__ - INFO - - Valores únicos: 5\n",
      "2025-01-05 21:03:14,769 - INFO - - Valores únicos: 5\n",
      "2025-01-05 21:03:14,772 - __main__ - INFO - - Muestra valores: [-0.89571617  0.05244706  1.0006103   1.94877354  3.84510001]\n",
      "2025-01-05 21:03:14,772 - INFO - - Muestra valores: [-0.89571617  0.05244706  1.0006103   1.94877354  3.84510001]\n",
      "2025-01-05 21:03:14,774 - __main__ - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:14,774 - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:14,780 - __main__ - WARNING - Variable armonicos_vl1_armonico_3_vl1 tiene ratio de valores únicos muy bajo (0.000700)\n",
      "2025-01-05 21:03:14,780 - WARNING - Variable armonicos_vl1_armonico_3_vl1 tiene ratio de valores únicos muy bajo (0.000700)\n",
      "2025-01-05 21:03:14,783 - __main__ - WARNING - Variable armonicos_vl1_armonico_3_vl1 no pasó validación inicial\n",
      "2025-01-05 21:03:14,783 - WARNING - Variable armonicos_vl1_armonico_3_vl1 no pasó validación inicial\n",
      "2025-01-05 21:03:14,785 - __main__ - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:14,785 - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:14,787 - __main__ - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:14,787 - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:14,788 - __main__ - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:14,788 - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:14,790 - __main__ - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:14,790 - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:14,792 - __main__ - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:14,792 - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:14,792 - __main__ - WARNING - Variable descartada: armonicos_vl1_armonico_3_vl1\n",
      "2025-01-05 21:03:14,792 - WARNING - Variable descartada: armonicos_vl1_armonico_3_vl1\n",
      "2025-01-05 21:03:14,793 - __main__ - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:14,793 - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:14,798 - __main__ - INFO - \n",
      "Analizando armonicos_vl1_armonico_5_vl1:\n",
      "2025-01-05 21:03:14,798 - INFO - \n",
      "Analizando armonicos_vl1_armonico_5_vl1:\n",
      "2025-01-05 21:03:14,799 - __main__ - INFO - - Valores únicos: 16\n",
      "2025-01-05 21:03:14,799 - INFO - - Valores únicos: 16\n",
      "2025-01-05 21:03:14,801 - __main__ - INFO - - Muestra valores: [ 0.22508909 -0.05759842 -0.34028594 -0.62297345 -0.90566096]\n",
      "2025-01-05 21:03:14,801 - INFO - - Muestra valores: [ 0.22508909 -0.05759842 -0.34028594 -0.62297345 -0.90566096]\n",
      "2025-01-05 21:03:14,802 - __main__ - INFO - - Varianza: 1.0001400560224092\n",
      "2025-01-05 21:03:14,802 - INFO - - Varianza: 1.0001400560224092\n",
      "2025-01-05 21:03:14,835 - __main__ - INFO - - variance_score: 0.0015532103764051045\n",
      "2025-01-05 21:03:14,835 - INFO - - variance_score: 0.0015532103764051045\n",
      "2025-01-05 21:03:14,838 - __main__ - INFO - - stability_score: 0.8864671870409642\n",
      "2025-01-05 21:03:14,838 - INFO - - stability_score: 0.8864671870409642\n",
      "2025-01-05 21:03:14,841 - __main__ - INFO - - trend_score: 0.0002520680984807908\n",
      "2025-01-05 21:03:14,841 - INFO - - trend_score: 0.0002520680984807908\n",
      "2025-01-05 21:03:14,844 - __main__ - INFO - - correlation_score: 0.40858924187323303\n",
      "2025-01-05 21:03:14,844 - INFO - - correlation_score: 0.40858924187323303\n",
      "2025-01-05 21:03:14,847 - __main__ - INFO - - final_score: 0.3481743812195535\n",
      "2025-01-05 21:03:14,847 - INFO - - final_score: 0.3481743812195535\n",
      "2025-01-05 21:03:14,854 - __main__ - INFO - \n",
      "Analizando armonicos_vl1_armonico_7_vl1:\n",
      "2025-01-05 21:03:14,854 - INFO - \n",
      "Analizando armonicos_vl1_armonico_7_vl1:\n",
      "2025-01-05 21:03:14,857 - __main__ - INFO - - Valores únicos: 12\n",
      "2025-01-05 21:03:14,857 - INFO - - Valores únicos: 12\n",
      "2025-01-05 21:03:14,859 - __main__ - INFO - - Muestra valores: [ 0.30927617  0.7012785  -0.08272616 -0.47472849 -0.86673081]\n",
      "2025-01-05 21:03:14,859 - INFO - - Muestra valores: [ 0.30927617  0.7012785  -0.08272616 -0.47472849 -0.86673081]\n",
      "2025-01-05 21:03:14,861 - __main__ - INFO - - Varianza: 1.0001400560224092\n",
      "2025-01-05 21:03:14,861 - INFO - - Varianza: 1.0001400560224092\n",
      "2025-01-05 21:03:14,892 - __main__ - INFO - - variance_score: 0.0011649077823038282\n",
      "2025-01-05 21:03:14,892 - INFO - - variance_score: 0.0011649077823038282\n",
      "2025-01-05 21:03:14,895 - __main__ - INFO - - stability_score: 0.8570568209006528\n",
      "2025-01-05 21:03:14,895 - INFO - - stability_score: 0.8570568209006528\n",
      "2025-01-05 21:03:14,898 - __main__ - INFO - - trend_score: 4.634213034554429e-05\n",
      "2025-01-05 21:03:14,898 - INFO - - trend_score: 4.634213034554429e-05\n",
      "2025-01-05 21:03:14,900 - __main__ - INFO - - correlation_score: 0.3035776415592526\n",
      "2025-01-05 21:03:14,900 - INFO - - correlation_score: 0.3035776415592526\n",
      "2025-01-05 21:03:14,903 - __main__ - INFO - - final_score: 0.3181913153428066\n",
      "2025-01-05 21:03:14,903 - INFO - - final_score: 0.3181913153428066\n",
      "2025-01-05 21:03:14,911 - __main__ - INFO - \n",
      "Analizando armonicos_vl1_armonico_9_vl1:\n",
      "2025-01-05 21:03:14,911 - INFO - \n",
      "Analizando armonicos_vl1_armonico_9_vl1:\n",
      "2025-01-05 21:03:14,913 - __main__ - INFO - - Valores únicos: 2\n",
      "2025-01-05 21:03:14,913 - INFO - - Valores únicos: 2\n",
      "2025-01-05 21:03:14,917 - __main__ - INFO - - Muestra valores: [-2.05008730e-02  4.87784105e+01]\n",
      "2025-01-05 21:03:14,917 - INFO - - Muestra valores: [-2.05008730e-02  4.87784105e+01]\n",
      "2025-01-05 21:03:14,920 - __main__ - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:14,920 - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:14,924 - __main__ - WARNING - Variable armonicos_vl1_armonico_9_vl1 tiene muy pocos valores únicos (2)\n",
      "2025-01-05 21:03:14,924 - WARNING - Variable armonicos_vl1_armonico_9_vl1 tiene muy pocos valores únicos (2)\n",
      "2025-01-05 21:03:14,927 - __main__ - WARNING - Variable armonicos_vl1_armonico_9_vl1 no pasó validación inicial\n",
      "2025-01-05 21:03:14,927 - WARNING - Variable armonicos_vl1_armonico_9_vl1 no pasó validación inicial\n",
      "2025-01-05 21:03:14,929 - __main__ - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:14,929 - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:14,932 - __main__ - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:14,932 - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:14,935 - __main__ - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:14,935 - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:14,938 - __main__ - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:14,938 - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:14,941 - __main__ - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:14,941 - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:14,945 - __main__ - WARNING - Variable descartada: armonicos_vl1_armonico_9_vl1\n",
      "2025-01-05 21:03:14,945 - WARNING - Variable descartada: armonicos_vl1_armonico_9_vl1\n",
      "2025-01-05 21:03:14,947 - __main__ - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:14,947 - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:14,953 - __main__ - INFO - \n",
      "Analizando armonicos_vl1_armonico_11_vl1:\n",
      "2025-01-05 21:03:14,953 - INFO - \n",
      "Analizando armonicos_vl1_armonico_11_vl1:\n",
      "2025-01-05 21:03:14,957 - __main__ - INFO - - Valores únicos: 4\n",
      "2025-01-05 21:03:14,957 - INFO - - Valores únicos: 4\n",
      "2025-01-05 21:03:14,961 - __main__ - INFO - - Muestra valores: [ 1.51631911  0.39261272 -0.73109367  2.6400255 ]\n",
      "2025-01-05 21:03:14,961 - INFO - - Muestra valores: [ 1.51631911  0.39261272 -0.73109367  2.6400255 ]\n",
      "2025-01-05 21:03:14,964 - __main__ - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:14,964 - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:14,970 - __main__ - WARNING - Variable armonicos_vl1_armonico_11_vl1 tiene ratio de valores únicos muy bajo (0.000560)\n",
      "2025-01-05 21:03:14,970 - WARNING - Variable armonicos_vl1_armonico_11_vl1 tiene ratio de valores únicos muy bajo (0.000560)\n",
      "2025-01-05 21:03:14,972 - __main__ - WARNING - Variable armonicos_vl1_armonico_11_vl1 no pasó validación inicial\n",
      "2025-01-05 21:03:14,972 - WARNING - Variable armonicos_vl1_armonico_11_vl1 no pasó validación inicial\n",
      "2025-01-05 21:03:14,976 - __main__ - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:14,976 - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:14,978 - __main__ - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:14,978 - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:14,980 - __main__ - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:14,980 - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:14,984 - __main__ - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:14,984 - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:15,015 - __main__ - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:15,015 - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:15,049 - __main__ - WARNING - Variable descartada: armonicos_vl1_armonico_11_vl1\n",
      "2025-01-05 21:03:15,049 - WARNING - Variable descartada: armonicos_vl1_armonico_11_vl1\n",
      "2025-01-05 21:03:15,089 - __main__ - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:15,089 - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:15,116 - __main__ - INFO - \n",
      "Analizando armonicos_vl1_armonico_13_vl1:\n",
      "2025-01-05 21:03:15,116 - INFO - \n",
      "Analizando armonicos_vl1_armonico_13_vl1:\n",
      "2025-01-05 21:03:15,123 - __main__ - INFO - - Valores únicos: 3\n",
      "2025-01-05 21:03:15,123 - INFO - - Valores únicos: 3\n",
      "2025-01-05 21:03:15,130 - __main__ - INFO - - Muestra valores: [ 2.64295957 -0.34617161  5.63209076]\n",
      "2025-01-05 21:03:15,130 - INFO - - Muestra valores: [ 2.64295957 -0.34617161  5.63209076]\n",
      "2025-01-05 21:03:15,139 - __main__ - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:15,139 - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:15,143 - __main__ - WARNING - Variable armonicos_vl1_armonico_13_vl1 tiene muy pocos valores únicos (3)\n",
      "2025-01-05 21:03:15,143 - WARNING - Variable armonicos_vl1_armonico_13_vl1 tiene muy pocos valores únicos (3)\n",
      "2025-01-05 21:03:15,147 - __main__ - WARNING - Variable armonicos_vl1_armonico_13_vl1 no pasó validación inicial\n",
      "2025-01-05 21:03:15,147 - WARNING - Variable armonicos_vl1_armonico_13_vl1 no pasó validación inicial\n",
      "2025-01-05 21:03:15,153 - __main__ - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:15,153 - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:15,158 - __main__ - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:15,158 - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:15,168 - __main__ - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:15,168 - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:15,173 - __main__ - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:15,173 - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:15,180 - __main__ - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:15,180 - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:15,182 - __main__ - WARNING - Variable descartada: armonicos_vl1_armonico_13_vl1\n",
      "2025-01-05 21:03:15,182 - WARNING - Variable descartada: armonicos_vl1_armonico_13_vl1\n",
      "2025-01-05 21:03:15,190 - __main__ - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:15,190 - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:15,197 - __main__ - INFO - \n",
      "Analizando armonicos_vl2_armonico_2_vl2:\n",
      "2025-01-05 21:03:15,197 - INFO - \n",
      "Analizando armonicos_vl2_armonico_2_vl2:\n",
      "2025-01-05 21:03:15,201 - __main__ - INFO - - Valores únicos: 3\n",
      "2025-01-05 21:03:15,201 - INFO - - Valores únicos: 3\n",
      "2025-01-05 21:03:15,205 - __main__ - INFO - - Muestra valores: [-2.75094325e-02  4.36269034e+01  2.17996970e+01]\n",
      "2025-01-05 21:03:15,205 - INFO - - Muestra valores: [-2.75094325e-02  4.36269034e+01  2.17996970e+01]\n",
      "2025-01-05 21:03:15,210 - __main__ - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:15,210 - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:15,215 - __main__ - WARNING - Variable armonicos_vl2_armonico_2_vl2 tiene muy pocos valores únicos (3)\n",
      "2025-01-05 21:03:15,215 - WARNING - Variable armonicos_vl2_armonico_2_vl2 tiene muy pocos valores únicos (3)\n",
      "2025-01-05 21:03:15,217 - __main__ - WARNING - Variable armonicos_vl2_armonico_2_vl2 no pasó validación inicial\n",
      "2025-01-05 21:03:15,217 - WARNING - Variable armonicos_vl2_armonico_2_vl2 no pasó validación inicial\n",
      "2025-01-05 21:03:15,219 - __main__ - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:15,219 - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:15,222 - __main__ - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:15,222 - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:15,224 - __main__ - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:15,224 - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:15,228 - __main__ - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:15,228 - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:15,233 - __main__ - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:15,233 - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:15,237 - __main__ - WARNING - Variable descartada: armonicos_vl2_armonico_2_vl2\n",
      "2025-01-05 21:03:15,237 - WARNING - Variable descartada: armonicos_vl2_armonico_2_vl2\n",
      "2025-01-05 21:03:15,241 - __main__ - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:15,241 - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:15,246 - __main__ - INFO - \n",
      "Analizando armonicos_vl2_armonico_3_vl2:\n",
      "2025-01-05 21:03:15,246 - INFO - \n",
      "Analizando armonicos_vl2_armonico_3_vl2:\n",
      "2025-01-05 21:03:15,248 - __main__ - INFO - - Valores únicos: 7\n",
      "2025-01-05 21:03:15,248 - INFO - - Valores únicos: 7\n",
      "2025-01-05 21:03:15,251 - __main__ - INFO - - Muestra valores: [-0.33202775  1.44135306  3.21473386  4.98811466  8.53487627]\n",
      "2025-01-05 21:03:15,251 - INFO - - Muestra valores: [-0.33202775  1.44135306  3.21473386  4.98811466  8.53487627]\n",
      "2025-01-05 21:03:15,255 - __main__ - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:15,255 - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:15,259 - __main__ - WARNING - Variable armonicos_vl2_armonico_3_vl2 tiene ratio de valores únicos muy bajo (0.000980)\n",
      "2025-01-05 21:03:15,259 - WARNING - Variable armonicos_vl2_armonico_3_vl2 tiene ratio de valores únicos muy bajo (0.000980)\n",
      "2025-01-05 21:03:15,261 - __main__ - WARNING - Variable armonicos_vl2_armonico_3_vl2 no pasó validación inicial\n",
      "2025-01-05 21:03:15,261 - WARNING - Variable armonicos_vl2_armonico_3_vl2 no pasó validación inicial\n",
      "2025-01-05 21:03:15,264 - __main__ - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:15,264 - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:15,268 - __main__ - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:15,268 - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:15,274 - __main__ - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:15,274 - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:15,276 - __main__ - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:15,276 - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:15,280 - __main__ - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:15,280 - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:15,283 - __main__ - WARNING - Variable descartada: armonicos_vl2_armonico_3_vl2\n",
      "2025-01-05 21:03:15,283 - WARNING - Variable descartada: armonicos_vl2_armonico_3_vl2\n",
      "2025-01-05 21:03:15,286 - __main__ - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:15,286 - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:15,291 - __main__ - INFO - \n",
      "Analizando armonicos_vl2_armonico_5_vl2:\n",
      "2025-01-05 21:03:15,291 - INFO - \n",
      "Analizando armonicos_vl2_armonico_5_vl2:\n",
      "2025-01-05 21:03:15,297 - __main__ - INFO - - Valores únicos: 19\n",
      "2025-01-05 21:03:15,297 - INFO - - Valores únicos: 19\n",
      "2025-01-05 21:03:15,304 - __main__ - INFO - - Muestra valores: [ 0.11045545 -0.12450504 -0.35946554 -0.59442603 -0.82938652]\n",
      "2025-01-05 21:03:15,304 - INFO - - Muestra valores: [ 0.11045545 -0.12450504 -0.35946554 -0.59442603 -0.82938652]\n",
      "2025-01-05 21:03:15,311 - __main__ - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:15,311 - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:15,340 - __main__ - INFO - - variance_score: 0.0018444373219810612\n",
      "2025-01-05 21:03:15,340 - INFO - - variance_score: 0.0018444373219810612\n",
      "2025-01-05 21:03:15,342 - __main__ - INFO - - stability_score: 0.9019929829335465\n",
      "2025-01-05 21:03:15,342 - INFO - - stability_score: 0.9019929829335465\n",
      "2025-01-05 21:03:15,344 - __main__ - INFO - - trend_score: 0.0002573545002199995\n",
      "2025-01-05 21:03:15,344 - INFO - - trend_score: 0.0002573545002199995\n",
      "2025-01-05 21:03:15,347 - __main__ - INFO - - correlation_score: 0.4133121777336047\n",
      "2025-01-05 21:03:15,347 - INFO - - correlation_score: 0.4133121777336047\n",
      "2025-01-05 21:03:15,349 - __main__ - INFO - - final_score: 0.35386513252342316\n",
      "2025-01-05 21:03:15,349 - INFO - - final_score: 0.35386513252342316\n",
      "2025-01-05 21:03:15,356 - __main__ - INFO - \n",
      "Analizando armonicos_vl2_armonico_7_vl2:\n",
      "2025-01-05 21:03:15,356 - INFO - \n",
      "Analizando armonicos_vl2_armonico_7_vl2:\n",
      "2025-01-05 21:03:15,358 - __main__ - INFO - - Valores únicos: 15\n",
      "2025-01-05 21:03:15,358 - INFO - - Valores únicos: 15\n",
      "2025-01-05 21:03:15,362 - __main__ - INFO - - Muestra valores: [ 0.06891456  0.40924572  0.74957689 -0.27141661 -0.61174777]\n",
      "2025-01-05 21:03:15,362 - INFO - - Muestra valores: [ 0.06891456  0.40924572  0.74957689 -0.27141661 -0.61174777]\n",
      "2025-01-05 21:03:15,364 - __main__ - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:15,364 - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:15,397 - __main__ - INFO - - variance_score: 0.001456134727879785\n",
      "2025-01-05 21:03:15,397 - INFO - - variance_score: 0.001456134727879785\n",
      "2025-01-05 21:03:15,400 - __main__ - INFO - - stability_score: 0.8540072573554134\n",
      "2025-01-05 21:03:15,400 - INFO - - stability_score: 0.8540072573554134\n",
      "2025-01-05 21:03:15,403 - __main__ - INFO - - trend_score: 1.0902715736418885e-05\n",
      "2025-01-05 21:03:15,403 - INFO - - trend_score: 1.0902715736418885e-05\n",
      "2025-01-05 21:03:15,406 - __main__ - INFO - - correlation_score: 0.307889913380909\n",
      "2025-01-05 21:03:15,406 - INFO - - correlation_score: 0.307889913380909\n",
      "2025-01-05 21:03:15,408 - __main__ - INFO - - final_score: 0.31821918084431705\n",
      "2025-01-05 21:03:15,408 - INFO - - final_score: 0.31821918084431705\n",
      "2025-01-05 21:03:15,414 - __main__ - INFO - \n",
      "Analizando armonicos_vl2_armonico_9_vl2:\n",
      "2025-01-05 21:03:15,414 - INFO - \n",
      "Analizando armonicos_vl2_armonico_9_vl2:\n",
      "2025-01-05 21:03:15,417 - __main__ - INFO - - Valores únicos: 3\n",
      "2025-01-05 21:03:15,417 - INFO - - Valores únicos: 3\n",
      "2025-01-05 21:03:15,419 - __main__ - INFO - - Muestra valores: [ 0.37227596  1.68378197 -0.93923004]\n",
      "2025-01-05 21:03:15,419 - INFO - - Muestra valores: [ 0.37227596  1.68378197 -0.93923004]\n",
      "2025-01-05 21:03:15,421 - __main__ - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:15,421 - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:15,427 - __main__ - WARNING - Variable armonicos_vl2_armonico_9_vl2 tiene muy pocos valores únicos (3)\n",
      "2025-01-05 21:03:15,427 - WARNING - Variable armonicos_vl2_armonico_9_vl2 tiene muy pocos valores únicos (3)\n",
      "2025-01-05 21:03:15,428 - __main__ - WARNING - Variable armonicos_vl2_armonico_9_vl2 no pasó validación inicial\n",
      "2025-01-05 21:03:15,428 - WARNING - Variable armonicos_vl2_armonico_9_vl2 no pasó validación inicial\n",
      "2025-01-05 21:03:15,431 - __main__ - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:15,431 - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:15,432 - __main__ - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:15,432 - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:15,435 - __main__ - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:15,435 - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:15,437 - __main__ - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:15,437 - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:15,441 - __main__ - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:15,441 - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:15,444 - __main__ - WARNING - Variable descartada: armonicos_vl2_armonico_9_vl2\n",
      "2025-01-05 21:03:15,444 - WARNING - Variable descartada: armonicos_vl2_armonico_9_vl2\n",
      "2025-01-05 21:03:15,447 - __main__ - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:15,447 - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:15,453 - __main__ - INFO - \n",
      "Analizando armonicos_vl2_armonico_11_vl2:\n",
      "2025-01-05 21:03:15,453 - INFO - \n",
      "Analizando armonicos_vl2_armonico_11_vl2:\n",
      "2025-01-05 21:03:15,454 - __main__ - INFO - - Valores únicos: 5\n",
      "2025-01-05 21:03:15,454 - INFO - - Valores únicos: 5\n",
      "2025-01-05 21:03:15,459 - __main__ - INFO - - Muestra valores: [ 1.68724889  0.28673229 -1.11378431 -2.51430092  3.08776549]\n",
      "2025-01-05 21:03:15,459 - INFO - - Muestra valores: [ 1.68724889  0.28673229 -1.11378431 -2.51430092  3.08776549]\n",
      "2025-01-05 21:03:15,461 - __main__ - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:15,461 - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:15,467 - __main__ - WARNING - Variable armonicos_vl2_armonico_11_vl2 tiene ratio de valores únicos muy bajo (0.000700)\n",
      "2025-01-05 21:03:15,467 - WARNING - Variable armonicos_vl2_armonico_11_vl2 tiene ratio de valores únicos muy bajo (0.000700)\n",
      "2025-01-05 21:03:15,471 - __main__ - WARNING - Variable armonicos_vl2_armonico_11_vl2 no pasó validación inicial\n",
      "2025-01-05 21:03:15,471 - WARNING - Variable armonicos_vl2_armonico_11_vl2 no pasó validación inicial\n",
      "2025-01-05 21:03:15,473 - __main__ - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:15,473 - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:15,476 - __main__ - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:15,476 - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:15,479 - __main__ - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:15,479 - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:15,481 - __main__ - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:15,481 - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:15,484 - __main__ - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:15,484 - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:15,486 - __main__ - WARNING - Variable descartada: armonicos_vl2_armonico_11_vl2\n",
      "2025-01-05 21:03:15,486 - WARNING - Variable descartada: armonicos_vl2_armonico_11_vl2\n",
      "2025-01-05 21:03:15,488 - __main__ - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:15,488 - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:15,493 - __main__ - INFO - \n",
      "Analizando armonicos_vl2_armonico_13_vl2:\n",
      "2025-01-05 21:03:15,493 - INFO - \n",
      "Analizando armonicos_vl2_armonico_13_vl2:\n",
      "2025-01-05 21:03:15,497 - __main__ - INFO - - Valores únicos: 3\n",
      "2025-01-05 21:03:15,497 - INFO - - Valores únicos: 3\n",
      "2025-01-05 21:03:15,500 - __main__ - INFO - - Muestra valores: [ 1.79482892 -0.47364423  4.06330208]\n",
      "2025-01-05 21:03:15,500 - INFO - - Muestra valores: [ 1.79482892 -0.47364423  4.06330208]\n",
      "2025-01-05 21:03:15,502 - __main__ - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:15,502 - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:15,509 - __main__ - WARNING - Variable armonicos_vl2_armonico_13_vl2 tiene muy pocos valores únicos (3)\n",
      "2025-01-05 21:03:15,509 - WARNING - Variable armonicos_vl2_armonico_13_vl2 tiene muy pocos valores únicos (3)\n",
      "2025-01-05 21:03:15,512 - __main__ - WARNING - Variable armonicos_vl2_armonico_13_vl2 no pasó validación inicial\n",
      "2025-01-05 21:03:15,512 - WARNING - Variable armonicos_vl2_armonico_13_vl2 no pasó validación inicial\n",
      "2025-01-05 21:03:15,514 - __main__ - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:15,514 - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:15,517 - __main__ - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:15,517 - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:15,519 - __main__ - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:15,519 - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:15,522 - __main__ - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:15,522 - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:15,523 - __main__ - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:15,523 - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:15,526 - __main__ - WARNING - Variable descartada: armonicos_vl2_armonico_13_vl2\n",
      "2025-01-05 21:03:15,526 - WARNING - Variable descartada: armonicos_vl2_armonico_13_vl2\n",
      "2025-01-05 21:03:15,528 - __main__ - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:15,528 - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:15,538 - __main__ - INFO - \n",
      "Analizando armonicos_vl3_armonico_2_vl3:\n",
      "2025-01-05 21:03:15,538 - INFO - \n",
      "Analizando armonicos_vl3_armonico_2_vl3:\n",
      "2025-01-05 21:03:15,540 - __main__ - INFO - - Valores únicos: 3\n",
      "2025-01-05 21:03:15,540 - INFO - - Valores únicos: 3\n",
      "2025-01-05 21:03:15,545 - __main__ - INFO - - Muestra valores: [-3.36289241e-02  4.36289433e+01  2.17976572e+01]\n",
      "2025-01-05 21:03:15,545 - INFO - - Muestra valores: [-3.36289241e-02  4.36289433e+01  2.17976572e+01]\n",
      "2025-01-05 21:03:15,548 - __main__ - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:15,548 - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:15,551 - __main__ - WARNING - Variable armonicos_vl3_armonico_2_vl3 tiene muy pocos valores únicos (3)\n",
      "2025-01-05 21:03:15,551 - WARNING - Variable armonicos_vl3_armonico_2_vl3 tiene muy pocos valores únicos (3)\n",
      "2025-01-05 21:03:15,553 - __main__ - WARNING - Variable armonicos_vl3_armonico_2_vl3 no pasó validación inicial\n",
      "2025-01-05 21:03:15,553 - WARNING - Variable armonicos_vl3_armonico_2_vl3 no pasó validación inicial\n",
      "2025-01-05 21:03:15,557 - __main__ - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:15,557 - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:15,567 - __main__ - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:15,567 - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:15,577 - __main__ - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:15,577 - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:15,582 - __main__ - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:15,582 - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:15,588 - __main__ - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:15,588 - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:15,650 - __main__ - WARNING - Variable descartada: armonicos_vl3_armonico_2_vl3\n",
      "2025-01-05 21:03:15,650 - WARNING - Variable descartada: armonicos_vl3_armonico_2_vl3\n",
      "2025-01-05 21:03:15,710 - __main__ - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:15,710 - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:15,732 - __main__ - INFO - \n",
      "Analizando armonicos_vl3_armonico_3_vl3:\n",
      "2025-01-05 21:03:15,732 - INFO - \n",
      "Analizando armonicos_vl3_armonico_3_vl3:\n",
      "2025-01-05 21:03:15,738 - __main__ - INFO - - Valores únicos: 6\n",
      "2025-01-05 21:03:15,738 - INFO - - Valores únicos: 6\n",
      "2025-01-05 21:03:15,747 - __main__ - INFO - - Muestra valores: [ 0.23356746  1.13077308 -0.66363815 -1.56084377  2.9251843 ]\n",
      "2025-01-05 21:03:15,747 - INFO - - Muestra valores: [ 0.23356746  1.13077308 -0.66363815 -1.56084377  2.9251843 ]\n",
      "2025-01-05 21:03:15,749 - __main__ - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:15,749 - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:15,750 - __main__ - WARNING - Variable armonicos_vl3_armonico_3_vl3 tiene ratio de valores únicos muy bajo (0.000840)\n",
      "2025-01-05 21:03:15,750 - WARNING - Variable armonicos_vl3_armonico_3_vl3 tiene ratio de valores únicos muy bajo (0.000840)\n",
      "2025-01-05 21:03:15,751 - __main__ - WARNING - Variable armonicos_vl3_armonico_3_vl3 no pasó validación inicial\n",
      "2025-01-05 21:03:15,751 - WARNING - Variable armonicos_vl3_armonico_3_vl3 no pasó validación inicial\n",
      "2025-01-05 21:03:15,752 - __main__ - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:15,752 - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:15,754 - __main__ - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:15,754 - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:15,755 - __main__ - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:15,755 - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:15,757 - __main__ - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:15,757 - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:15,758 - __main__ - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:15,758 - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:15,759 - __main__ - WARNING - Variable descartada: armonicos_vl3_armonico_3_vl3\n",
      "2025-01-05 21:03:15,759 - WARNING - Variable descartada: armonicos_vl3_armonico_3_vl3\n",
      "2025-01-05 21:03:15,761 - __main__ - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:15,761 - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:15,766 - __main__ - INFO - \n",
      "Analizando armonicos_vl3_armonico_5_vl3:\n",
      "2025-01-05 21:03:15,766 - INFO - \n",
      "Analizando armonicos_vl3_armonico_5_vl3:\n",
      "2025-01-05 21:03:15,770 - __main__ - INFO - - Valores únicos: 17\n",
      "2025-01-05 21:03:15,770 - INFO - - Valores únicos: 17\n",
      "2025-01-05 21:03:15,772 - __main__ - INFO - - Muestra valores: [ 0.18732941 -0.09153641 -0.37040222 -0.64926804  0.46619523]\n",
      "2025-01-05 21:03:15,772 - INFO - - Muestra valores: [ 0.18732941 -0.09153641 -0.37040222 -0.64926804  0.46619523]\n",
      "2025-01-05 21:03:15,778 - __main__ - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:15,778 - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:15,824 - __main__ - INFO - - variance_score: 0.0016502860249304233\n",
      "2025-01-05 21:03:15,824 - INFO - - variance_score: 0.0016502860249304233\n",
      "2025-01-05 21:03:15,829 - __main__ - INFO - - stability_score: 0.8952755682245627\n",
      "2025-01-05 21:03:15,829 - INFO - - stability_score: 0.8952755682245627\n",
      "2025-01-05 21:03:15,864 - __main__ - INFO - - trend_score: 0.00026316491400011065\n",
      "2025-01-05 21:03:15,864 - INFO - - trend_score: 0.00026316491400011065\n",
      "2025-01-05 21:03:15,922 - __main__ - INFO - - correlation_score: 0.40978661953479556\n",
      "2025-01-05 21:03:15,922 - INFO - - correlation_score: 0.40978661953479556\n",
      "2025-01-05 21:03:15,927 - __main__ - INFO - - final_score: 0.3510877131646071\n",
      "2025-01-05 21:03:15,927 - INFO - - final_score: 0.3510877131646071\n",
      "2025-01-05 21:03:15,929 - __main__ - INFO - \n",
      "Analizando armonicos_vl3_armonico_7_vl3:\n",
      "2025-01-05 21:03:15,929 - INFO - \n",
      "Analizando armonicos_vl3_armonico_7_vl3:\n",
      "2025-01-05 21:03:15,930 - __main__ - INFO - - Valores únicos: 12\n",
      "2025-01-05 21:03:15,930 - INFO - - Valores únicos: 12\n",
      "2025-01-05 21:03:15,937 - __main__ - INFO - - Muestra valores: [ 0.05687679  0.47951695  0.90215711  1.32479726 -0.36576336]\n",
      "2025-01-05 21:03:15,937 - INFO - - Muestra valores: [ 0.05687679  0.47951695  0.90215711  1.32479726 -0.36576336]\n",
      "2025-01-05 21:03:15,940 - __main__ - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:15,940 - INFO - - Varianza: 1.000140056022409\n",
      "2025-01-05 21:03:15,977 - __main__ - INFO - - variance_score: 0.001164907782303828\n",
      "2025-01-05 21:03:15,977 - INFO - - variance_score: 0.001164907782303828\n",
      "2025-01-05 21:03:15,996 - __main__ - INFO - - stability_score: 0.841545654980141\n",
      "2025-01-05 21:03:15,996 - INFO - - stability_score: 0.841545654980141\n",
      "2025-01-05 21:03:16,018 - __main__ - INFO - - trend_score: 1.1961723267098085e-05\n",
      "2025-01-05 21:03:16,018 - INFO - - trend_score: 1.1961723267098085e-05\n",
      "2025-01-05 21:03:16,063 - __main__ - INFO - - correlation_score: 0.2954342259544376\n",
      "2025-01-05 21:03:16,063 - INFO - - correlation_score: 0.2954342259544376\n",
      "2025-01-05 21:03:16,075 - __main__ - INFO - - final_score: 0.31190240636427435\n",
      "2025-01-05 21:03:16,075 - INFO - - final_score: 0.31190240636427435\n",
      "2025-01-05 21:03:16,090 - __main__ - INFO - \n",
      "Analizando armonicos_vl3_armonico_9_vl3:\n",
      "2025-01-05 21:03:16,090 - INFO - \n",
      "Analizando armonicos_vl3_armonico_9_vl3:\n",
      "2025-01-05 21:03:16,098 - __main__ - INFO - - Valores únicos: 2\n",
      "2025-01-05 21:03:16,098 - INFO - - Valores únicos: 2\n",
      "2025-01-05 21:03:16,100 - __main__ - INFO - - Muestra valores: [-1.67377203e-02  5.97452927e+01]\n",
      "2025-01-05 21:03:16,100 - INFO - - Muestra valores: [-1.67377203e-02  5.97452927e+01]\n",
      "2025-01-05 21:03:16,103 - __main__ - INFO - - Varianza: 1.0001400560224092\n",
      "2025-01-05 21:03:16,103 - INFO - - Varianza: 1.0001400560224092\n",
      "2025-01-05 21:03:16,107 - __main__ - WARNING - Variable armonicos_vl3_armonico_9_vl3 tiene muy pocos valores únicos (2)\n",
      "2025-01-05 21:03:16,107 - WARNING - Variable armonicos_vl3_armonico_9_vl3 tiene muy pocos valores únicos (2)\n",
      "2025-01-05 21:03:16,111 - __main__ - WARNING - Variable armonicos_vl3_armonico_9_vl3 no pasó validación inicial\n",
      "2025-01-05 21:03:16,111 - WARNING - Variable armonicos_vl3_armonico_9_vl3 no pasó validación inicial\n",
      "2025-01-05 21:03:16,114 - __main__ - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:16,114 - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:16,116 - __main__ - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:16,116 - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:16,119 - __main__ - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:16,119 - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:16,122 - __main__ - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:16,122 - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:16,125 - __main__ - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:16,125 - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:16,130 - __main__ - WARNING - Variable descartada: armonicos_vl3_armonico_9_vl3\n",
      "2025-01-05 21:03:16,130 - WARNING - Variable descartada: armonicos_vl3_armonico_9_vl3\n",
      "2025-01-05 21:03:16,132 - __main__ - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:16,132 - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:16,137 - __main__ - INFO - \n",
      "Analizando armonicos_vl3_armonico_11_vl3:\n",
      "2025-01-05 21:03:16,137 - INFO - \n",
      "Analizando armonicos_vl3_armonico_11_vl3:\n",
      "2025-01-05 21:03:16,140 - __main__ - INFO - - Valores únicos: 4\n",
      "2025-01-05 21:03:16,140 - INFO - - Valores únicos: 4\n",
      "2025-01-05 21:03:16,151 - __main__ - INFO - - Muestra valores: [ 0.86363548 -0.35110176 -1.565839    2.07837272]\n",
      "2025-01-05 21:03:16,151 - INFO - - Muestra valores: [ 0.86363548 -0.35110176 -1.565839    2.07837272]\n",
      "2025-01-05 21:03:16,155 - __main__ - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:16,155 - INFO - - Varianza: 1.0001400560224087\n",
      "2025-01-05 21:03:16,256 - __main__ - WARNING - Variable armonicos_vl3_armonico_11_vl3 tiene ratio de valores únicos muy bajo (0.000560)\n",
      "2025-01-05 21:03:16,256 - WARNING - Variable armonicos_vl3_armonico_11_vl3 tiene ratio de valores únicos muy bajo (0.000560)\n",
      "2025-01-05 21:03:16,283 - __main__ - WARNING - Variable armonicos_vl3_armonico_11_vl3 no pasó validación inicial\n",
      "2025-01-05 21:03:16,283 - WARNING - Variable armonicos_vl3_armonico_11_vl3 no pasó validación inicial\n",
      "2025-01-05 21:03:16,299 - __main__ - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:16,299 - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:16,313 - __main__ - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:16,313 - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:16,318 - __main__ - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:16,318 - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:16,322 - __main__ - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:16,322 - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:16,328 - __main__ - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:16,328 - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:16,332 - __main__ - WARNING - Variable descartada: armonicos_vl3_armonico_11_vl3\n",
      "2025-01-05 21:03:16,332 - WARNING - Variable descartada: armonicos_vl3_armonico_11_vl3\n",
      "2025-01-05 21:03:16,338 - __main__ - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:16,338 - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:16,345 - __main__ - INFO - \n",
      "Analizando armonicos_vl3_armonico_13_vl3:\n",
      "2025-01-05 21:03:16,345 - INFO - \n",
      "Analizando armonicos_vl3_armonico_13_vl3:\n",
      "2025-01-05 21:03:16,351 - __main__ - INFO - - Valores únicos: 3\n",
      "2025-01-05 21:03:16,351 - INFO - - Valores únicos: 3\n",
      "2025-01-05 21:03:16,356 - __main__ - INFO - - Muestra valores: [-0.05824387 15.93865846 31.9355608 ]\n",
      "2025-01-05 21:03:16,356 - INFO - - Muestra valores: [-0.05824387 15.93865846 31.9355608 ]\n",
      "2025-01-05 21:03:16,360 - __main__ - INFO - - Varianza: 1.0001400560224094\n",
      "2025-01-05 21:03:16,360 - INFO - - Varianza: 1.0001400560224094\n",
      "2025-01-05 21:03:16,365 - __main__ - WARNING - Variable armonicos_vl3_armonico_13_vl3 tiene muy pocos valores únicos (3)\n",
      "2025-01-05 21:03:16,365 - WARNING - Variable armonicos_vl3_armonico_13_vl3 tiene muy pocos valores únicos (3)\n",
      "2025-01-05 21:03:16,368 - __main__ - WARNING - Variable armonicos_vl3_armonico_13_vl3 no pasó validación inicial\n",
      "2025-01-05 21:03:16,368 - WARNING - Variable armonicos_vl3_armonico_13_vl3 no pasó validación inicial\n",
      "2025-01-05 21:03:16,371 - __main__ - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:16,371 - INFO - - variance_score: 0.0\n",
      "2025-01-05 21:03:16,372 - __main__ - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:16,372 - INFO - - stability_score: 0.0\n",
      "2025-01-05 21:03:16,377 - __main__ - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:16,377 - INFO - - trend_score: 0.0\n",
      "2025-01-05 21:03:16,380 - __main__ - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:16,380 - INFO - - correlation_score: 0.0\n",
      "2025-01-05 21:03:16,382 - __main__ - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:16,382 - INFO - - final_score: 0.0\n",
      "2025-01-05 21:03:16,388 - __main__ - WARNING - Variable descartada: armonicos_vl3_armonico_13_vl3\n",
      "2025-01-05 21:03:16,388 - WARNING - Variable descartada: armonicos_vl3_armonico_13_vl3\n",
      "2025-01-05 21:03:16,392 - __main__ - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:16,392 - WARNING - Razón: Varianza nula\n",
      "2025-01-05 21:03:16,397 - __main__ - INFO - Variables excluidas de categorización: ['armonicos_il1_armonico_11_il1', 'armonicos_il1_armonico_13_il1', 'armonicos_il2_armonico_9_il2', 'armonicos_vl1_armonico_11_vl1', 'armonicos_vl1_armonico_13_vl1', 'armonicos_vl1_armonico_2_vl1', 'armonicos_vl1_armonico_3_vl1', 'armonicos_vl1_armonico_9_vl1', 'armonicos_vl2_armonico_11_vl2', 'armonicos_vl2_armonico_13_vl2', 'armonicos_vl2_armonico_2_vl2', 'armonicos_vl2_armonico_3_vl2', 'armonicos_vl2_armonico_9_vl2', 'armonicos_vl3_armonico_11_vl3', 'armonicos_vl3_armonico_13_vl3', 'armonicos_vl3_armonico_2_vl3', 'armonicos_vl3_armonico_3_vl3', 'armonicos_vl3_armonico_9_vl3']\n",
      "2025-01-05 21:03:16,397 - INFO - Variables excluidas de categorización: ['armonicos_il1_armonico_11_il1', 'armonicos_il1_armonico_13_il1', 'armonicos_il2_armonico_9_il2', 'armonicos_vl1_armonico_11_vl1', 'armonicos_vl1_armonico_13_vl1', 'armonicos_vl1_armonico_2_vl1', 'armonicos_vl1_armonico_3_vl1', 'armonicos_vl1_armonico_9_vl1', 'armonicos_vl2_armonico_11_vl2', 'armonicos_vl2_armonico_13_vl2', 'armonicos_vl2_armonico_2_vl2', 'armonicos_vl2_armonico_3_vl2', 'armonicos_vl2_armonico_9_vl2', 'armonicos_vl3_armonico_11_vl3', 'armonicos_vl3_armonico_13_vl3', 'armonicos_vl3_armonico_2_vl3', 'armonicos_vl3_armonico_3_vl3', 'armonicos_vl3_armonico_9_vl3']\n",
      "2025-01-05 21:03:16,408 - __main__ - INFO - \n",
      "            === RESUMEN FINAL DE CATEGORIZACIÓN ===\n",
      "            Total variables originales: 56\n",
      "            Variables analizadas: 38\n",
      "            Variables removidas: 18\n",
      "            Variables válidas: 38\n",
      "            Variables críticas: 8\n",
      "            Variables en monitoreo: 11\n",
      "            Variables descartadas: ['armonicos_il1_armonico_11_il1', 'armonicos_il1_armonico_13_il1', 'armonicos_il2_armonico_9_il2', 'armonicos_vl1_armonico_11_vl1', 'armonicos_vl1_armonico_13_vl1', 'armonicos_vl1_armonico_2_vl1', 'armonicos_vl1_armonico_3_vl1', 'armonicos_vl1_armonico_9_vl1', 'armonicos_vl2_armonico_11_vl2', 'armonicos_vl2_armonico_13_vl2', 'armonicos_vl2_armonico_2_vl2', 'armonicos_vl2_armonico_3_vl2', 'armonicos_vl2_armonico_9_vl2', 'armonicos_vl3_armonico_11_vl3', 'armonicos_vl3_armonico_13_vl3', 'armonicos_vl3_armonico_2_vl3', 'armonicos_vl3_armonico_3_vl3', 'armonicos_vl3_armonico_9_vl3']\n",
      "            =====================================\n",
      "            \n",
      "2025-01-05 21:03:16,408 - INFO - \n",
      "            === RESUMEN FINAL DE CATEGORIZACIÓN ===\n",
      "            Total variables originales: 56\n",
      "            Variables analizadas: 38\n",
      "            Variables removidas: 18\n",
      "            Variables válidas: 38\n",
      "            Variables críticas: 8\n",
      "            Variables en monitoreo: 11\n",
      "            Variables descartadas: ['armonicos_il1_armonico_11_il1', 'armonicos_il1_armonico_13_il1', 'armonicos_il2_armonico_9_il2', 'armonicos_vl1_armonico_11_vl1', 'armonicos_vl1_armonico_13_vl1', 'armonicos_vl1_armonico_2_vl1', 'armonicos_vl1_armonico_3_vl1', 'armonicos_vl1_armonico_9_vl1', 'armonicos_vl2_armonico_11_vl2', 'armonicos_vl2_armonico_13_vl2', 'armonicos_vl2_armonico_2_vl2', 'armonicos_vl2_armonico_3_vl2', 'armonicos_vl2_armonico_9_vl2', 'armonicos_vl3_armonico_11_vl3', 'armonicos_vl3_armonico_13_vl3', 'armonicos_vl3_armonico_2_vl3', 'armonicos_vl3_armonico_3_vl3', 'armonicos_vl3_armonico_9_vl3']\n",
      "            =====================================\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Fase 2: Identificación de Variables Clave\n",
    "========================================\n",
    "\n",
    "Objetivos:\n",
    "1. Identificar y registrar variables clave para prognosis en PostgreSQL.\n",
    "2. Implementar un sistema robusto de selección y seguimiento de variables.\n",
    "3. Mantener histórico de cambios en las variables seleccionadas.\n",
    "4. Generar reportes detallados de análisis.\n",
    "\n",
    "Características:\n",
    "- Análisis multifactorial de variables.\n",
    "- Sistema de puntuación ponderado.\n",
    "- Registro histórico con timestamps.\n",
    "- Validación y logging exhaustivo.\n",
    "- Creación robusta de la base de datos y tablas.\n",
    "\"\"\"\n",
    "\n",
    "# Importaciones necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import OperationalError, ProgrammingError\n",
    "from psycopg2 import connect\n",
    "from typing import Dict, Any, List\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "class DatabaseSetup:\n",
    "    @staticmethod\n",
    "    def create_database_if_not_exists(config: Dict[str, str]):\n",
    "        \"\"\"Crea la base de datos si no existe.\"\"\"\n",
    "        try:\n",
    "            connection = connect(\n",
    "                dbname=\"postgres\",\n",
    "                user=config[\"user\"],\n",
    "                password=config[\"password\"],\n",
    "                host=config[\"host\"],\n",
    "                port=config[\"port\"]\n",
    "            )\n",
    "            connection.autocommit = True\n",
    "            cursor = connection.cursor()\n",
    "            cursor.execute(f\"SELECT 1 FROM pg_database WHERE datname = '{config['database']}';\")\n",
    "            if not cursor.fetchone():\n",
    "                cursor.execute(f\"CREATE DATABASE {config['database']};\")\n",
    "                logging.info(f\"Base de datos '{config['database']}' creada exitosamente.\")\n",
    "            cursor.close()\n",
    "            connection.close()\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error al crear la base de datos: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "class KeyVariableSelector:\n",
    "    def __init__(self, db_engine, table_name: str):\n",
    "        \"\"\"Inicializa el selector de variables clave.\"\"\"\n",
    "        self.db_engine = db_engine\n",
    "        self.table_name = table_name\n",
    "        self.mapping_table = \"variable_mapping\"\n",
    "        self.history_table = \"selected_variables_history\"\n",
    "        self.analysis_table = \"variable_analysis_history\"\n",
    "        self.logger = self._setup_logging()\n",
    "        self.variable_mapping = {}\n",
    "        self.results = {\n",
    "            \"selected_variables\": {},\n",
    "            \"variable_scores\": {},\n",
    "            \"removed_variables\": [],\n",
    "            \"new_variables\": [],\n",
    "            \"analysis_timestamp\": datetime.now()\n",
    "        }\n",
    "        self._validate_db_connection()\n",
    "        self._create_tables()\n",
    "\n",
    "    def _setup_logging(self):\n",
    "        \"\"\"Configura el sistema de logging.\"\"\"\n",
    "        logger = logging.getLogger(__name__)\n",
    "        if not logger.handlers:\n",
    "            handler = logging.StreamHandler()\n",
    "            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "            handler.setFormatter(formatter)\n",
    "            logger.addHandler(handler)\n",
    "            logger.setLevel(logging.INFO)\n",
    "        return logger\n",
    "\n",
    "    def _validate_db_connection(self):\n",
    "        \"\"\"Valida la conexión con la base de datos.\"\"\"\n",
    "        try:\n",
    "            with self.db_engine.connect() as conn:\n",
    "                self.logger.info(\"Conexión con la base de datos validada correctamente.\")\n",
    "        except OperationalError as e:\n",
    "            self.logger.error(f\"Error al conectar con la base de datos: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _create_tables(self):\n",
    "        \"\"\"Crea las tablas necesarias en la base de datos.\"\"\"\n",
    "        try:\n",
    "            with self.db_engine.connect() as conn:\n",
    "                with conn.begin():\n",
    "                    # Tabla para histórico de variables seleccionadas\n",
    "                    conn.execute(text(f\"\"\"\n",
    "                        CREATE TABLE IF NOT EXISTS {self.history_table} (\n",
    "                            id SERIAL PRIMARY KEY,\n",
    "                            variable_name TEXT NOT NULL,\n",
    "                            original_name TEXT NOT NULL,\n",
    "                            importance_score FLOAT NOT NULL,\n",
    "                            category TEXT NOT NULL,\n",
    "                            timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "                            UNIQUE(variable_name, timestamp)\n",
    "                        );\n",
    "                    \"\"\"))\n",
    "                    \n",
    "                    # Tabla para histórico de análisis\n",
    "                    conn.execute(text(f\"\"\"\n",
    "                        CREATE TABLE IF NOT EXISTS {self.analysis_table} (\n",
    "                            id SERIAL PRIMARY KEY,\n",
    "                            variable_name TEXT NOT NULL,\n",
    "                            original_name TEXT NOT NULL,\n",
    "                            variance_score FLOAT,\n",
    "                            stability_score FLOAT,\n",
    "                            trend_score FLOAT,\n",
    "                            correlation_score FLOAT,\n",
    "                            final_score FLOAT,\n",
    "                            timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "                        );\n",
    "                    \"\"\"))\n",
    "            self.logger.info(\"Tablas creadas/verificadas exitosamente.\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error creando tablas: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def load_data(self) -> pd.DataFrame:\n",
    "        \"\"\"Carga datos y mantiene trazabilidad de nombres.\"\"\"\n",
    "        try:\n",
    "            with self.db_engine.connect() as conn:\n",
    "                # Cargar datos normalizados\n",
    "                query = f\"SELECT * FROM {self.table_name};\"\n",
    "                data = pd.read_sql_query(query, conn)\n",
    "                \n",
    "                # Cargar mapeo de variables\n",
    "                mapping_query = f\"SELECT normalized_name, original_name FROM {self.mapping_table};\"\n",
    "                variable_mapping = pd.read_sql_query(mapping_query, conn)\n",
    "                \n",
    "            # Validaciones\n",
    "            if data.empty:\n",
    "                raise ValueError(\"No se encontraron datos en la tabla.\")\n",
    "            if 'timestamp' not in data.columns:\n",
    "                raise ValueError(\"La tabla debe contener una columna 'timestamp'.\")\n",
    "                \n",
    "            # Configurar índice temporal\n",
    "            data.set_index('timestamp', inplace=True)\n",
    "            \n",
    "            # Guardar mapeo para uso posterior\n",
    "            self.variable_mapping = dict(zip(variable_mapping['normalized_name'], \n",
    "                                          variable_mapping['original_name']))\n",
    "            \n",
    "            self.logger.info(f\"Datos cargados: {data.shape[0]} filas y {data.shape[1]} columnas.\")\n",
    "            return data\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error al cargar datos: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def calculate_variable_score(self, series: pd.Series) -> float:\n",
    "        \"\"\"Calcula el score inicial de una variable y valida si es utilizable.\"\"\"\n",
    "        try:\n",
    "            # 1. Verificación de valores únicos sin NaN\n",
    "            unique_values = series.dropna().unique()\n",
    "            n_unique = len(unique_values)\n",
    "            total_values = len(series.dropna())\n",
    "            \n",
    "            self.logger.debug(f\"Evaluando {series.name}:\")\n",
    "            self.logger.debug(f\"- Valores únicos: {n_unique}\")\n",
    "            \n",
    "            # Filtrar variables con muy pocos valores únicos\n",
    "            if n_unique <= 3:  # Aumentamos el umbral mínimo de valores únicos\n",
    "                self.logger.warning(f\"Variable {series.name} tiene muy pocos valores únicos ({n_unique})\")\n",
    "                return 0.0\n",
    "                \n",
    "            # Calcular ratio de valores únicos\n",
    "            unique_ratio = n_unique / total_values\n",
    "            if unique_ratio < 0.001:  # Si menos del 0.1% de valores son únicos\n",
    "                self.logger.warning(f\"Variable {series.name} tiene ratio de valores únicos muy bajo ({unique_ratio:.6f})\")\n",
    "                return 0.0\n",
    "                \n",
    "            # 2. Verificación de varianza\n",
    "            variance = series.var()\n",
    "            self.logger.debug(f\"- Varianza: {variance}\")\n",
    "            \n",
    "            if abs(variance) < 1e-6:  # Aumentamos el umbral de varianza mínima\n",
    "                self.logger.warning(f\"Variable {series.name} tiene varianza prácticamente nula ({variance})\")\n",
    "                return 0.0\n",
    "                \n",
    "            # 3. Cálculo del score considerando tanto varianza como diversidad de valores\n",
    "            score = float(np.log1p(abs(variance))) * unique_ratio\n",
    "            return score\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error calculando score para {series.name}: {str(e)}\")\n",
    "            return 0.0\n",
    "    def _analyze_single_variable(self, series: pd.Series, data: pd.DataFrame) -> Dict[str, float]:\n",
    "        \"\"\"Analiza una variable individual con múltiples métricas.\"\"\"\n",
    "        try:\n",
    "            # 1. Score inicial de variabilidad\n",
    "            variance_score = self.calculate_variable_score(series)\n",
    "            \n",
    "            # Si no pasa la validación inicial, retornamos scores en cero\n",
    "            if variance_score == 0:\n",
    "                self.logger.warning(f\"Variable {series.name} no pasó validación inicial\")\n",
    "                return self._get_zero_scores()\n",
    "\n",
    "            # 2. Cálculo de métricas adicionales\n",
    "            try:\n",
    "                # Estabilidad temporal\n",
    "                rolling_std = series.rolling(window=24, min_periods=1).std().mean()\n",
    "                total_std = series.std()\n",
    "                stability_score = float(1 - ( rolling_std / total_std) if total_std > 0 else 0)\n",
    "                    # Tendencia\n",
    "                trend_score = float(abs(np.polyfit(np.arange(len(series)), series, 1)[0]))\n",
    "                    # Correlación con otras variables\n",
    "                correlations = data.corrwith(series).abs()\n",
    "                correlation_score = float(correlations.mean())\n",
    "                    # 3. Score final ponderado\n",
    "                scores = {\n",
    "                    \"variance_score\": variance_score,\n",
    "                    \"stability_score\": stability_score,\n",
    "                    \"trend_score\": trend_score,\n",
    "                    \"correlation_score\": correlation_score\n",
    "                }\n",
    "                \n",
    "                weights = {\n",
    "                    \"variance_score\": 0.3,\n",
    "                    \"stability_score\": 0.3,\n",
    "                    \"trend_score\": 0.2,\n",
    "                    \"correlation_score\": 0.2\n",
    "                }\n",
    "                \n",
    "                final_score = sum(score * weights[name] for name, score in scores.items())\n",
    "                return {**scores, \"final_score\": float(final_score)}\n",
    "            except Exception as calc_error:\n",
    "                self.logger.error(f\"Error en cálculo de métricas para {series.name}: {calc_error}\")\n",
    "                return self._get_zero_scores()\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en análisis de {series.name}: {str(e)}\")\n",
    "            return self._get_zero_scores()\n",
    "    def analyze_variables(self, data: pd.DataFrame) -> Dict[str, Any]:\n",
    "        \"\"\"Realiza análisis completo de variables.\"\"\"\n",
    "        try:\n",
    "            self.logger.info(\"Iniciando análisis de variables...\")\n",
    "            analysis_results = []\n",
    "            constant_variables = []\n",
    "            scores_dict = {}\n",
    "                # Análisis individual de variables\n",
    "            for col in data.columns:\n",
    "                series = data[col].copy()\n",
    "                \n",
    "                # Estadísticas básicas para logging\n",
    "                unique_vals = series.dropna().unique()\n",
    "                variance = series.var()\n",
    "                self.logger.info(f\"\\nAnalizando {col}:\")\n",
    "                self.logger.info(f\"- Valores únicos: {len(unique_vals)}\")\n",
    "                self.logger.info(f\"- Muestra valores: {unique_vals[:5]}\")\n",
    "                self.logger.info(f\"- Varianza: {variance}\")\n",
    "                \n",
    "                # Análisis completo\n",
    "                scores = self._analyze_single_variable(series, data)\n",
    "                \n",
    "                # Logging de scores\n",
    "                for score_name, score_value in scores.items():\n",
    "                    self.logger.info(f\"- {score_name}: {score_value}\")\n",
    "                \n",
    "                # Clasificación de la variable\n",
    "                if scores[\"final_score\"] == 0:\n",
    "                    reason = \"Variable constante\" if len(unique_vals) <= 1 else \"Varianza nula\"\n",
    "                    value = str(series.iloc[0]) if not series.empty else \"NA\"\n",
    "                    \n",
    "                    self.logger.warning(f\"Variable descartada: {col}\")\n",
    "                    self.logger.warning(f\"Razón: {reason}\")\n",
    "                    \n",
    "                    constant_variables.append({\n",
    "                        \"variable\": col,\n",
    "                        \"reason\": reason,\n",
    "                        \"value\": value,\n",
    "                        \"variance\": float(variance)\n",
    "                    })\n",
    "                    continue\n",
    "                \n",
    "                # Registro de variables válidas\n",
    "                scores_dict[col] = scores[\"final_score\"]\n",
    "                analysis_results.append({\n",
    "                    \"variable_name\": col,\n",
    "                    \"original_name\": self.variable_mapping.get(col, col),\n",
    "                    **scores\n",
    "                })\n",
    "                # Actualización de resultados\n",
    "            self.results.update({\n",
    "                \"variable_scores\": scores_dict,\n",
    "                \"removed_variables\": constant_variables\n",
    "            })\n",
    "                # Proceso final\n",
    "            self._categorize_variables(data)\n",
    "            self._save_analysis_results(analysis_results)\n",
    "            self.validate_selected_variables()\n",
    "            \n",
    "            return self.results\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en análisis de variables: {str(e)}\")\n",
    "            raise\n",
    "    def _get_zero_scores(self) -> Dict[str, float]:\n",
    "        \"\"\"Retorna un diccionario con todos los scores en cero.\"\"\"\n",
    "        return {\n",
    "            \"variance_score\": 0.0,\n",
    "            \"stability_score\": 0.0,\n",
    "            \"trend_score\": 0.0,\n",
    "            \"correlation_score\": 0.0,\n",
    "            \"final_score\": 0.0\n",
    "        }\n",
    "\n",
    "    def _categorize_variables(self, data: pd.DataFrame):\n",
    "        \"\"\"Categoriza variables en críticas y monitoreo.\"\"\"\n",
    "        try:\n",
    "            # 1. Obtener scores y variables removidas\n",
    "            scores = pd.Series(self.results[\"variable_scores\"])\n",
    "            removed_vars = set(v[\"variable\"] for v in self.results.get(\"removed_variables\", []))\n",
    "            \n",
    "            # 2. Logging inicial de variables removidas\n",
    "            if removed_vars:\n",
    "                self.logger.info(f\"Variables excluidas de categorización: {sorted(list(removed_vars))}\")\n",
    "            \n",
    "            # 3. Filtrado estricto de variables válidas\n",
    "            valid_scores = scores[\n",
    "                (scores > 0) & (~scores.index.isin(removed_vars))\n",
    "            ]\n",
    "        \n",
    "            if valid_scores.empty:\n",
    "                self.logger.warning(\"No hay variables válidas para categorizar\")\n",
    "                return\n",
    "            \n",
    "            # 4. Verificación de seguridad\n",
    "            if set(valid_scores.index).intersection(removed_vars):\n",
    "                self.logger.error(\"¡ALERTA! Variables removidas encontradas en scores válidos\")\n",
    "                valid_scores = valid_scores[~valid_scores.index.isin(removed_vars)]\n",
    "            \n",
    "            if valid_scores.empty:\n",
    "                self.logger.warning(\"No hay variables válidas para categorizar\")\n",
    "                return\n",
    "            \n",
    "            # 5. Cálculo de umbrales y categorización\n",
    "            thresholds = {\n",
    "                \"critical\": valid_scores.quantile(0.8),\n",
    "                \"monitoring\": valid_scores.quantile(0.5)\n",
    "            }\n",
    "                # 6. Reset y categorización de variables\n",
    "            self.results[\"selected_variables\"] = {}\n",
    "            for var, score in valid_scores.items():\n",
    "                if score >= thresholds[\"critical\"]:\n",
    "                    category = \"critical\"\n",
    "                elif score >= thresholds[\"monitoring\"]:\n",
    "                    category = \"monitoring\"\n",
    "                else:\n",
    "                    continue\n",
    "                    \n",
    "                self.results[\"selected_variables\"][var] = {\n",
    "                    \"category\": category,\n",
    "                    \"score\": float(score),\n",
    "                    \"threshold_used\": thresholds[category],\n",
    "                    \"timestamp\": datetime.now().isoformat()\n",
    "                }\n",
    "                # 7. Registro de métricas finales\n",
    "            self.results[\"categorization_metrics\"] = {\n",
    "                \"total_variables\": len(data.columns),  # Total original\n",
    "                \"analyzed_variables\": len(scores),     # Variables analizadas\n",
    "                \"valid_variables\": len(valid_scores),  # Variables válidas\n",
    "                \"removed_variables\": len(removed_vars),# Variables removidas\n",
    "                \"critical_variables\": len([v for v in self.results[\"selected_variables\"].values() \n",
    "                                        if v[\"category\"] == \"critical\"]),\n",
    "                \"monitoring_variables\": len([v for v in self.results[\"selected_variables\"].values() \n",
    "                                            if v[\"category\"] == \"monitoring\"]),\n",
    "                \"thresholds\": thresholds,\n",
    "                \"removed_list\": sorted(list(removed_vars))\n",
    "            }\n",
    "                # 8. Logging detallado final\n",
    "            self.logger.info(f\"\"\"\n",
    "            === RESUMEN FINAL DE CATEGORIZACIÓN ===\n",
    "            Total variables originales: {self.results['categorization_metrics']['total_variables']}\n",
    "            Variables analizadas: {self.results['categorization_metrics']['analyzed_variables']}\n",
    "            Variables removidas: {self.results['categorization_metrics']['removed_variables']}\n",
    "            Variables válidas: {self.results['categorization_metrics']['valid_variables']}\n",
    "            Variables críticas: {self.results['categorization_metrics']['critical_variables']}\n",
    "            Variables en monitoreo: {self.results['categorization_metrics']['monitoring_variables']}\n",
    "            Variables descartadas: {self.results['categorization_metrics']['removed_list']}\n",
    "            =====================================\n",
    "            \"\"\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en categorización de variables: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def validate_selected_variables(self) -> bool:\n",
    "        \"\"\"Validación adicional de variables seleccionadas.\"\"\"\n",
    "        try:\n",
    "            for var, details in self.results[\"selected_variables\"].items():\n",
    "                if details[\"score\"] == 0:\n",
    "                    self.logger.error(f\"Variable {var} con score 0 detectada en selección\")\n",
    "                    del self.results[\"selected_variables\"][var]  # Se agregó 'del'\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en validación: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def _save_analysis_results(self, analysis_results: List[Dict[str, Any]]):\n",
    "        \"\"\"Guarda resultados detallados del análisis.\"\"\"\n",
    "        try:\n",
    "            with self.db_engine.connect() as conn:\n",
    "                with conn.begin():\n",
    "                    for result in analysis_results:\n",
    "                        result = {k: float(v) if isinstance(v, (np.float64, np.float32)) else v \n",
    "                                for k, v in result.items()}\n",
    "                        conn.execute(text(f\"\"\"\n",
    "                            INSERT INTO {self.analysis_table} \n",
    "                            (variable_name, original_name, variance_score, stability_score, \n",
    "                             trend_score, correlation_score, final_score)\n",
    "                            VALUES (:variable_name, :original_name, :variance_score, \n",
    "                                    :stability_score, :trend_score, :correlation_score, :final_score)\n",
    "                        \"\"\"), result)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error guardando análisis: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def save_results(self):\n",
    "        \"\"\"Guarda las variables seleccionadas manteniendo trazabilidad.\"\"\"\n",
    "        try:\n",
    "            with self.db_engine.connect() as conn:\n",
    "                with conn.begin():\n",
    "                    for var, details in self.results[\"selected_variables\"].items():\n",
    "                        # Usar nombre original en el registro\n",
    "                        original_name = self.variable_mapping.get(var, var)\n",
    "                        \n",
    "                        query = text(f\"\"\"\n",
    "                            INSERT INTO {self.history_table} \n",
    "                            (variable_name, original_name, importance_score, category)\n",
    "                            VALUES (:variable_name, :original_name, :importance_score, :category)\n",
    "                            ON CONFLICT (variable_name, timestamp)\n",
    "                            DO UPDATE SET\n",
    "                                importance_score = EXCLUDED.importance_score,\n",
    "                                category = EXCLUDED.category;\n",
    "                        \"\"\")\n",
    "                        \n",
    "                        conn.execute(query, {\n",
    "                            \"variable_name\": var,\n",
    "                            \"original_name\": original_name,\n",
    "                            \"importance_score\": float(details[\"score\"]),\n",
    "                            \"category\": details[\"category\"]\n",
    "                        })\n",
    "                        \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error al guardar resultados: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "# Ejecución\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        DB_CONFIG = {\n",
    "            \"user\": \"postgres\",\n",
    "            \"password\": \"elico\",\n",
    "            \"host\": \"localhost\",\n",
    "            \"port\": \"5432\",\n",
    "            \"database\": \"prognosis_db\"\n",
    "        }\n",
    "\n",
    "        # Crear la base de datos si no existe\n",
    "        DatabaseSetup.create_database_if_not_exists(DB_CONFIG)\n",
    "\n",
    "        # Crear el motor de conexión\n",
    "        DATABASE_URL = f\"postgresql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}\"\n",
    "        engine = create_engine(DATABASE_URL)\n",
    "        \n",
    "        # Ejecutar el flujo\n",
    "        selector = KeyVariableSelector(engine, \"normalized_data_table\")\n",
    "        data = selector.load_data()\n",
    "        selector.analyze_variables(data)\n",
    "        selector.save_results()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error ejecutando flujo: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-05 22:49:08,554 - INFO - Variables críticas identificadas: 8\n",
      "2025-01-05 22:49:08,555 - INFO - Iniciando procesamiento incremental de: tension_l2_v\n",
      "2025-01-05 22:49:08,559 - INFO - Iniciando procesamiento incremental de: tension_l3_v\n",
      "2025-01-05 22:49:08,569 - INFO - Iniciando procesamiento incremental de: tension_l1_l2_v\n",
      "2025-01-05 22:51:10,835 - DEBUG - input tempfile: /tmp/tmpng3_x0fd/1dbsrkwn.json\n",
      "2025-01-05 22:51:13,447 - DEBUG - input tempfile: /tmp/tmpng3_x0fd/_8cfel8_.json\n",
      "2025-01-05 22:51:13,761 - DEBUG - idx 0\n",
      "2025-01-05 22:51:14,035 - DEBUG - running CmdStan, num_threads: None\n",
      "2025-01-05 22:51:14,039 - DEBUG - CmdStan args: ['/home/elicoubuntu/Desktop/Industrial_Insigths/.venv/lib/python3.10/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=89452', 'data', 'file=/tmp/tmpng3_x0fd/1dbsrkwn.json', 'init=/tmp/tmpng3_x0fd/_8cfel8_.json', 'output', 'file=/tmp/tmpng3_x0fd/prophet_modelrpispkjw/prophet_model-20250105225113.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
      "22:51:14 - cmdstanpy - INFO - Chain [1] start processing\n",
      "2025-01-05 22:51:14,319 - INFO - Chain [1] start processing\n",
      "22:51:15 - cmdstanpy - INFO - Chain [1] done processing\n",
      "2025-01-05 22:51:15,293 - INFO - Chain [1] done processing\n",
      "2025-01-05 22:51:35,862 - INFO - Variable tension_l3_v procesada exitosamente\n",
      "2025-01-05 22:51:36,108 - INFO - Iniciando procesamiento incremental de: tension_l2_l3_v\n",
      "2025-01-05 22:51:37,601 - DEBUG - input tempfile: /tmp/tmpng3_x0fd/xhle3upg.json\n",
      "2025-01-05 22:51:38,292 - DEBUG - input tempfile: /tmp/tmpng3_x0fd/ju1vb1_j.json\n",
      "2025-01-05 22:51:38,308 - DEBUG - idx 0\n",
      "2025-01-05 22:51:38,375 - DEBUG - running CmdStan, num_threads: None\n",
      "2025-01-05 22:51:38,378 - DEBUG - CmdStan args: ['/home/elicoubuntu/Desktop/Industrial_Insigths/.venv/lib/python3.10/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=87038', 'data', 'file=/tmp/tmpng3_x0fd/xhle3upg.json', 'init=/tmp/tmpng3_x0fd/ju1vb1_j.json', 'output', 'file=/tmp/tmpng3_x0fd/prophet_model36dyhma2/prophet_model-20250105225138.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
      "22:51:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "2025-01-05 22:51:38,613 - INFO - Chain [1] start processing\n",
      "22:51:40 - cmdstanpy - INFO - Chain [1] done processing\n",
      "2025-01-05 22:51:40,208 - INFO - Chain [1] done processing\n",
      "2025-01-05 22:52:01,629 - INFO - Variable tension_l1_l2_v procesada exitosamente\n",
      "2025-01-05 22:52:01,641 - INFO - Iniciando procesamiento incremental de: tension_l3_l1_v\n",
      "2025-01-05 22:52:33,621 - DEBUG - input tempfile: /tmp/tmpng3_x0fd/79l9wzsy.json\n",
      "2025-01-05 22:52:36,523 - DEBUG - input tempfile: /tmp/tmpng3_x0fd/m8u3u7x5.json\n",
      "2025-01-05 22:52:36,884 - DEBUG - idx 0\n",
      "2025-01-05 22:52:37,445 - DEBUG - running CmdStan, num_threads: None\n",
      "2025-01-05 22:52:37,853 - DEBUG - CmdStan args: ['/home/elicoubuntu/Desktop/Industrial_Insigths/.venv/lib/python3.10/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=3927', 'data', 'file=/tmp/tmpng3_x0fd/79l9wzsy.json', 'init=/tmp/tmpng3_x0fd/m8u3u7x5.json', 'output', 'file=/tmp/tmpng3_x0fd/prophet_model_wihd211/prophet_model-20250105225236.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
      "22:52:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "2025-01-05 22:52:38,083 - INFO - Chain [1] start processing\n",
      "22:52:38 - cmdstanpy - INFO - Chain [1] done processing\n",
      "2025-01-05 22:52:38,933 - INFO - Chain [1] done processing\n",
      "2025-01-05 22:52:55,948 - INFO - Variable tension_l2_v procesada exitosamente\n",
      "2025-01-05 22:52:56,354 - INFO - Iniciando procesamiento incremental de: corriente_l1_a\n",
      "2025-01-05 22:54:08,802 - DEBUG - input tempfile: /tmp/tmpng3_x0fd/imq1qt01.json\n",
      "2025-01-05 22:54:10,369 - DEBUG - input tempfile: /tmp/tmpng3_x0fd/6zdo3gjn.json\n",
      "2025-01-05 22:54:10,613 - DEBUG - idx 0\n",
      "2025-01-05 22:54:10,687 - DEBUG - running CmdStan, num_threads: None\n",
      "2025-01-05 22:54:10,688 - DEBUG - CmdStan args: ['/home/elicoubuntu/Desktop/Industrial_Insigths/.venv/lib/python3.10/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=53226', 'data', 'file=/tmp/tmpng3_x0fd/imq1qt01.json', 'init=/tmp/tmpng3_x0fd/6zdo3gjn.json', 'output', 'file=/tmp/tmpng3_x0fd/prophet_modelnlt_2sc2/prophet_model-20250105225410.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
      "22:54:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "2025-01-05 22:54:11,313 - INFO - Chain [1] start processing\n",
      "22:54:11 - cmdstanpy - INFO - Chain [1] done processing\n",
      "2025-01-05 22:54:11,919 - INFO - Chain [1] done processing\n",
      "2025-01-05 22:54:18,642 - DEBUG - input tempfile: /tmp/tmpng3_x0fd/8bv2o836.json\n",
      "2025-01-05 22:54:20,188 - DEBUG - input tempfile: /tmp/tmpng3_x0fd/3mdmczbs.json\n",
      "2025-01-05 22:54:20,202 - DEBUG - idx 0\n",
      "2025-01-05 22:54:20,616 - DEBUG - running CmdStan, num_threads: None\n",
      "2025-01-05 22:54:20,621 - DEBUG - CmdStan args: ['/home/elicoubuntu/Desktop/Industrial_Insigths/.venv/lib/python3.10/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=76600', 'data', 'file=/tmp/tmpng3_x0fd/8bv2o836.json', 'init=/tmp/tmpng3_x0fd/3mdmczbs.json', 'output', 'file=/tmp/tmpng3_x0fd/prophet_model57dc41cs/prophet_model-20250105225420.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
      "22:54:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "2025-01-05 22:54:20,637 - INFO - Chain [1] start processing\n",
      "22:54:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      "2025-01-05 22:54:21,537 - INFO - Chain [1] done processing\n",
      "2025-01-05 22:54:26,736 - INFO - Variable tension_l2_l3_v procesada exitosamente\n",
      "2025-01-05 22:54:26,978 - INFO - Iniciando procesamiento incremental de: corriente_l2_a\n",
      "2025-01-05 22:54:30,604 - INFO - Variable tension_l3_l1_v procesada exitosamente\n",
      "2025-01-05 22:54:30,801 - INFO - Iniciando procesamiento incremental de: corriente_l3_a\n",
      "2025-01-05 22:55:18,183 - DEBUG - input tempfile: /tmp/tmpng3_x0fd/fgyib5k_.json\n",
      "2025-01-05 22:55:20,300 - DEBUG - input tempfile: /tmp/tmpng3_x0fd/xjydc7we.json\n",
      "2025-01-05 22:55:20,441 - DEBUG - idx 0\n",
      "2025-01-05 22:55:20,622 - DEBUG - running CmdStan, num_threads: None\n",
      "2025-01-05 22:55:20,677 - DEBUG - CmdStan args: ['/home/elicoubuntu/Desktop/Industrial_Insigths/.venv/lib/python3.10/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=15068', 'data', 'file=/tmp/tmpng3_x0fd/fgyib5k_.json', 'init=/tmp/tmpng3_x0fd/xjydc7we.json', 'output', 'file=/tmp/tmpng3_x0fd/prophet_model7xtzg8p2/prophet_model-20250105225520.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
      "22:55:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "2025-01-05 22:55:20,904 - INFO - Chain [1] start processing\n",
      "22:55:22 - cmdstanpy - INFO - Chain [1] done processing\n",
      "2025-01-05 22:55:22,043 - INFO - Chain [1] done processing\n",
      "2025-01-05 22:55:31,704 - INFO - Variable corriente_l1_a procesada exitosamente\n",
      "2025-01-05 22:55:54,357 - DEBUG - input tempfile: /tmp/tmpng3_x0fd/lgol1kax.json\n",
      "2025-01-05 22:55:54,733 - DEBUG - input tempfile: /tmp/tmpng3_x0fd/jun8abbc.json\n",
      "2025-01-05 22:55:54,811 - DEBUG - idx 0\n",
      "2025-01-05 22:55:54,970 - DEBUG - running CmdStan, num_threads: None\n",
      "2025-01-05 22:55:55,234 - DEBUG - CmdStan args: ['/home/elicoubuntu/Desktop/Industrial_Insigths/.venv/lib/python3.10/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=82607', 'data', 'file=/tmp/tmpng3_x0fd/lgol1kax.json', 'init=/tmp/tmpng3_x0fd/jun8abbc.json', 'output', 'file=/tmp/tmpng3_x0fd/prophet_modelmfv3l9nm/prophet_model-20250105225554.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
      "22:55:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "2025-01-05 22:55:55,294 - INFO - Chain [1] start processing\n",
      "22:55:55 - cmdstanpy - INFO - Chain [1] done processing\n",
      "2025-01-05 22:55:55,587 - INFO - Chain [1] done processing\n",
      "2025-01-05 22:55:59,252 - INFO - Variable corriente_l2_a procesada exitosamente\n",
      "2025-01-05 22:56:09,030 - DEBUG - input tempfile: /tmp/tmpng3_x0fd/kixyp267.json\n",
      "2025-01-05 22:56:09,092 - DEBUG - input tempfile: /tmp/tmpng3_x0fd/hf875n7p.json\n",
      "2025-01-05 22:56:09,138 - DEBUG - idx 0\n",
      "2025-01-05 22:56:09,151 - DEBUG - running CmdStan, num_threads: None\n",
      "2025-01-05 22:56:09,155 - DEBUG - CmdStan args: ['/home/elicoubuntu/Desktop/Industrial_Insigths/.venv/lib/python3.10/site-packages/prophet/stan_model/prophet_model.bin', 'random', 'seed=1738', 'data', 'file=/tmp/tmpng3_x0fd/kixyp267.json', 'init=/tmp/tmpng3_x0fd/hf875n7p.json', 'output', 'file=/tmp/tmpng3_x0fd/prophet_modelo8liem2x/prophet_model-20250105225609.csv', 'method=optimize', 'algorithm=lbfgs', 'iter=10000']\n",
      "22:56:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "2025-01-05 22:56:09,157 - INFO - Chain [1] start processing\n",
      "22:56:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "2025-01-05 22:56:09,189 - INFO - Chain [1] done processing\n",
      "2025-01-05 22:56:09,850 - INFO - Variable corriente_l3_a procesada exitosamente\n",
      "2025-01-05 22:56:09,854 - INFO - \n",
      "        Proceso completado:\n",
      "        - Variables exitosas: 8\n",
      "        - Variables fallidas: 0\n",
      "        - Total procesadas: 8\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "FASE 3: Sistema Robusto de Línea Base Adaptativa Incremental\n",
    "=========================================================\n",
    "\n",
    "Objetivo: Establecer líneas base robustas y adaptativas para variables clave\n",
    "Versión: 5.0\n",
    "Descripción: Sistema avanzado de modelado de comportamiento normal con:\n",
    "- Procesamiento incremental por lotes\n",
    "- Ensemble de modelos estadísticos y ML\n",
    "- Detección automática de patrones y regímenes\n",
    "- Validación temporal rigurosa \n",
    "- Control de versiones de modelos\n",
    "- Preparación para predicción de fallas\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text, MetaData\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import adfuller, kpss\n",
    "from scipy import stats\n",
    "from prophet import Prophet\n",
    "from typing import Dict, List, Any, Tuple, Optional\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import warnings\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración del sistema\n",
    "class SystemConfig:\n",
    "    def __init__(self):\n",
    "        # Configuración de BD\n",
    "        self.DB_CONFIG = {\n",
    "            \"user\": \"postgres\",\n",
    "            \"password\": \"elico\",\n",
    "            \"host\": \"localhost\", \n",
    "            \"port\": \"5432\",\n",
    "            \"database\": \"prognosis_db\"\n",
    "        }\n",
    "        \n",
    "        # Parámetros del modelo\n",
    "        self.MODEL_PARAMS = {\n",
    "            \"training_window\": \"90D\",\n",
    "            \"update_frequency\": \"1D\",\n",
    "            \"min_data_points\": 1000,\n",
    "            \"confidence_level\": 0.95,\n",
    "            \"seasonality_test_size\": 168,\n",
    "            \"batch_size\": 1000,  # Tamaño del lote para procesamiento incremental\n",
    "            \"max_versions\": 5     # Número máximo de versiones a mantener\n",
    "        }\n",
    "        \n",
    "        # Umbrales estadísticos\n",
    "        self.STATISTICAL_THRESHOLDS = {\n",
    "            \"stationarity_pvalue\": 0.05,\n",
    "            \"seasonality_strength\": 0.3,\n",
    "            \"outlier_std_dev\": 3,\n",
    "            \"minimum_variance_ratio\": 0.01,\n",
    "            \"learning_threshold\": 0.1  # Umbral para considerar mejora significativa\n",
    "        }\n",
    "        \n",
    "        # Tablas de BD\n",
    "        self.TABLES = {\n",
    "            \"input\": {\n",
    "                \"normalized_data\": \"normalized_data_table\",\n",
    "                \"selected_variables\": \"selected_variables_history\"\n",
    "            },\n",
    "            \"output\": {\n",
    "                \"baseline\": \"baseline_models\",\n",
    "                \"patterns\": \"pattern_registry\", \n",
    "                \"metrics\": \"baseline_metrics\",\n",
    "                \"validation\": \"baseline_validation\",\n",
    "                \"incremental\": \"baseline_incremental_control\",\n",
    "                \"versions\": \"baseline_model_versions\"\n",
    "            }\n",
    "        }\n",
    "class DatabaseManager:\n",
    "    def __init__(self, config: SystemConfig):\n",
    "        self.config = config\n",
    "        self.engine = self._create_engine()\n",
    "        self.metadata = MetaData()\n",
    "        self._create_tables()\n",
    "        \n",
    "    def _create_engine(self):\n",
    "        url = f\"postgresql://{self.config.DB_CONFIG['user']}:{self.config.DB_CONFIG['password']}@{self.config.DB_CONFIG['host']}:{self.config.DB_CONFIG['port']}/{self.config.DB_CONFIG['database']}\"\n",
    "        return create_engine(url)\n",
    "    \n",
    "    def _create_tables(self):\n",
    "        with self.engine.begin() as conn:\n",
    "            conn.execute(text(\"\"\"\n",
    "                -- Tabla para modelos base\n",
    "                CREATE TABLE IF NOT EXISTS baseline_models (\n",
    "                    id SERIAL PRIMARY KEY,\n",
    "                    variable_name TEXT NOT NULL,\n",
    "                    model_type TEXT NOT NULL,\n",
    "                    model_parameters JSONB,\n",
    "                    baseline_stats JSONB,\n",
    "                    confidence_intervals JSONB,\n",
    "                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "                    is_active BOOLEAN DEFAULT true,\n",
    "                    UNIQUE(variable_name, model_type)\n",
    "                );\n",
    "\n",
    "                -- Tabla para registro de patrones\n",
    "                CREATE TABLE IF NOT EXISTS pattern_registry (\n",
    "                    id SERIAL PRIMARY KEY,\n",
    "                    variable_name TEXT NOT NULL,\n",
    "                    pattern_type TEXT NOT NULL,\n",
    "                    pattern_params JSONB,\n",
    "                    detection_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "                    confidence_score FLOAT,\n",
    "                    UNIQUE(variable_name, pattern_type)\n",
    "                );\n",
    "\n",
    "                -- Tabla para métricas\n",
    "                CREATE TABLE IF NOT EXISTS baseline_metrics (\n",
    "                    id SERIAL PRIMARY KEY,\n",
    "                    variable_name TEXT NOT NULL,\n",
    "                    metric_type TEXT NOT NULL,\n",
    "                    metric_value FLOAT,\n",
    "                    calculation_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "                );\n",
    "\n",
    "                -- Tabla para validación\n",
    "                CREATE TABLE IF NOT EXISTS baseline_validation (\n",
    "                    id SERIAL PRIMARY KEY,\n",
    "                    variable_name TEXT NOT NULL,\n",
    "                    validation_type TEXT NOT NULL,\n",
    "                    validation_result JSONB,\n",
    "                    validation_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "                );\n",
    "\n",
    "                -- Nueva tabla para control incremental\n",
    "                CREATE TABLE IF NOT EXISTS baseline_incremental_control (\n",
    "                    id SERIAL PRIMARY KEY,\n",
    "                    variable_name TEXT NOT NULL,\n",
    "                    last_processed_timestamp TIMESTAMP,\n",
    "                    batch_number INTEGER DEFAULT 0,\n",
    "                    batch_size INTEGER,\n",
    "                    learning_metrics JSONB,\n",
    "                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "                    UNIQUE(variable_name)\n",
    "                );\n",
    "\n",
    "                -- Nueva tabla para versiones de modelos\n",
    "                CREATE TABLE IF NOT EXISTS baseline_model_versions (\n",
    "                    id SERIAL PRIMARY KEY,\n",
    "                    variable_name TEXT NOT NULL,\n",
    "                    version INTEGER,\n",
    "                    model_parameters JSONB,\n",
    "                    performance_metrics JSONB,\n",
    "                    training_metadata JSONB,\n",
    "                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "                    is_active BOOLEAN DEFAULT true,\n",
    "                    UNIQUE(variable_name, version)\n",
    "                );\n",
    "            \"\"\"))\n",
    "\n",
    "    def get_selected_variables(self) -> List[str]:\n",
    "        \"\"\"Obtene solo las variables críticas del último análisis\"\"\"\n",
    "        query = f\"\"\"\n",
    "            WITH LastAnalysisTime AS (\n",
    "                SELECT MAX(timestamp) as max_time \n",
    "                FROM {self.config.TABLES['input']['selected_variables']}\n",
    "            )\n",
    "            SELECT variable_name \n",
    "            FROM {self.config.TABLES['input']['selected_variables']}\n",
    "            WHERE timestamp = (SELECT max_time FROM LastAnalysisTime)\n",
    "            AND category = 'critical';\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with self.engine.connect() as conn:  # Cambio: self.db.engine -> self.engine\n",
    "                result = conn.execute(text(query))\n",
    "                variables = [row[0] for row in result]  # Corrección de la línea corrupta\n",
    "                \n",
    "                # Validación adicional\n",
    "                if len(variables) != 8:  # Número esperado según VariableAnalyzer\n",
    "                    logging.warning(  # Cambio: self.logger -> logging\n",
    "                        f\"Discrepancia en variables críticas: \"\n",
    "                        f\"Esperadas=8, Obtenidas={len(variables)}\"\n",
    "                    )\n",
    "                    \n",
    "                return variables\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error obteniendo variables críticas: {str(e)}\")  # Cambio: self.logger -> logging\n",
    "            return []\n",
    "\n",
    "    def get_variable_data_batch(self, variable_name: str, last_timestamp: Optional[datetime] = None, \n",
    "                              batch_size: int = 1000) -> pd.DataFrame:\n",
    "        \"\"\"Obtiene datos de la variable en lotes\"\"\"\n",
    "        if last_timestamp is None:\n",
    "            query = f\"\"\"\n",
    "                SELECT timestamp, {variable_name}\n",
    "                FROM {self.config.TABLES['input']['normalized_data']}\n",
    "                ORDER BY timestamp\n",
    "                LIMIT {batch_size};\n",
    "            \"\"\"\n",
    "        else:\n",
    "            query = f\"\"\"\n",
    "                SELECT timestamp, {variable_name}\n",
    "                FROM {self.config.TABLES['input']['normalized_data']}\n",
    "                WHERE timestamp > :last_timestamp\n",
    "                ORDER BY timestamp\n",
    "                LIMIT {batch_size};\n",
    "            \"\"\"\n",
    "        return pd.read_sql_query(text(query), self.engine, \n",
    "                               params={\"last_timestamp\": last_timestamp},\n",
    "                               parse_dates=['timestamp'])\n",
    "\n",
    "    def get_last_processed_timestamp(self, variable_name: str) -> Optional[datetime]:\n",
    "        \"\"\"Obtiene el último timestamp procesado para una variable\"\"\"\n",
    "        query = \"\"\"\n",
    "            SELECT last_processed_timestamp\n",
    "            FROM baseline_incremental_control\n",
    "            WHERE variable_name = :variable_name;\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with self.engine.connect() as conn:\n",
    "                result = conn.execute(text(query), {\"variable_name\": variable_name})\n",
    "                row = result.fetchone()\n",
    "                return row[0] if row else None\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error obteniendo último timestamp: {str(e)}\")\n",
    "            return None\n",
    "        \n",
    "class BaselineModeler:\n",
    "    def __init__(self, config: SystemConfig, db_manager: DatabaseManager):\n",
    "        self.config = config\n",
    "        self.db = db_manager\n",
    "        self.models = {}\n",
    "        self.scalers = {}\n",
    "        self.patterns = {}\n",
    "    \n",
    "    def save_results(self, variable_name: str, results: Dict[str, Any]):\n",
    "        \"\"\"Guarda los resultados del modelo y crea una nueva versión\"\"\"\n",
    "        try:\n",
    "            # Limpiar datos antes de serializar\n",
    "            clean_results = {\n",
    "                \"patterns\": self._clean_json_data(results[\"patterns\"]),\n",
    "                \"metrics\": self._clean_json_data(results[\"metrics\"]),\n",
    "                \"validation\": self._clean_json_data(results[\"validation\"])\n",
    "            }\n",
    "\n",
    "            with self.db.engine.begin() as conn:\n",
    "                # Guardar modelo base\n",
    "                conn.execute(text(\"\"\"\n",
    "                    INSERT INTO baseline_models \n",
    "                    (variable_name, model_type, model_parameters, baseline_stats, \n",
    "                    confidence_intervals)\n",
    "                    VALUES (:variable_name, 'ensemble', :model_params, :stats, :intervals)\n",
    "                    ON CONFLICT (variable_name, model_type) DO UPDATE \n",
    "                    SET model_parameters = EXCLUDED.model_parameters,\n",
    "                        baseline_stats = EXCLUDED.baseline_stats,\n",
    "                        confidence_intervals = EXCLUDED.confidence_intervals,\n",
    "                        updated_at = CURRENT_TIMESTAMP;\n",
    "                \"\"\"), {\n",
    "                    \"variable_name\": variable_name,\n",
    "                    \"model_params\": json.dumps(clean_results[\"patterns\"]),\n",
    "                    \"stats\": json.dumps(clean_results[\"metrics\"]),\n",
    "                    \"intervals\": json.dumps(clean_results[\"validation\"])\n",
    "                })\n",
    "\n",
    "            # Guardar versión del modelo\n",
    "            self.save_model_version(variable_name, clean_results)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error guardando resultados para {variable_name}: {str(e)}\")\n",
    "            raise \n",
    "\n",
    "    def _clean_json_data(self, data: Any) -> Any:\n",
    "        \"\"\"Limpia valores NaN y los convierte a NULL para compatibilidad con PostgreSQL\"\"\"\n",
    "        if isinstance(data, dict):\n",
    "            return {k: self._clean_json_data(v) for k, v in data.items()}\n",
    "        elif isinstance(data, list):\n",
    "            return [self._clean_json_data(x) for x in data]\n",
    "        elif isinstance(data, (float, np.float64, np.float32)):\n",
    "            return None if np.isnan(data) else float(data)\n",
    "        return data\n",
    "    \n",
    "    def analyze_variable(self, variable_name: str, data: pd.DataFrame) -> Dict[str, Any]:\n",
    "        \"\"\"Analiza una variable y genera su línea base\"\"\"\n",
    "        # Preparación de datos\n",
    "        ts_data = self._prepare_timeseries(data)\n",
    "        \n",
    "        # Detección de patrones\n",
    "        patterns = self._detect_patterns(ts_data)\n",
    "        self.patterns[variable_name] = patterns\n",
    "        \n",
    "        # Modelado ensemble\n",
    "        models = self._create_ensemble_model(ts_data, patterns)\n",
    "        self.models[variable_name] = models\n",
    "        \n",
    "        # Validación\n",
    "        validation = self._validate_models(variable_name, ts_data, models)\n",
    "        \n",
    "        # Métricas\n",
    "        metrics = self._calculate_metrics(variable_name, ts_data, models)\n",
    "        \n",
    "        return {\n",
    "            \"patterns\": patterns,\n",
    "            \"models\": models,\n",
    "            \"validation\": validation,\n",
    "            \"metrics\": metrics\n",
    "        }\n",
    "\n",
    "    def _prepare_timeseries(self, data: pd.DataFrame) -> pd.Series:\n",
    "        \"\"\"Prepara los datos de series temporales\"\"\"\n",
    "        data = data.set_index('timestamp').sort_index()\n",
    "        return data.iloc[:, 0]  # Primera columna contiene los valores\n",
    "\n",
    "    def _detect_patterns(self, data: pd.Series) -> Dict[str, Any]:\n",
    "        \"\"\"Detecta patrones en los datos\"\"\"\n",
    "        # Análisis de estacionariedad\n",
    "        adf_test = adfuller(data)\n",
    "        kpss_test = kpss(data)\n",
    "        \n",
    "        # Descomposición de series\n",
    "        decomposition = seasonal_decompose(data, period=24)\n",
    "        \n",
    "        # Detección de estacionalidad\n",
    "        acf_24 = np.correlate(data, data, mode='full')[len(data)-1:len(data)+24]\n",
    "        seasonal_strength = np.max(np.abs(acf_24[1:]))\n",
    "        \n",
    "        return {\n",
    "            \"stationarity\": {\n",
    "                \"adf_pvalue\": adf_test[1],\n",
    "                \"kpss_pvalue\": kpss_test[1]\n",
    "            },\n",
    "            \"seasonality\": {\n",
    "                \"strength\": seasonal_strength,\n",
    "                \"period\": 24 if seasonal_strength > self.config.STATISTICAL_THRESHOLDS[\"seasonality_strength\"] else 0\n",
    "            },\n",
    "            \"decomposition\": {\n",
    "                \"trend\": decomposition.trend.dropna().tolist(),\n",
    "                \"seasonal\": decomposition.seasonal.dropna().tolist(),\n",
    "                \"resid\": decomposition.resid.dropna().tolist()\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def _create_ensemble_model(self, data: pd.Series, patterns: Dict) -> Dict[str, Any]:\n",
    "        \"\"\"Crea un conjunto de modelos para la serie temporal\"\"\"\n",
    "        models = {}\n",
    "        \n",
    "        # Verificar si los datos son constantes\n",
    "        if len(data.unique()) <= 1:\n",
    "            logging.warning(f\"Datos constantes detectados con valor {data.iloc[0]}\")\n",
    "            return {\n",
    "                \"constant\": {\n",
    "                    \"value\": float(data.iloc[0]),\n",
    "                    \"is_constant\": True\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        try:\n",
    "            # Modelo SARIMA para componentes temporales\n",
    "            if patterns[\"seasonality\"][\"period\"] > 0:\n",
    "                try:\n",
    "                    sarima = SARIMAX(data, order=(1,1,1), \n",
    "                                seasonal_order=(1,1,1,patterns[\"seasonality\"][\"period\"]))\n",
    "                    models[\"sarima\"] = sarima.fit(disp=False)\n",
    "                except Exception as e:\n",
    "                    logging.warning(f\"Error en ajuste SARIMA: {str(e)}\")\n",
    "            \n",
    "            # Modelo Prophet optimizado\n",
    "            try:\n",
    "                prophet_data = pd.DataFrame({\n",
    "                    'ds': data.index,\n",
    "                    'y': data.values\n",
    "                })\n",
    "                prophet = Prophet(\n",
    "                    yearly_seasonality=True, \n",
    "                    weekly_seasonality=True,\n",
    "                    daily_seasonality=True,\n",
    "                    n_changepoints=25,\n",
    "                    interval_width=0.95,\n",
    "                    mcmc_samples=0\n",
    "                )\n",
    "                prophet.fit(prophet_data)\n",
    "                models[\"prophet\"] = prophet\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Error en ajuste Prophet: {str(e)}\")\n",
    "            \n",
    "            # Isolation Forest para detección de anomalías\n",
    "            try:\n",
    "                iso_forest = IsolationForest(\n",
    "                    contamination=0.1, \n",
    "                    random_state=42,\n",
    "                    n_jobs=-1\n",
    "                )\n",
    "                iso_forest.fit(data.values.reshape(-1, 1))\n",
    "                models[\"isolation_forest\"] = iso_forest\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Error en ajuste Isolation Forest: {str(e)}\")\n",
    "            \n",
    "            return models\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error en creación de ensemble: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _validate_models(self, variable_name: str, data: pd.Series, models: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Valida los modelos generados\"\"\"\n",
    "        validation_results = {}\n",
    "        \n",
    "        # Validación cruzada temporal\n",
    "        train_size = int(len(data) * 0.8)\n",
    "        train_data = data[:train_size]\n",
    "        test_data = data[train_size:]\n",
    "        \n",
    "        # Validación SARIMA\n",
    "        if \"sarima\" in models:\n",
    "            sarima_pred = models[\"sarima\"].predict(start=test_data.index[0],\n",
    "                                                end=test_data.index[-1])\n",
    "            validation_results[\"sarima\"] = {\n",
    "                \"rmse\": np.sqrt(((test_data - sarima_pred) ** 2).mean()),\n",
    "                \"mae\": np.abs(test_data - sarima_pred).mean()\n",
    "            }\n",
    "        \n",
    "        # Validación Prophet\n",
    "        try:\n",
    "            prophet_test = pd.DataFrame({'ds': test_data.index})\n",
    "            prophet_pred = models[\"prophet\"].predict(prophet_test)\n",
    "            \n",
    "            # Alinear índices\n",
    "            test_values = test_data.reindex(prophet_pred['ds'].values)\n",
    "            pred_values = prophet_pred['yhat']\n",
    "            \n",
    "            if len(test_values) == len(pred_values):\n",
    "                validation_results[\"prophet\"] = {\n",
    "                    \"rmse\": np.sqrt(((test_values - pred_values) ** 2).mean()),\n",
    "                    \"mae\": np.abs(test_values - pred_values).mean()\n",
    "                }\n",
    "            else:\n",
    "                validation_results[\"prophet\"] = {\n",
    "                    \"rmse\": None,\n",
    "                    \"mae\": None\n",
    "                }\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Error en validación Prophet: {str(e)}\")\n",
    "            validation_results[\"prophet\"] = {\n",
    "                \"rmse\": None,\n",
    "                \"mae\": None\n",
    "            }\n",
    "        \n",
    "        return validation_results\n",
    "\n",
    "    def _calculate_metrics(self, variable_name: str, data: pd.Series, models: Dict[str, Any]) -> Dict[str, float]:\n",
    "        \"\"\"Calcula métricas del modelo\"\"\"\n",
    "        metrics = {}\n",
    "        \n",
    "        # Estadísticas básicas\n",
    "        metrics.update({\n",
    "            \"mean\": float(data.mean()),\n",
    "            \"std\": float(data.std()),\n",
    "            \"skewness\": float(stats.skew(data)),\n",
    "            \"kurtosis\": float(stats.kurtosis(data))\n",
    "        })\n",
    "        \n",
    "        # Métricas de calidad del modelo\n",
    "        if \"sarima\" in models:\n",
    "            metrics[\"sarima_aic\"] = float(models[\"sarima\"].aic)\n",
    "            metrics[\"sarima_bic\"] = float(models[\"sarima\"].bic)\n",
    "        \n",
    "        # Score de anomalías\n",
    "        iso_scores = models[\"isolation_forest\"].score_samples(data.values.reshape(-1, 1))\n",
    "        metrics[\"anomaly_ratio\"] = float((iso_scores < 0).mean())\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "    def process_incremental(self, variable_name: str) -> bool:\n",
    "        \"\"\"Procesa una variable de forma incremental con validación\"\"\"\n",
    "        try:\n",
    "            # Verificar si la variable realmente es crítica\n",
    "            query = f\"\"\"\n",
    "                WITH LastAnalysis AS (\n",
    "                    SELECT MAX(timestamp) as max_time \n",
    "                    FROM {self.config.TABLES['input']['selected_variables']}\n",
    "                )\n",
    "                SELECT COUNT(1) \n",
    "                FROM {self.config.TABLES['input']['selected_variables']}\n",
    "                WHERE timestamp = (SELECT max_time FROM LastAnalysis)\n",
    "                AND category = 'critical'\n",
    "                AND variable_name = :variable_name;\n",
    "            \"\"\"\n",
    "            \n",
    "            with self.db.engine.connect() as conn:\n",
    "                result = conn.execute(text(query), {\"variable_name\": variable_name})\n",
    "                if not result.scalar():\n",
    "                    logging.warning(f\"Variable {variable_name} no es crítica en el último análisis\")\n",
    "                    return False\n",
    "            # Obtener último timestamp procesado\n",
    "            last_timestamp = self.db.get_last_processed_timestamp(variable_name)\n",
    "            batch_size = self.config.MODEL_PARAMS[\"batch_size\"]\n",
    "            \n",
    "            # Obtener siguiente lote de datos\n",
    "            data_batch = self.db.get_variable_data_batch(\n",
    "                variable_name, last_timestamp, batch_size\n",
    "            )\n",
    "            \n",
    "            if data_batch.empty:\n",
    "                logging.info(f\"No hay nuevos datos para {variable_name}\")\n",
    "                return True\n",
    "                \n",
    "            # Procesar lote\n",
    "            results = self.analyze_variable(variable_name, data_batch)\n",
    "            \n",
    "            # Actualizar modelo existente si existe\n",
    "            current_model = self.get_current_model(variable_name)\n",
    "            if current_model:\n",
    "                results = self.update_model(current_model, results)\n",
    "            \n",
    "            # Guardar resultados y actualizar control\n",
    "            self.save_results(variable_name, results)\n",
    "            self.update_incremental_control(\n",
    "                variable_name, \n",
    "                data_batch['timestamp'].max(),\n",
    "                len(data_batch)\n",
    "            )\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error en procesamiento incremental de {variable_name}: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def get_current_model(self, variable_name: str) -> Optional[Dict]:\n",
    "        \"\"\"Obtiene el modelo actual de la variable\"\"\"\n",
    "        query = \"\"\"\n",
    "            SELECT model_parameters::text, \n",
    "                    baseline_stats::text, \n",
    "                    confidence_intervals::text\n",
    "            FROM baseline_models\n",
    "            WHERE variable_name = :variable_name\n",
    "            AND is_active = true;\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with self.db.engine.connect() as conn:\n",
    "                result = conn.execute(text(query), {\"variable_name\": variable_name})\n",
    "                row = result.fetchone()\n",
    "                if row:\n",
    "                    try:\n",
    "                        return {\n",
    "                            \"parameters\": json.loads(row[0]) if row[0] else {},\n",
    "                            \"stats\": json.loads(row[1]) if row[1] else {},\n",
    "                            \"intervals\": json.loads(row[2]) if row[2] else {}\n",
    "                        }\n",
    "                    except json.JSONDecodeError as je:\n",
    "                        logging.error(f\"Error decodificando JSON para {variable_name}: {str(je)}\")\n",
    "                        return None\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error obteniendo modelo actual: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def update_model(self, current_model: Dict, new_results: Dict) -> Dict:\n",
    "        \"\"\"Actualiza el modelo con nuevos resultados\"\"\"\n",
    "        # Combinar patrones\n",
    "        combined_patterns = self._merge_patterns(\n",
    "            current_model[\"parameters\"], \n",
    "            new_results[\"patterns\"]\n",
    "        )\n",
    "        \n",
    "        # Actualizar métricas\n",
    "        updated_metrics = self._update_metrics(\n",
    "            current_model[\"stats\"], \n",
    "            new_results[\"metrics\"]\n",
    "        )\n",
    "        \n",
    "        # Actualizar intervalos de confianza\n",
    "        updated_intervals = self._update_intervals(\n",
    "            current_model[\"intervals\"], \n",
    "            new_results[\"validation\"]\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"patterns\": combined_patterns,\n",
    "            \"metrics\": updated_metrics,\n",
    "            \"validation\": updated_intervals,\n",
    "            \"models\": new_results[\"models\"]  # Mantener modelos actualizados\n",
    "        }\n",
    "\n",
    "    def _merge_patterns(self, old_patterns: Dict, new_patterns: Dict) -> Dict:\n",
    "        \"\"\"Combina patrones antiguos y nuevos\"\"\"\n",
    "        merged = {}\n",
    "        \n",
    "        # Combinar estacionariedad\n",
    "        merged[\"stationarity\"] = {\n",
    "            \"adf_pvalue\": min(old_patterns[\"stationarity\"][\"adf_pvalue\"],\n",
    "                            new_patterns[\"stationarity\"][\"adf_pvalue\"]),\n",
    "            \"kpss_pvalue\": min(old_patterns[\"stationarity\"][\"kpss_pvalue\"],\n",
    "                             new_patterns[\"stationarity\"][\"kpss_pvalue\"])\n",
    "        }\n",
    "        \n",
    "        # Actualizar estacionalidad\n",
    "        merged[\"seasonality\"] = new_patterns[\"seasonality\"]\n",
    "        \n",
    "        # Mantener descomposición más reciente\n",
    "        merged[\"decomposition\"] = new_patterns[\"decomposition\"]\n",
    "        \n",
    "        return merged\n",
    "\n",
    "    def _update_metrics(self, old_metrics: Dict, new_metrics: Dict) -> Dict:\n",
    "        \"\"\"Actualiza métricas con nuevos datos\"\"\"\n",
    "        updated = {}\n",
    "        \n",
    "        # Actualizar estadísticas básicas con ponderación\n",
    "        weight_old = 0.7  # Dar más peso a la historia\n",
    "        weight_new = 0.3\n",
    "        \n",
    "        for key in [\"mean\", \"std\", \"skewness\", \"kurtosis\"]:\n",
    "            updated[key] = (old_metrics[key] * weight_old + \n",
    "                          new_metrics[key] * weight_new)\n",
    "        \n",
    "        # Actualizar métricas de modelo\n",
    "        if \"sarima_aic\" in new_metrics:\n",
    "            updated[\"sarima_aic\"] = new_metrics[\"sarima_aic\"]\n",
    "            updated[\"sarima_bic\"] = new_metrics[\"sarima_bic\"]\n",
    "        \n",
    "        # Actualizar ratio de anomalías\n",
    "        updated[\"anomaly_ratio\"] = new_metrics[\"anomaly_ratio\"]\n",
    "        \n",
    "        return updated\n",
    "    \n",
    "    def _update_intervals(self, old_intervals: Dict, new_intervals: Dict) -> Dict:\n",
    "        \"\"\"Actualiza intervalos de confianza\"\"\"\n",
    "        updated = {}\n",
    "        \n",
    "        # Actualizar métricas SARIMA\n",
    "        if \"sarima\" in new_intervals:\n",
    "            updated[\"sarima\"] = new_intervals[\"sarima\"]\n",
    "        \n",
    "        # Actualizar métricas Prophet\n",
    "        if \"prophet\" in new_intervals:\n",
    "            updated[\"prophet\"] = new_intervals[\"prophet\"]\n",
    "        \n",
    "        return updated\n",
    "\n",
    "    def update_incremental_control(self, variable_name: str, \n",
    "                                 last_timestamp: datetime, \n",
    "                                 batch_size: int) -> None:\n",
    "        \"\"\"Actualiza el control de procesamiento incremental\"\"\"\n",
    "        query = \"\"\"\n",
    "            INSERT INTO baseline_incremental_control \n",
    "            (variable_name, last_processed_timestamp, batch_size, batch_number)\n",
    "            VALUES (:variable_name, :last_timestamp, :batch_size, 1)\n",
    "            ON CONFLICT (variable_name) DO UPDATE\n",
    "            SET last_processed_timestamp = :last_timestamp,\n",
    "                batch_size = :batch_size,\n",
    "                batch_number = baseline_incremental_control.batch_number + 1,\n",
    "                updated_at = CURRENT_TIMESTAMP;\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with self.db.engine.begin() as conn:\n",
    "                conn.execute(text(query), {\n",
    "                    \"variable_name\": variable_name,\n",
    "                    \"last_timestamp\": last_timestamp,\n",
    "                    \"batch_size\": batch_size\n",
    "                })\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error actualizando control incremental: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def save_model_version(self, variable_name: str, results: Dict[str, Any]):\n",
    "        \"\"\"Guarda una nueva versión del modelo\"\"\"\n",
    "        try:\n",
    "            # Obtener última versión\n",
    "            query = \"\"\"\n",
    "                SELECT COALESCE(MAX(version), 0)\n",
    "                FROM baseline_model_versions\n",
    "                WHERE variable_name = :variable_name;\n",
    "            \"\"\"\n",
    "            with self.db.engine.connect() as conn:\n",
    "                result = conn.execute(text(query), {\"variable_name\": variable_name})\n",
    "                last_version = result.scalar() or 0\n",
    "                \n",
    "                # Crear nueva versión\n",
    "                new_version = last_version + 1\n",
    "                \n",
    "                # Desactivar versiones antiguas si excede el máximo\n",
    "                if new_version > self.config.MODEL_PARAMS[\"max_versions\"]:\n",
    "                    conn.execute(text(\"\"\"\n",
    "                        UPDATE baseline_model_versions\n",
    "                        SET is_active = false\n",
    "                        WHERE variable_name = :variable_name\n",
    "                        AND version <= :old_version;\n",
    "                    \"\"\"), {\n",
    "                        \"variable_name\": variable_name,\n",
    "                        \"old_version\": new_version - self.config.MODEL_PARAMS[\"max_versions\"]\n",
    "                    })\n",
    "                \n",
    "                # Insertar nueva versión\n",
    "                conn.execute(text(\"\"\"\n",
    "                    INSERT INTO baseline_model_versions\n",
    "                    (variable_name, version, model_parameters, \n",
    "                     performance_metrics, training_metadata)\n",
    "                    VALUES (:variable_name, :version, :parameters,\n",
    "                           :metrics, :metadata);\n",
    "                \"\"\"), {\n",
    "                    \"variable_name\": variable_name,\n",
    "                    \"version\": new_version,\n",
    "                    \"parameters\": json.dumps(self._clean_json_data(results[\"patterns\"])),\n",
    "                    \"metrics\": json.dumps(self._clean_json_data(results[\"metrics\"])),\n",
    "                    \"metadata\": json.dumps({\n",
    "                        \"timestamp\": datetime.now().isoformat(),\n",
    "                        \"validation\": results[\"validation\"]\n",
    "                    })\n",
    "                })\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error guardando versión del modelo: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "             \n",
    "\n",
    "\n",
    "def execute_baseline_system():\n",
    "    \"\"\"Ejecuta el sistema de línea base con procesamiento incremental\"\"\"\n",
    "    try:\n",
    "        config = SystemConfig()\n",
    "        db_manager = DatabaseManager(config)\n",
    "        modeler = BaselineModeler(config, db_manager)\n",
    "        \n",
    "        # Obtener variables críticas\n",
    "        variables = db_manager.get_selected_variables()\n",
    "        if not variables:\n",
    "            logging.warning(\"No se encontraron variables críticas para procesar\")\n",
    "            return False\n",
    "            \n",
    "        logging.info(f\"Variables críticas identificadas: {len(variables)}\")\n",
    "        \n",
    "        def process_variable(variable: str) -> bool:\n",
    "            try:\n",
    "                logging.info(f\"Iniciando procesamiento incremental de: {variable}\")\n",
    "                success = modeler.process_incremental(variable)\n",
    "                if success:\n",
    "                    logging.info(f\"Variable {variable} procesada exitosamente\")\n",
    "                return success\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error procesando {variable}: {str(e)}\")\n",
    "                return False\n",
    "        \n",
    "        # Procesar variables en paralelo\n",
    "        successful = []\n",
    "        failed = []\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "            future_to_var = {executor.submit(process_variable, var): var \n",
    "                           for var in variables}\n",
    "            \n",
    "            for future in future_to_var:\n",
    "                variable = future_to_var[future]\n",
    "                try:\n",
    "                    if future.result():\n",
    "                        successful.append(variable)\n",
    "                    else:\n",
    "                        failed.append(variable)\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error en {variable}: {str(e)}\")\n",
    "                    failed.append(variable)\n",
    "        \n",
    "        # Reporte final\n",
    "        logging.info(f\"\"\"\n",
    "        Proceso completado:\n",
    "        - Variables exitosas: {len(successful)}\n",
    "        - Variables fallidas: {len(failed)}\n",
    "        - Total procesadas: {len(variables)}\n",
    "        \"\"\")\n",
    "        \n",
    "        if failed:\n",
    "            logging.warning(f\"Variables con errores: {failed}\")\n",
    "            \n",
    "        return len(successful) > 0\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error en proceso de línea base: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "    )\n",
    "    execute_baseline_system()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
