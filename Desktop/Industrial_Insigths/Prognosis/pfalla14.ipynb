{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuración inicial completada exitosamente.\n"
     ]
    }
   ],
   "source": [
    "# CELDA 1: Configuración Inicial y Documentación\n",
    "\"\"\"\n",
    "Módulo de Prognosis Industrial\n",
    "=============================\n",
    "\n",
    "Objetivo: Implementar un sistema automatizado de prognosis para sistemas industriales\n",
    "que permita detectar y predecir fallas basándose en:\n",
    "1. Detección de anomalías\n",
    "2. Análisis de tendencias\n",
    "3. Evaluación de límites\n",
    "\n",
    "Estructura del Notebook:\n",
    "- Fase 1: Preprocesamiento de datos\n",
    "- Fase 2: Identificación de variables clave\n",
    "- Fase 3: Aprendizaje de línea base\n",
    "- Fase 4: Detector de fallas\n",
    "\n",
    "Autor: [Nombre]\n",
    "Fecha: [Fecha]\n",
    "Versión: 1.0\n",
    "\"\"\"\n",
    "\n",
    "# Importaciones necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest, RandomForestRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Tuple, Any, Optional\n",
    "from datetime import datetime\n",
    "import json\n",
    "import warnings\n",
    "from statsmodels.tsa.stattools import acf\n",
    "\n",
    "# Configuración inicial\n",
    "plt.style.use('default')\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuración de logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "# Configuración de visualización\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print(\"Configuración inicial completada exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-27 09:55:09,464 - INFO - Iniciando preprocesamiento de datos...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PRUEBA DE PREPROCESAMIENTO ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-27 09:55:15,223 - INFO - Datos cargados: 7141 filas, 56 columnas\n",
      "2024-12-27 09:55:15,224 - INFO - Rango temporal: 2013-05-04 16:07:00 a 2013-05-09 15:07:00\n",
      "2024-12-27 09:55:15,581 - INFO - Preprocesamiento completado exitosamente\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumen del procesamiento:\n",
      "Forma inicial: (7141, 56)\n",
      "Forma final: (7141, 56)\n",
      "\n",
      "Rango temporal:\n",
      "Inicio: 2013-05-04 16:07:00\n",
      "Fin: 2013-05-09 15:07:00\n",
      "Frecuencia: 1T\n",
      "\n",
      "Muestra de datos procesados:\n",
      "                     Tensión: L1 (V)  Tensión: L2 (V)  Tensión: L3 (V)  \\\n",
      "timestamp                                                                \n",
      "2013-05-04 16:07:00        -0.018462        -0.192635        -0.074713   \n",
      "2013-05-04 16:08:00         0.076923        -0.116147        -0.002874   \n",
      "2013-05-04 16:09:00         0.092308        -0.099150         0.025862   \n",
      "2013-05-04 16:10:00         0.089231        -0.113314         0.025862   \n",
      "2013-05-04 16:11:00         0.113846        -0.099150         0.020115   \n",
      "\n",
      "                     Tensión: L1 - L2 (V)  Tensión: L2 - L3 (V)  \\\n",
      "timestamp                                                         \n",
      "2013-05-04 16:07:00             -0.134907             -0.136824   \n",
      "2013-05-04 16:08:00             -0.053963             -0.064189   \n",
      "2013-05-04 16:09:00             -0.043845             -0.035473   \n",
      "2013-05-04 16:10:00             -0.048904             -0.045608   \n",
      "2013-05-04 16:11:00             -0.026981             -0.047297   \n",
      "\n",
      "                     Tensión: L3 - L1 (V)  Corriente: L1 (A)  \\\n",
      "timestamp                                                      \n",
      "2013-05-04 16:07:00             -0.025773           4.134037   \n",
      "2013-05-04 16:08:00              0.067010           3.829024   \n",
      "2013-05-04 16:09:00              0.087629           3.770976   \n",
      "2013-05-04 16:10:00              0.087629           3.898153   \n",
      "2013-05-04 16:11:00              0.096220           3.947230   \n",
      "\n",
      "                     Corriente: L2 (A)  Corriente: L3 (A)  \\\n",
      "timestamp                                                   \n",
      "2013-05-04 16:07:00           0.658023           0.730655   \n",
      "2013-05-04 16:08:00           0.540962           0.600831   \n",
      "2013-05-04 16:09:00           0.523300           0.583614   \n",
      "2013-05-04 16:10:00           0.575911           0.631704   \n",
      "2013-05-04 16:11:00           0.586622           0.643776   \n",
      "\n",
      "                     Factor de potencia: L1 +  Factor de potencia: L2 +  \\\n",
      "timestamp                                                                 \n",
      "2013-05-04 16:07:00                  0.342105                 -0.638889   \n",
      "2013-05-04 16:08:00                 -0.131579                 -1.111111   \n",
      "2013-05-04 16:09:00                 -0.210526                 -1.222222   \n",
      "2013-05-04 16:10:00                  0.000000                 -0.972222   \n",
      "2013-05-04 16:11:00                  0.026316                 -0.888889   \n",
      "\n",
      "                     Factor de potencia: L3 +  Flicker (Pst): L1 (Pst)  \\\n",
      "timestamp                                                                \n",
      "2013-05-04 16:07:00                 -0.421053                      0.5   \n",
      "2013-05-04 16:08:00                 -0.789474                      0.5   \n",
      "2013-05-04 16:09:00                 -0.868421                      1.0   \n",
      "2013-05-04 16:10:00                 -0.631579                      0.0   \n",
      "2013-05-04 16:11:00                 -0.605263                      0.0   \n",
      "\n",
      "                     Flicker (Pst): L2 (Pst)  Flicker (Pst): L3 (Pst)  \\\n",
      "timestamp                                                               \n",
      "2013-05-04 16:07:00                      0.5                     -0.5   \n",
      "2013-05-04 16:08:00                      0.5                     -0.5   \n",
      "2013-05-04 16:09:00                     -0.5                      0.0   \n",
      "2013-05-04 16:10:00                      0.5                     -0.5   \n",
      "2013-05-04 16:11:00                      0.5                     -0.5   \n",
      "\n",
      "                     Distorsión armónica: VL1 (%V THD)  \\\n",
      "timestamp                                                \n",
      "2013-05-04 16:07:00                                0.2   \n",
      "2013-05-04 16:08:00                                0.2   \n",
      "2013-05-04 16:09:00                                0.2   \n",
      "2013-05-04 16:10:00                                0.2   \n",
      "2013-05-04 16:11:00                                0.4   \n",
      "\n",
      "                     Distorsión armónica: VL2 (%V THD)  \\\n",
      "timestamp                                                \n",
      "2013-05-04 16:07:00                           0.000000   \n",
      "2013-05-04 16:08:00                           0.166667   \n",
      "2013-05-04 16:09:00                           0.166667   \n",
      "2013-05-04 16:10:00                           0.166667   \n",
      "2013-05-04 16:11:00                           0.166667   \n",
      "\n",
      "                     Distorsión armónica: VL3 (%V THD)  \\\n",
      "timestamp                                                \n",
      "2013-05-04 16:07:00                                0.2   \n",
      "2013-05-04 16:08:00                                0.2   \n",
      "2013-05-04 16:09:00                                0.2   \n",
      "2013-05-04 16:10:00                                0.4   \n",
      "2013-05-04 16:11:00                                0.4   \n",
      "\n",
      "                     Distorsión armónica: IL1 (%I THD)  \\\n",
      "timestamp                                                \n",
      "2013-05-04 16:07:00                          -0.746479   \n",
      "2013-05-04 16:08:00                          -0.704225   \n",
      "2013-05-04 16:09:00                          -0.704225   \n",
      "2013-05-04 16:10:00                          -0.619718   \n",
      "2013-05-04 16:11:00                          -0.549296   \n",
      "\n",
      "                     Distorsión armónica: IL2 (%I THD)  \\\n",
      "timestamp                                                \n",
      "2013-05-04 16:07:00                          -0.357143   \n",
      "2013-05-04 16:08:00                          -0.214286   \n",
      "2013-05-04 16:09:00                          -0.214286   \n",
      "2013-05-04 16:10:00                           0.000000   \n",
      "2013-05-04 16:11:00                           0.142857   \n",
      "\n",
      "                     Distorsión armónica: IL3 (%I THD)  \\\n",
      "timestamp                                                \n",
      "2013-05-04 16:07:00                              -0.52   \n",
      "2013-05-04 16:08:00                              -0.44   \n",
      "2013-05-04 16:09:00                              -0.40   \n",
      "2013-05-04 16:10:00                              -0.16   \n",
      "2013-05-04 16:11:00                              -0.04   \n",
      "\n",
      "                     Armónicos IL1: Armónico 2 (%IL1)  \\\n",
      "timestamp                                               \n",
      "2013-05-04 16:07:00                         -0.853933   \n",
      "2013-05-04 16:08:00                         -0.853933   \n",
      "2013-05-04 16:09:00                         -0.853933   \n",
      "2013-05-04 16:10:00                         -0.853933   \n",
      "2013-05-04 16:11:00                         -0.853933   \n",
      "\n",
      "                     Armónicos IL1: Armónico 3 (%IL1)  \\\n",
      "timestamp                                               \n",
      "2013-05-04 16:07:00                         -0.586207   \n",
      "2013-05-04 16:08:00                         -0.568966   \n",
      "2013-05-04 16:09:00                         -0.568966   \n",
      "2013-05-04 16:10:00                         -0.551724   \n",
      "2013-05-04 16:11:00                         -0.534483   \n",
      "\n",
      "                     Armónicos IL1: Armónico 5 (%IL1)  \\\n",
      "timestamp                                               \n",
      "2013-05-04 16:07:00                         -0.270270   \n",
      "2013-05-04 16:08:00                         -0.162162   \n",
      "2013-05-04 16:09:00                         -0.189189   \n",
      "2013-05-04 16:10:00                         -0.027027   \n",
      "2013-05-04 16:11:00                          0.081081   \n",
      "\n",
      "                     Armónicos IL1: Armónico 6 (%IL1)  \\\n",
      "timestamp                                               \n",
      "2013-05-04 16:07:00                               0.0   \n",
      "2013-05-04 16:08:00                               0.0   \n",
      "2013-05-04 16:09:00                               0.0   \n",
      "2013-05-04 16:10:00                               0.0   \n",
      "2013-05-04 16:11:00                               0.0   \n",
      "\n",
      "                     Armónicos IL1: Armónico 7 (%IL1)  \\\n",
      "timestamp                                               \n",
      "2013-05-04 16:07:00                         -0.266667   \n",
      "2013-05-04 16:08:00                         -0.233333   \n",
      "2013-05-04 16:09:00                         -0.233333   \n",
      "2013-05-04 16:10:00                         -0.133333   \n",
      "2013-05-04 16:11:00                         -0.066667   \n",
      "\n",
      "                     Armónicos IL1: Armónico 11 (%IL1)  \\\n",
      "timestamp                                                \n",
      "2013-05-04 16:07:00                                0.0   \n",
      "2013-05-04 16:08:00                                0.0   \n",
      "2013-05-04 16:09:00                                0.0   \n",
      "2013-05-04 16:10:00                                0.0   \n",
      "2013-05-04 16:11:00                                0.0   \n",
      "\n",
      "                     Armónicos IL1: Armónico 13 (%IL1)  \\\n",
      "timestamp                                                \n",
      "2013-05-04 16:07:00                                0.5   \n",
      "2013-05-04 16:08:00                                0.5   \n",
      "2013-05-04 16:09:00                                0.5   \n",
      "2013-05-04 16:10:00                                0.5   \n",
      "2013-05-04 16:11:00                                0.5   \n",
      "\n",
      "                     Armónicos IL2: Armónico 2 (%IL2)  \\\n",
      "timestamp                                               \n",
      "2013-05-04 16:07:00                               0.0   \n",
      "2013-05-04 16:08:00                               0.0   \n",
      "2013-05-04 16:09:00                               0.0   \n",
      "2013-05-04 16:10:00                               0.0   \n",
      "2013-05-04 16:11:00                               0.0   \n",
      "\n",
      "                     Armónicos IL2: Armónico 3 (%IL2)  \\\n",
      "timestamp                                               \n",
      "2013-05-04 16:07:00                         -0.071429   \n",
      "2013-05-04 16:08:00                         -0.071429   \n",
      "2013-05-04 16:09:00                         -0.071429   \n",
      "2013-05-04 16:10:00                          0.071429   \n",
      "2013-05-04 16:11:00                          0.000000   \n",
      "\n",
      "                     Armónicos IL2: Armónico 5 (%IL2)  \\\n",
      "timestamp                                               \n",
      "2013-05-04 16:07:00                         -0.307692   \n",
      "2013-05-04 16:08:00                         -0.192308   \n",
      "2013-05-04 16:09:00                         -0.192308   \n",
      "2013-05-04 16:10:00                          0.038462   \n",
      "2013-05-04 16:11:00                          0.192308   \n",
      "\n",
      "                     Armónicos IL2: Armónico 7 (%IL2)  \\\n",
      "timestamp                                               \n",
      "2013-05-04 16:07:00                         -0.636364   \n",
      "2013-05-04 16:08:00                         -0.545455   \n",
      "2013-05-04 16:09:00                         -0.545455   \n",
      "2013-05-04 16:10:00                         -0.272727   \n",
      "2013-05-04 16:11:00                         -0.090909   \n",
      "\n",
      "                     Armónicos IL2: Armónico 9 (%IL2)  \\\n",
      "timestamp                                               \n",
      "2013-05-04 16:07:00                               0.0   \n",
      "2013-05-04 16:08:00                               0.0   \n",
      "2013-05-04 16:09:00                               0.0   \n",
      "2013-05-04 16:10:00                               0.0   \n",
      "2013-05-04 16:11:00                               0.0   \n",
      "\n",
      "                     Armónicos IL2: Armónico 11 (%IL2)  \\\n",
      "timestamp                                                \n",
      "2013-05-04 16:07:00                                0.0   \n",
      "2013-05-04 16:08:00                                0.0   \n",
      "2013-05-04 16:09:00                                0.0   \n",
      "2013-05-04 16:10:00                                0.0   \n",
      "2013-05-04 16:11:00                                0.0   \n",
      "\n",
      "                     Armónicos IL2: Armónico 13 (%IL2)  \\\n",
      "timestamp                                                \n",
      "2013-05-04 16:07:00                           0.000000   \n",
      "2013-05-04 16:08:00                           0.142857   \n",
      "2013-05-04 16:09:00                           0.142857   \n",
      "2013-05-04 16:10:00                           0.285714   \n",
      "2013-05-04 16:11:00                           0.142857   \n",
      "\n",
      "                     Armónicos VL1: Armónico 2 (%VL1)  \\\n",
      "timestamp                                               \n",
      "2013-05-04 16:07:00                               0.0   \n",
      "2013-05-04 16:08:00                               0.0   \n",
      "2013-05-04 16:09:00                               0.0   \n",
      "2013-05-04 16:10:00                               0.0   \n",
      "2013-05-04 16:11:00                               0.0   \n",
      "\n",
      "                     Armónicos VL1: Armónico 3 (%VL1)  \\\n",
      "timestamp                                               \n",
      "2013-05-04 16:07:00                               0.0   \n",
      "2013-05-04 16:08:00                               0.0   \n",
      "2013-05-04 16:09:00                               0.0   \n",
      "2013-05-04 16:10:00                               0.5   \n",
      "2013-05-04 16:11:00                               0.5   \n",
      "\n",
      "                     Armónicos VL1: Armónico 5 (%VL1)  \\\n",
      "timestamp                                               \n",
      "2013-05-04 16:07:00                               0.2   \n",
      "2013-05-04 16:08:00                               0.2   \n",
      "2013-05-04 16:09:00                               0.2   \n",
      "2013-05-04 16:10:00                               0.2   \n",
      "2013-05-04 16:11:00                               0.0   \n",
      "\n",
      "                     Armónicos VL1: Armónico 7 (%VL1)  \\\n",
      "timestamp                                               \n",
      "2013-05-04 16:07:00                              0.25   \n",
      "2013-05-04 16:08:00                              0.25   \n",
      "2013-05-04 16:09:00                              0.25   \n",
      "2013-05-04 16:10:00                              0.25   \n",
      "2013-05-04 16:11:00                              0.50   \n",
      "\n",
      "                     Armónicos VL1: Armónico 9 (%VL1)  \\\n",
      "timestamp                                               \n",
      "2013-05-04 16:07:00                               0.0   \n",
      "2013-05-04 16:08:00                               0.0   \n",
      "2013-05-04 16:09:00                               0.0   \n",
      "2013-05-04 16:10:00                               0.0   \n",
      "2013-05-04 16:11:00                               0.0   \n",
      "\n",
      "                     Armónicos VL1: Armónico 11 (%VL1)  \\\n",
      "timestamp                                                \n",
      "2013-05-04 16:07:00                                2.0   \n",
      "2013-05-04 16:08:00                                2.0   \n",
      "2013-05-04 16:09:00                                2.0   \n",
      "2013-05-04 16:10:00                                2.0   \n",
      "2013-05-04 16:11:00                                1.0   \n",
      "\n",
      "                     Armónicos VL1: Armónico 13 (%VL1)  \\\n",
      "timestamp                                                \n",
      "2013-05-04 16:07:00                                0.1   \n",
      "2013-05-04 16:08:00                                0.1   \n",
      "2013-05-04 16:09:00                                0.1   \n",
      "2013-05-04 16:10:00                                0.0   \n",
      "2013-05-04 16:11:00                                0.0   \n",
      "\n",
      "                     Armónicos VL2: Armónico 2 (%VL2)  \\\n",
      "timestamp                                               \n",
      "2013-05-04 16:07:00                               0.0   \n",
      "2013-05-04 16:08:00                               0.0   \n",
      "2013-05-04 16:09:00                               0.0   \n",
      "2013-05-04 16:10:00                               0.0   \n",
      "2013-05-04 16:11:00                               0.0   \n",
      "\n",
      "                     Armónicos VL2: Armónico 3 (%VL2)  \\\n",
      "timestamp                                               \n",
      "2013-05-04 16:07:00                               0.0   \n",
      "2013-05-04 16:08:00                               0.0   \n",
      "2013-05-04 16:09:00                               0.0   \n",
      "2013-05-04 16:10:00                               0.0   \n",
      "2013-05-04 16:11:00                               0.0   \n",
      "\n",
      "                     Armónicos VL2: Armónico 5 (%VL2)  \\\n",
      "timestamp                                               \n",
      "2013-05-04 16:07:00                               0.2   \n",
      "2013-05-04 16:08:00                               0.2   \n",
      "2013-05-04 16:09:00                               0.2   \n",
      "2013-05-04 16:10:00                               0.2   \n",
      "2013-05-04 16:11:00                               0.0   \n",
      "\n",
      "                     Armónicos VL2: Armónico 7 (%VL2)  \\\n",
      "timestamp                                               \n",
      "2013-05-04 16:07:00                              0.00   \n",
      "2013-05-04 16:08:00                              0.00   \n",
      "2013-05-04 16:09:00                              0.00   \n",
      "2013-05-04 16:10:00                              0.25   \n",
      "2013-05-04 16:11:00                              0.25   \n",
      "\n",
      "                     Armónicos VL2: Armónico 9 (%VL2)  \\\n",
      "timestamp                                               \n",
      "2013-05-04 16:07:00                               0.0   \n",
      "2013-05-04 16:08:00                               0.0   \n",
      "2013-05-04 16:09:00                               0.0   \n",
      "2013-05-04 16:10:00                               0.0   \n",
      "2013-05-04 16:11:00                               0.0   \n",
      "\n",
      "                     Armónicos VL2: Armónico 11 (%VL2)  \\\n",
      "timestamp                                                \n",
      "2013-05-04 16:07:00                                1.0   \n",
      "2013-05-04 16:08:00                                1.0   \n",
      "2013-05-04 16:09:00                                1.0   \n",
      "2013-05-04 16:10:00                                1.0   \n",
      "2013-05-04 16:11:00                                0.0   \n",
      "\n",
      "                     Armónicos VL2: Armónico 13 (%VL2)  \\\n",
      "timestamp                                                \n",
      "2013-05-04 16:07:00                                0.1   \n",
      "2013-05-04 16:08:00                                0.1   \n",
      "2013-05-04 16:09:00                                0.1   \n",
      "2013-05-04 16:10:00                                0.1   \n",
      "2013-05-04 16:11:00                                0.0   \n",
      "\n",
      "                     Armónicos VL3: Armónico 2 (%VL3)  \\\n",
      "timestamp                                               \n",
      "2013-05-04 16:07:00                               0.0   \n",
      "2013-05-04 16:08:00                               0.0   \n",
      "2013-05-04 16:09:00                               0.0   \n",
      "2013-05-04 16:10:00                               0.0   \n",
      "2013-05-04 16:11:00                               0.0   \n",
      "\n",
      "                     Armónicos VL3: Armónico 3 (%VL3)  \\\n",
      "timestamp                                               \n",
      "2013-05-04 16:07:00                               0.0   \n",
      "2013-05-04 16:08:00                               0.0   \n",
      "2013-05-04 16:09:00                               0.0   \n",
      "2013-05-04 16:10:00                               0.0   \n",
      "2013-05-04 16:11:00                               0.0   \n",
      "\n",
      "                     Armónicos VL3: Armónico 5 (%VL3)  \\\n",
      "timestamp                                               \n",
      "2013-05-04 16:07:00                              0.25   \n",
      "2013-05-04 16:08:00                              0.25   \n",
      "2013-05-04 16:09:00                              0.25   \n",
      "2013-05-04 16:10:00                              0.25   \n",
      "2013-05-04 16:11:00                              0.00   \n",
      "\n",
      "                     Armónicos VL3: Armónico 7 (%VL3)  \\\n",
      "timestamp                                               \n",
      "2013-05-04 16:07:00                              0.00   \n",
      "2013-05-04 16:08:00                              0.00   \n",
      "2013-05-04 16:09:00                              0.00   \n",
      "2013-05-04 16:10:00                              0.25   \n",
      "2013-05-04 16:11:00                              0.50   \n",
      "\n",
      "                     Armónicos VL3: Armónico 9 (%VL3)  \\\n",
      "timestamp                                               \n",
      "2013-05-04 16:07:00                               0.0   \n",
      "2013-05-04 16:08:00                               0.0   \n",
      "2013-05-04 16:09:00                               0.0   \n",
      "2013-05-04 16:10:00                               0.0   \n",
      "2013-05-04 16:11:00                               0.0   \n",
      "\n",
      "                     Armónicos VL3: Armónico 11 (%VL3)  \\\n",
      "timestamp                                                \n",
      "2013-05-04 16:07:00                                1.0   \n",
      "2013-05-04 16:08:00                                1.0   \n",
      "2013-05-04 16:09:00                                1.0   \n",
      "2013-05-04 16:10:00                                1.0   \n",
      "2013-05-04 16:11:00                                0.0   \n",
      "\n",
      "                     Armónicos VL3: Armónico 13 (%VL3)  \n",
      "timestamp                                               \n",
      "2013-05-04 16:07:00                                0.0  \n",
      "2013-05-04 16:08:00                                0.0  \n",
      "2013-05-04 16:09:00                                0.0  \n",
      "2013-05-04 16:10:00                                0.0  \n",
      "2013-05-04 16:11:00                                0.0  \n"
     ]
    }
   ],
   "source": [
    "# CELDA 2: Fase 1 - Preprocesamiento de Datos\n",
    "\"\"\"\n",
    "Fase 1: Preprocesamiento de Datos\n",
    "================================\n",
    "\n",
    "Esta fase implementa:\n",
    "1. Carga y validación de datos\n",
    "2. Control de calidad\n",
    "3. Normalización y escalado\n",
    "4. Análisis estadístico inicial\n",
    "\n",
    "Características principales:\n",
    "- Manejo de datos faltantes y outliers\n",
    "- Normalización robusta\n",
    "- Generación de reportes de calidad\n",
    "- Preservación de estructura temporal\n",
    "\"\"\"\n",
    "\n",
    "class DataPreprocessor:\n",
    "    def __init__(self):\n",
    "        \"\"\"Inicializa el preprocesador con configuraciones por defecto\"\"\"\n",
    "        self.scaler = RobustScaler()  # Más robusto que StandardScaler para datos industriales\n",
    "        self.stats = {}\n",
    "        self.quality_report = {\n",
    "            'missing_values': {},\n",
    "            'infinite_values': {},\n",
    "            'outliers': {},\n",
    "            'irrelevant_columns': [],\n",
    "            'data_types': {},\n",
    "            'temporal_stats': {},  # Nueva sección para estadísticas temporales\n",
    "            'warnings': [],\n",
    "            'errors': []\n",
    "        }\n",
    "        self._setup_logging()\n",
    "\n",
    "    def _setup_logging(self):\n",
    "        \"\"\"Configura el sistema de logging\"\"\"\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def process_data(self, data_path: str) -> Tuple[pd.DataFrame, Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Procesa los datos desde el archivo fuente.\n",
    "        \n",
    "        Args:\n",
    "            data_path: Ruta al archivo de datos (.csv o .xlsx)\n",
    "            \n",
    "        Returns:\n",
    "            Tuple[pd.DataFrame, Dict]: Datos procesados y reporte de calidad\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.logger.info(\"Iniciando preprocesamiento de datos...\")\n",
    "            \n",
    "            # 1. Carga y validación inicial\n",
    "            data = self._load_data(data_path)\n",
    "            if data is None:\n",
    "                return None, self.quality_report\n",
    "            \n",
    "            # 2. Control de calidad\n",
    "            data = self._quality_control(data)\n",
    "            if data is None:\n",
    "                return None, self.quality_report\n",
    "                \n",
    "            # 3. Normalización y escalado\n",
    "            data_processed = self._normalize_data(data)\n",
    "            \n",
    "            # 4. Análisis estadístico\n",
    "            self._perform_statistical_analysis(data_processed)\n",
    "            \n",
    "            # 5. Análisis temporal\n",
    "            self._analyze_temporal_structure(data_processed)\n",
    "            \n",
    "            results = {\n",
    "                'quality_report': self.quality_report,\n",
    "                'statistics': self.stats,\n",
    "                'data_shape': data_processed.shape,\n",
    "                'columns': list(data_processed.columns),\n",
    "                'temporal_range': {\n",
    "                    'start': data_processed.index.min(),\n",
    "                    'end': data_processed.index.max(),\n",
    "                    'frequency': self._detect_sampling_frequency(data_processed)\n",
    "                },\n",
    "                'processing_summary': {\n",
    "                    'initial_shape': data.shape,\n",
    "                    'final_shape': data_processed.shape,\n",
    "                    'removed_columns': self.quality_report['irrelevant_columns']\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            self.logger.info(\"Preprocesamiento completado exitosamente\")\n",
    "            return data_processed, results\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en preprocesamiento: {str(e)}\")\n",
    "            return None, None\n",
    "\n",
    "    def _load_data(self, path: str) -> Optional[pd.DataFrame]:\n",
    "        \"\"\"Carga los datos desde archivo y configura el índice temporal\"\"\"\n",
    "        try:\n",
    "            if path.endswith('.xlsx'):\n",
    "                data = pd.read_excel(path)\n",
    "            elif path.endswith('.csv'):\n",
    "                data = pd.read_csv(path)\n",
    "            else:\n",
    "                self.logger.error(\"Formato de archivo no soportado\")\n",
    "                return None\n",
    "            \n",
    "            # Verificar y configurar timestamp\n",
    "            if 'timestamp' in data.columns:\n",
    "                # Convertir a datetime si no lo es\n",
    "                if not pd.api.types.is_datetime64_any_dtype(data['timestamp']):\n",
    "                    data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "                \n",
    "                # Establecer timestamp como índice\n",
    "                data.set_index('timestamp', inplace=True)\n",
    "                data.sort_index(inplace=True)  # Ordenar por timestamp\n",
    "                \n",
    "                self.logger.info(f\"Datos cargados: {data.shape[0]} filas, {data.shape[1]} columnas\")\n",
    "                self.logger.info(f\"Rango temporal: {data.index.min()} a {data.index.max()}\")\n",
    "            else:\n",
    "                self.logger.error(\"No se encontró columna de timestamp\")\n",
    "                return None\n",
    "            \n",
    "            return data\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en carga de datos: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def _quality_control(self, data: pd.DataFrame) -> Optional[pd.DataFrame]:\n",
    "        \"\"\"Realiza control de calidad en los datos preservando estructura temporal\"\"\"\n",
    "        try:\n",
    "            # 1. Análisis de valores faltantes\n",
    "            for column in data.columns:\n",
    "                missing = data[column].isnull().sum()\n",
    "                self.quality_report['missing_values'][column] = missing\n",
    "                \n",
    "                if missing > 0:\n",
    "                    if missing/len(data) > 0.5:  # Si más del 50% son nulos\n",
    "                        self.quality_report['irrelevant_columns'].append(column)\n",
    "                    else:\n",
    "                        if pd.api.types.is_numeric_dtype(data[column]):\n",
    "                            # Interpolación temporal para datos numéricos\n",
    "                            data[column] = data[column].interpolate(method='time')\n",
    "                        else:\n",
    "                            data[column] = data[column].fillna(data[column].mode()[0])\n",
    "            \n",
    "            # 2. Manejo de infinitos\n",
    "            numeric_columns = data.select_dtypes(include=[np.number]).columns\n",
    "            for column in numeric_columns:\n",
    "                inf_mask = np.isinf(data[column])\n",
    "                inf_count = inf_mask.sum()\n",
    "                self.quality_report['infinite_values'][column] = inf_count\n",
    "                \n",
    "                if inf_count > 0:\n",
    "                    data[column] = data[column].replace([np.inf, -np.inf], np.nan)\n",
    "                    data[column] = data[column].interpolate(method='time')\n",
    "            \n",
    "            # 3. Detección de outliers\n",
    "            for column in numeric_columns:\n",
    "                z_scores = np.abs(stats.zscore(data[column]))\n",
    "                outliers = (z_scores > 3).sum()\n",
    "                self.quality_report['outliers'][column] = outliers\n",
    "            \n",
    "            return data\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en control de calidad: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def _normalize_data(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Normaliza las variables numéricas preservando el índice temporal\"\"\"\n",
    "        try:\n",
    "            numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "            if len(numeric_cols) > 0:\n",
    "                # Preservar el índice temporal\n",
    "                scaled_data = self.scaler.fit_transform(data[numeric_cols])\n",
    "                data[numeric_cols] = scaled_data\n",
    "            return data\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en normalización: {str(e)}\")\n",
    "            return data\n",
    "\n",
    "    def _perform_statistical_analysis(self, data: pd.DataFrame):\n",
    "        \"\"\"Realiza análisis estadístico de los datos\"\"\"\n",
    "        try:\n",
    "            numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "            \n",
    "            for column in numeric_cols:\n",
    "                self.stats[column] = {\n",
    "                    'basic_stats': {\n",
    "                        'mean': float(data[column].mean()),\n",
    "                        'std': float(data[column].std()),\n",
    "                        'min': float(data[column].min()),\n",
    "                        'max': float(data[column].max()),\n",
    "                        'median': float(data[column].median())\n",
    "                    },\n",
    "                    'distribution': {\n",
    "                        'skewness': float(data[column].skew()),\n",
    "                        'kurtosis': float(data[column].kurtosis())\n",
    "                    }\n",
    "                }\n",
    "            \n",
    "            if len(numeric_cols) > 1:\n",
    "                self.stats['correlations'] = data[numeric_cols].corr().to_dict()\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en análisis estadístico: {str(e)}\")\n",
    "\n",
    "    def _analyze_temporal_structure(self, data: pd.DataFrame):\n",
    "        \"\"\"Analiza la estructura temporal de los datos\"\"\"\n",
    "        try:\n",
    "            # Análisis de frecuencia de muestreo\n",
    "            freq = self._detect_sampling_frequency(data)\n",
    "            \n",
    "            self.quality_report['temporal_stats'] = {\n",
    "                'sampling_frequency': freq,\n",
    "                'start_time': data.index.min(),\n",
    "                'end_time': data.index.max(),\n",
    "                'total_duration': str(data.index.max() - data.index.min()),\n",
    "                'gaps': self._detect_temporal_gaps(data)\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en análisis temporal: {str(e)}\")\n",
    "\n",
    "    def _detect_sampling_frequency(self, data: pd.DataFrame) -> str:\n",
    "        \"\"\"Detecta la frecuencia de muestreo predominante\"\"\"\n",
    "        try:\n",
    "            # Calcular diferencias entre timestamps consecutivos\n",
    "            time_diffs = data.index.to_series().diff()\n",
    "            most_common_diff = time_diffs.mode()[0]\n",
    "            \n",
    "            # Convertir a string formato frecuencia pandas\n",
    "            seconds = most_common_diff.total_seconds()\n",
    "            if seconds < 60:\n",
    "                return f\"{int(seconds)}S\"\n",
    "            elif seconds < 3600:\n",
    "                return f\"{int(seconds/60)}T\"\n",
    "            else:\n",
    "                return f\"{int(seconds/3600)}H\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error detectando frecuencia: {str(e)}\")\n",
    "            return \"Unknown\"\n",
    "\n",
    "    def _detect_temporal_gaps(self, data: pd.DataFrame) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Detecta gaps significativos en la serie temporal\"\"\"\n",
    "        try:\n",
    "            time_diffs = data.index.to_series().diff()\n",
    "            freq = pd.Timedelta(self._detect_sampling_frequency(data))\n",
    "            gaps = []\n",
    "            \n",
    "            # Detectar diferencias mayores a 2 veces la frecuencia normal\n",
    "            significant_gaps = time_diffs[time_diffs > 2 * freq]\n",
    "            \n",
    "            for idx, gap in significant_gaps.items():\n",
    "                gaps.append({\n",
    "                    'start': str(idx - gap),\n",
    "                    'end': str(idx),\n",
    "                    'duration': str(gap)\n",
    "                })\n",
    "                \n",
    "            return gaps\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error detectando gaps: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "# Función de prueba\n",
    "def test_preprocessing():\n",
    "    \"\"\"Prueba el preprocesamiento de datos\"\"\"\n",
    "    try:\n",
    "        print(\"\\n=== PRUEBA DE PREPROCESAMIENTO ===\\n\")\n",
    "        \n",
    "        # Crear instancia del preprocesador\n",
    "        preprocessor = DataPreprocessor()\n",
    "        \n",
    "        # Procesar datos\n",
    "        data_path = \"filtered_consolidated_data_cleaned.xlsx\"\n",
    "        processed_data, results = preprocessor.process_data(data_path)\n",
    "        \n",
    "        if processed_data is not None:\n",
    "            print(\"\\nResumen del procesamiento:\")\n",
    "            print(f\"Forma inicial: {results['processing_summary']['initial_shape']}\")\n",
    "            print(f\"Forma final: {results['processing_summary']['final_shape']}\")\n",
    "            print(f\"\\nRango temporal:\")\n",
    "            print(f\"Inicio: {results['temporal_range']['start']}\")\n",
    "            print(f\"Fin: {results['temporal_range']['end']}\")\n",
    "            print(f\"Frecuencia: {results['temporal_range']['frequency']}\")\n",
    "            \n",
    "            # Mostrar primeras filas de datos procesados\n",
    "            print(\"\\nMuestra de datos procesados:\")\n",
    "            print(processed_data.head())\n",
    "            \n",
    "            return processed_data, results\n",
    "        else:\n",
    "            print(\"Error en el preprocesamiento\")\n",
    "            return None, None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error en prueba: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "# Ejecutar prueba\n",
    "processed_data, preprocessing_results = test_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-27 09:55:15,867 - __main__ - INFO - Iniciando análisis de variables...\n",
      "2024-12-27 09:55:15,867 - INFO - Iniciando análisis de variables...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PRUEBA DE ANÁLISIS DE VARIABLES ===\n",
      "\n",
      "Analizando 56 variables numéricas...\n",
      "Rango temporal: 2013-05-04 16:07:00 a 2013-05-09 15:07:00\n",
      "\n",
      "Variables más importantes:\n",
      "Armónicos IL1: Armónico 3 (%IL1): 0.730\n",
      "Armónicos IL1: Armónico 2 (%IL1): 0.706\n",
      "Distorsión armónica: IL1 (%I THD): 0.699\n",
      "Armónicos VL3: Armónico 5 (%VL3): 0.685\n",
      "Armónicos VL2: Armónico 5 (%VL2): 0.679\n",
      "Armónicos IL2: Armónico 7 (%IL2): 0.670\n",
      "Armónicos VL1: Armónico 5 (%VL1): 0.670\n",
      "Armónicos IL1: Armónico 7 (%IL1): 0.658\n",
      "Corriente: L1 (A): 0.654\n",
      "Armónicos IL1: Armónico 5 (%IL1): 0.639\n",
      "Tensión: L2 - L3 (V): 0.637\n",
      "\n",
      "Estado de validación:\n",
      "Baseline: ✓\n",
      "Prediction: ✓\n"
     ]
    }
   ],
   "source": [
    "# CELDA 3: Fase 2 - Identificación de Variables Clave\n",
    "\"\"\"\n",
    "Fase 2: Identificación de Variables Clave\n",
    "=======================================\n",
    "\n",
    "Objetivos:\n",
    "1. Identificar variables críticas para prognosis\n",
    "2. Evaluar importancia multifactorial\n",
    "3. Analizar patrones temporales\n",
    "4. Determinar correlaciones significativas\n",
    "5. Asegurar integración robusta con fases posteriores\n",
    "\n",
    "Características:\n",
    "- Análisis multidimensional con preservación temporal\n",
    "- Categorización adaptativa de variables\n",
    "- Tracking de cambios en variables críticas\n",
    "- Validación de estructura de datos\n",
    "- Integración validada con fases posteriores\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import logging\n",
    "from typing import Dict, List, Any, Optional, Union\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "class VariableAnalyzer:\n",
    "    def __init__(self):\n",
    "        self._setup_logging()\n",
    "        self.scaler = RobustScaler()\n",
    "        self.results = {\n",
    "            'importance_scores': {},\n",
    "            'temporal_patterns': {},\n",
    "            'correlations': {},\n",
    "            'selected_variables': {},\n",
    "            'categories': {\n",
    "                'critical': {},      \n",
    "                'monitoring': {},    \n",
    "                'supporting': {}     \n",
    "            },\n",
    "            'metrics': {},\n",
    "            'data_structure': {      \n",
    "                'temporal_format': None,\n",
    "                'sampling_rate': None,\n",
    "                'variable_metadata': {}\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        self.state = {\n",
    "            'last_update': None,\n",
    "            'variable_history': {},\n",
    "            'structure_changes': [],\n",
    "            'validation_status': {}\n",
    "        }\n",
    "        \n",
    "        self.thresholds = {\n",
    "            'correlation': 0.7,\n",
    "            'importance': 0.6,\n",
    "            'stability': 0.5,\n",
    "            'change_point': 2.0\n",
    "        }\n",
    "\n",
    "    def _setup_logging(self):\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        if not self.logger.handlers:\n",
    "            handler = logging.StreamHandler()\n",
    "            formatter = logging.Formatter(\n",
    "                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "            )\n",
    "            handler.setFormatter(formatter)\n",
    "            self.logger.addHandler(handler)\n",
    "            self.logger.setLevel(logging.INFO)\n",
    "\n",
    "    def analyze_variables(self, data: pd.DataFrame) -> Dict[str, Any]:\n",
    "        try:\n",
    "            self.logger.info(\"Iniciando análisis de variables...\")\n",
    "            \n",
    "            structure_valid = self._analyze_data_structure(data)\n",
    "            if not structure_valid:\n",
    "                raise ValueError(\"Estructura de datos inválida\")\n",
    "            \n",
    "            self.data = self._prepare_data(data)\n",
    "            self.numeric_data = self.data.select_dtypes(include=[np.number])\n",
    "            \n",
    "            print(f\"Analizando {len(self.numeric_data.columns)} variables numéricas...\")\n",
    "            print(f\"Rango temporal: {data.index.min()} a {data.index.max()}\")\n",
    "            \n",
    "            for column in self.numeric_data.columns:\n",
    "                self._analyze_single_variable(column)\n",
    "                self._track_variable_changes(column)\n",
    "            \n",
    "            self._analyze_correlations()\n",
    "            self._update_categories()\n",
    "            self._validate_results()\n",
    "            \n",
    "            self.state['last_update'] = pd.Timestamp.now()\n",
    "            return self.results\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en análisis: {str(e)}\")\n",
    "            return None\n",
    "        \n",
    "    def _analyze_data_structure(self, data: pd.DataFrame) -> bool:\n",
    "        try:\n",
    "            if not isinstance(data.index, pd.DatetimeIndex):\n",
    "                self.logger.error(\"Se requiere índice temporal\")\n",
    "                return False\n",
    "            \n",
    "            freq = pd.infer_freq(data.index)\n",
    "            sampling = data.index.to_series().diff().mode()[0]\n",
    "            \n",
    "            self.results['data_structure'].update({\n",
    "                'temporal_format': str(data.index.dtype),\n",
    "                'sampling_rate': str(sampling),\n",
    "                'frequency': str(freq),\n",
    "                'timestamp_format': data.index.strftime('%Y-%m-%d %H:%M:%S')[0]\n",
    "            })\n",
    "            \n",
    "            for column in data.columns:\n",
    "                self.results['data_structure']['variable_metadata'][column] = {\n",
    "                    'dtype': str(data[column].dtype),\n",
    "                    'missing_pct': float(data[column].isnull().mean()),\n",
    "                    'unique_count': int(data[column].nunique()),\n",
    "                    'range': {\n",
    "                        'min': float(data[column].min()) if pd.api.types.is_numeric_dtype(data[column]) else None,\n",
    "                        'max': float(data[column].max()) if pd.api.types.is_numeric_dtype(data[column]) else None\n",
    "                    }\n",
    "                }\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en análisis de estructura: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def _prepare_data(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Prepara los datos para el análisis manteniendo la normalización original\n",
    "        de la fase de preprocesamiento.\n",
    "        \n",
    "        Args:\n",
    "            data: DataFrame con datos ya normalizados de la fase 1\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame: Datos preparados solo con interpolación si es necesaria\n",
    "        \"\"\"\n",
    "        try:\n",
    "            prepared_data = data.copy()\n",
    "            \n",
    "            # Solo realizar interpolación para valores faltantes\n",
    "            for column in prepared_data.columns:\n",
    "                if prepared_data[column].isnull().any():\n",
    "                    prepared_data[column] = prepared_data[column].interpolate(\n",
    "                        method='time',\n",
    "                        limit=24,\n",
    "                        limit_direction='both'\n",
    "                    )\n",
    "            \n",
    "            return prepared_data\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en preparación de datos: {str(e)}\")\n",
    "            return data\n",
    "\n",
    "    def _analyze_single_variable(self, column: str):\n",
    "        try:\n",
    "            series = self.numeric_data[column]\n",
    "            importance_score = self._calculate_importance_score(series)\n",
    "            temporal_patterns = self._analyze_temporal_patterns(series)\n",
    "            stability = self._calculate_stability(series)\n",
    "            \n",
    "            self.results['importance_scores'][column] = {\n",
    "                'combined_score': importance_score['combined_score'],\n",
    "                'components': importance_score['components'],\n",
    "                'temporal_analysis': temporal_patterns,\n",
    "                'stability': stability\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en análisis de {column}: {str(e)}\")\n",
    "\n",
    "    def _track_variable_changes(self, column: str):\n",
    "        \"\"\"\n",
    "        Rastrea cambios en las variables a lo largo del tiempo\n",
    "        \n",
    "        Args:\n",
    "            column: Nombre de la variable a rastrear\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if column not in self.state['variable_history']:\n",
    "                self.state['variable_history'][column] = []  # Cambiado a lista\n",
    "            \n",
    "            current_stats = {\n",
    "                'timestamp': pd.Timestamp.now(),\n",
    "                'mean': float(self.numeric_data[column].mean()),\n",
    "                'std': float(self.numeric_data[column].std()),\n",
    "                'stability': self._calculate_stability(self.numeric_data[column])\n",
    "            }\n",
    "            \n",
    "            self.state['variable_history'][column].append(current_stats)  # Ahora append funciona\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en tracking de variable {column}: {str(e)}\")\n",
    "\n",
    "    def _calculate_temporal_stats(self, series: pd.Series) -> Dict[str, float]:\n",
    "        try:\n",
    "            # Calcular estadísticas temporales básicas\n",
    "            acf_values = acf(series.fillna(method='ffill'), nlags=min(len(series)-1, 48))\n",
    "            \n",
    "            return {\n",
    "                'temporal_stability': 1 - series.std() / (series.max() - series.min()),\n",
    "                'trend_strength': abs(stats.linregress(np.arange(len(series)), series)[2]),\n",
    "                'autocorrelation': float(acf_values[1]) if len(acf_values) > 1 else 0.0\n",
    "            }\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en estadísticas temporales: {str(e)}\")\n",
    "            return {'temporal_stability': 0.0, 'trend_strength': 0.0, 'autocorrelation': 0.0}\n",
    "\n",
    "    def _calculate_importance_score(self, series: pd.Series) -> Dict[str, Any]:\n",
    "        try:\n",
    "            variance = float(series.var())\n",
    "            std = float(series.std())\n",
    "            range_size = float(series.max() - series.min())\n",
    "            \n",
    "            temporal_stats = self._calculate_temporal_stats(series)\n",
    "            \n",
    "            weights = {\n",
    "                'variance': 0.15,\n",
    "                'temporal_stability': 0.25,\n",
    "                'trend_strength': 0.3,\n",
    "                'autocorrelation': 0.3\n",
    "            }\n",
    "            \n",
    "            components = {\n",
    "                'variance': min(variance / range_size, 1.0),\n",
    "                'temporal_stability': temporal_stats['temporal_stability'],\n",
    "                'trend_strength': temporal_stats['trend_strength'],\n",
    "                'autocorrelation': abs(temporal_stats['autocorrelation'])\n",
    "            }\n",
    "            \n",
    "            combined_score = sum(components[k] * weights[k] for k in weights)\n",
    "            \n",
    "            return {\n",
    "                'combined_score': float(min(max(combined_score, 0), 1)),\n",
    "                'components': components\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en cálculo de importancia: {str(e)}\")\n",
    "            return {'combined_score': 0.0, 'components': {}}\n",
    "\n",
    "    def _estimate_seasonality_period(self, series: pd.Series) -> int:\n",
    "        try:\n",
    "            n_lags = min(len(series)-1, 168)  # Máximo 1 semana\n",
    "            acf_values = acf(series.fillna(method='ffill'), nlags=n_lags)\n",
    "            peaks, _ = find_peaks(acf_values, height=0.3)\n",
    "            return int(peaks[0]) if len(peaks) > 0 else 24\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en estimación de estacionalidad: {str(e)}\")\n",
    "            return 24\n",
    "\n",
    "    def _analyze_temporal_patterns(self, series: pd.Series) -> Dict[str, Any]:\n",
    "        try:\n",
    "            period = self._estimate_seasonality_period(series)\n",
    "            decomposition = seasonal_decompose(\n",
    "                series.fillna(method='ffill'),\n",
    "                period=period\n",
    "            )\n",
    "            \n",
    "            trend = decomposition.trend\n",
    "            seasonal = decomposition.seasonal\n",
    "            residual = decomposition.resid\n",
    "            \n",
    "            change_points = self._detect_change_points(series)\n",
    "            \n",
    "            return {\n",
    "                'trend_strength': float(1 - (residual.std() / series.std())),\n",
    "                'seasonal_strength': float(1 - (residual.std() / seasonal.std())),\n",
    "                'seasonality_period': int(period),\n",
    "                'change_points': change_points\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en análisis temporal: {str(e)}\")\n",
    "            return {}\n",
    "\n",
    "    def _detect_change_points(self, series: pd.Series) -> List[Dict[str, Any]]:\n",
    "        try:\n",
    "            rolling_mean = series.rolling(window=24).mean()\n",
    "            rolling_std = series.rolling(window=24).std()\n",
    "            z_scores = abs(series - rolling_mean) / rolling_std\n",
    "            \n",
    "            change_points = []\n",
    "            for idx in range(len(z_scores)):\n",
    "                if z_scores[idx] > self.thresholds['change_point']:\n",
    "                    change_points.append({\n",
    "                        'timestamp': str(series.index[idx]),\n",
    "                        'score': float(z_scores[idx])\n",
    "                    })\n",
    "            \n",
    "            return change_points\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en detección de cambios: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "   \n",
    "\n",
    "    def _analyze_correlations(self):\n",
    "        try:\n",
    "            corr_matrix = self.numeric_data.corr()\n",
    "            self.results['correlations'] = {}\n",
    "            \n",
    "            for col1 in corr_matrix.columns:\n",
    "                self.results['correlations'][col1] = {}\n",
    "                for col2 in corr_matrix.columns:\n",
    "                    if col1 != col2 and abs(corr_matrix.loc[col1, col2]) > self.thresholds['correlation']:\n",
    "                        self.results['correlations'][col1][col2] = float(corr_matrix.loc[col1, col2])\n",
    "                        \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en análisis de correlaciones: {str(e)}\")\n",
    "\n",
    "    def _get_current_category(self, var: str) -> str:\n",
    "        for category, vars_dict in self.results['categories'].items():\n",
    "            if var in vars_dict:\n",
    "                return category\n",
    "        return 'supporting'\n",
    "\n",
    "    def _track_category_change(self, var: str, old_cat: str, new_cat: str):\n",
    "        if var not in self.state['variable_history']:\n",
    "            self.state['variable_history'][var] = []\n",
    "            \n",
    "        self.state['variable_history'][var].append({\n",
    "            'timestamp': pd.Timestamp.now(),\n",
    "            'old_category': old_cat,\n",
    "            'new_category': new_cat\n",
    "        })\n",
    "\n",
    "    def _calculate_stability(self, series: pd.Series) -> float:\n",
    "        \"\"\"\n",
    "        Calcula la estabilidad temporal de una serie\n",
    "        \n",
    "        Args:\n",
    "            series: Serie temporal a analizar\n",
    "            \n",
    "        Returns:\n",
    "            float: Score de estabilidad entre 0 y 1\n",
    "        \"\"\"\n",
    "        try:\n",
    "            rolling_std = series.rolling(window=24).std()\n",
    "            stability = 1 - (rolling_std.mean() / series.std())\n",
    "            return float(max(0, min(1, stability)))\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en cálculo de estabilidad: {str(e)}\")\n",
    "            return 0.0\n",
    "\n",
    "    def _update_categories(self):\n",
    "        try:\n",
    "            importance_scores = {\n",
    "                k: v['combined_score'] \n",
    "                for k, v in self.results['importance_scores'].items()\n",
    "            }\n",
    "            sorted_vars = sorted(importance_scores.items(), \n",
    "                               key=lambda x: x[1], \n",
    "                               reverse=True)\n",
    "            \n",
    "            scores = np.array([score for _, score in sorted_vars])\n",
    "            critical_threshold = np.percentile(scores, 80)\n",
    "            monitoring_threshold = np.percentile(scores, 50)\n",
    "            \n",
    "            for var, score in sorted_vars:\n",
    "                old_category = self._get_current_category(var)\n",
    "                \n",
    "                if score >= critical_threshold:\n",
    "                    new_category = 'critical'\n",
    "                elif score >= monitoring_threshold:\n",
    "                    new_category = 'monitoring'\n",
    "                else:\n",
    "                    new_category = 'supporting'\n",
    "                \n",
    "                if old_category != new_category:\n",
    "                    self._track_category_change(var, old_category, new_category)\n",
    "                \n",
    "                self.results['categories'][new_category][var] = {\n",
    "                    'importance_score': score,\n",
    "                    'temporal_stability': self._calculate_stability(self.numeric_data[var]),\n",
    "                    'last_update': pd.Timestamp.now()\n",
    "                }\n",
    "            \n",
    "            self.results['selected_variables'] = {\n",
    "                var: score for var, score in sorted_vars[:int(len(sorted_vars) * 0.2)]\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en actualización de categorías: {str(e)}\")\n",
    "\n",
    "    def _validate_results(self):\n",
    "        try:\n",
    "            validation_status = {\n",
    "                'complete': True,\n",
    "                'warnings': []\n",
    "            }\n",
    "            \n",
    "            # Validar variables críticas\n",
    "            if not self.results['categories']['critical']:\n",
    "                validation_status['warnings'].append(\"No se identificaron variables críticas\")\n",
    "                validation_status['complete'] = False\n",
    "            \n",
    "            # Validar análisis temporal\n",
    "            for var in self.results['selected_variables']:\n",
    "                if var not in self.results['temporal_patterns']:\n",
    "                    validation_status['warnings'].append(f\"Falta análisis temporal para {var}\")\n",
    "                    validation_status['complete'] = False\n",
    "            \n",
    "            self.state['validation_status']['results'] = validation_status\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en validación de resultados: {str(e)}\")\n",
    "\n",
    "    def validate_integration(self, phase: str) -> Dict[str, Any]:\n",
    "        try:\n",
    "            validation = {\n",
    "                'status': True,\n",
    "                'warnings': [],\n",
    "                'recommendations': []\n",
    "            }\n",
    "            \n",
    "            if phase == 'baseline':\n",
    "                self._validate_baseline_requirements(validation)\n",
    "            elif phase == 'prediction':\n",
    "                self._validate_prediction_requirements(validation)\n",
    "            \n",
    "            self.state['validation_status'][phase] = validation\n",
    "            return validation\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en validación: {str(e)}\")\n",
    "            return {'status': False, 'error': str(e)}\n",
    "\n",
    "    def _validate_baseline_requirements(self, validation: Dict):\n",
    "        if not self.results['selected_variables']:\n",
    "            validation['status'] = False\n",
    "            validation['warnings'].append(\"No hay variables seleccionadas\")\n",
    "        \n",
    "        for var in self.results['selected_variables']:\n",
    "            if var not in self.results['temporal_patterns']:\n",
    "                validation['warnings'].append(f\"Falta análisis temporal para {var}\")\n",
    "\n",
    "    def _validate_prediction_requirements(self, validation: Dict):\n",
    "        if not self.results['categories']['critical']:\n",
    "            validation['status'] = False\n",
    "            validation['warnings'].append(\"No hay variables críticas identificadas\")\n",
    "\n",
    "def test_variable_analysis(data: pd.DataFrame):\n",
    "    try:\n",
    "        print(\"\\n=== PRUEBA DE ANÁLISIS DE VARIABLES ===\\n\")\n",
    "        \n",
    "        analyzer = VariableAnalyzer()\n",
    "        results = analyzer.analyze_variables(data)\n",
    "        \n",
    "        if results:\n",
    "            print(\"\\nVariables más importantes:\")\n",
    "            for var, score in sorted(\n",
    "                results['selected_variables'].items(), \n",
    "                key=lambda x: x[1], \n",
    "                reverse=True\n",
    "            ):\n",
    "                print(f\"{var}: {score:.3f}\")\n",
    "            \n",
    "            baseline_validation = analyzer.validate_integration('baseline')\n",
    "            prediction_validation = analyzer.validate_integration('prediction')\n",
    "            \n",
    "            print(\"\\nEstado de validación:\")\n",
    "            print(f\"Baseline: {'✓' if baseline_validation['status'] else '✗'}\")\n",
    "            print(f\"Prediction: {'✓' if prediction_validation['status'] else '✗'}\")\n",
    "            \n",
    "            return analyzer\n",
    "        else:\n",
    "            print(\"Error en análisis de variables\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error en prueba: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "if 'processed_data' in globals():\n",
    "    variable_analyzer = test_variable_analysis(processed_data)\n",
    "else:\n",
    "    print(\"Error: Ejecutar primero el preprocesamiento de datos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-27 09:55:24,585 - __main__ - INFO - Iniciando aprendizaje de línea base para 11 variables...\n",
      "2024-12-27 09:55:24,585 - INFO - Iniciando aprendizaje de línea base para 11 variables...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PRUEBA DE APRENDIZAJE DE LÍNEA BASE ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-27 09:56:20,603 - __main__ - INFO - \n",
      "            === Iniciando validación ===\n",
      "            Serie original:\n",
      "            - Shape: (914,)\n",
      "            - Valores finitos: 914\n",
      "            - Rango: [-0.070, 0.296]\n",
      "            \n",
      "2024-12-27 09:56:20,603 - INFO - \n",
      "            === Iniciando validación ===\n",
      "            Serie original:\n",
      "            - Shape: (914,)\n",
      "            - Valores finitos: 914\n",
      "            - Rango: [-0.070, 0.296]\n",
      "            \n",
      "2024-12-27 09:56:20,873 - __main__ - INFO - \n",
      "            Serie limpia:\n",
      "            - Shape: (914,)\n",
      "            - Rango índices: [2013-05-08 22:28:00, 2013-05-09 15:06:00]\n",
      "            \n",
      "2024-12-27 09:56:20,873 - INFO - \n",
      "            Serie limpia:\n",
      "            - Shape: (914,)\n",
      "            - Rango índices: [2013-05-08 22:28:00, 2013-05-09 15:06:00]\n",
      "            \n",
      "2024-12-27 09:56:21,823 - __main__ - INFO - \n",
      "            === Iniciando validación ===\n",
      "            Serie original:\n",
      "            - Shape: (933,)\n",
      "            - Valores finitos: 933\n",
      "            - Rango: [-1.250, 0.250]\n",
      "            \n",
      "2024-12-27 09:56:21,823 - INFO - \n",
      "            === Iniciando validación ===\n",
      "            Serie original:\n",
      "            - Shape: (933,)\n",
      "            - Valores finitos: 933\n",
      "            - Rango: [-1.250, 0.250]\n",
      "            \n",
      "2024-12-27 09:56:22,046 - __main__ - INFO - \n",
      "            Serie limpia:\n",
      "            - Shape: (933,)\n",
      "            - Rango índices: [2013-05-08 22:28:00, 2013-05-09 15:07:00]\n",
      "            \n",
      "2024-12-27 09:56:22,046 - INFO - \n",
      "            Serie limpia:\n",
      "            - Shape: (933,)\n",
      "            - Rango índices: [2013-05-08 22:28:00, 2013-05-09 15:07:00]\n",
      "            \n",
      "2024-12-27 09:56:29,869 - __main__ - INFO - \n",
      "            === Iniciando validación ===\n",
      "            Serie original:\n",
      "            - Shape: (912,)\n",
      "            - Valores finitos: 912\n",
      "            - Rango: [-0.138, 0.500]\n",
      "            \n",
      "2024-12-27 09:56:29,869 - INFO - \n",
      "            === Iniciando validación ===\n",
      "            Serie original:\n",
      "            - Shape: (912,)\n",
      "            - Valores finitos: 912\n",
      "            - Rango: [-0.138, 0.500]\n",
      "            \n",
      "2024-12-27 09:56:30,440 - __main__ - INFO - \n",
      "            Serie limpia:\n",
      "            - Shape: (912,)\n",
      "            - Rango índices: [2013-05-08 22:28:00, 2013-05-09 15:03:00]\n",
      "            \n",
      "2024-12-27 09:56:30,440 - INFO - \n",
      "            Serie limpia:\n",
      "            - Shape: (912,)\n",
      "            - Rango índices: [2013-05-08 22:28:00, 2013-05-09 15:03:00]\n",
      "            \n",
      "2024-12-27 09:56:48,263 - __main__ - INFO - \n",
      "            === Iniciando validación ===\n",
      "            Serie original:\n",
      "            - Shape: (901,)\n",
      "            - Valores finitos: 901\n",
      "            - Rango: [-0.135, 0.056]\n",
      "            \n",
      "2024-12-27 09:56:48,263 - INFO - \n",
      "            === Iniciando validación ===\n",
      "            Serie original:\n",
      "            - Shape: (901,)\n",
      "            - Valores finitos: 901\n",
      "            - Rango: [-0.135, 0.056]\n",
      "            \n",
      "2024-12-27 09:56:48,700 - __main__ - INFO - \n",
      "            Serie limpia:\n",
      "            - Shape: (901,)\n",
      "            - Rango índices: [2013-05-08 22:28:00, 2013-05-09 15:07:00]\n",
      "            \n",
      "2024-12-27 09:56:48,700 - INFO - \n",
      "            Serie limpia:\n",
      "            - Shape: (901,)\n",
      "            - Rango índices: [2013-05-08 22:28:00, 2013-05-09 15:07:00]\n",
      "            \n",
      "2024-12-27 09:56:54,641 - __main__ - INFO - \n",
      "                Predicciones generadas:\n",
      "                - Shape predicción: (914,)\n",
      "                - Shape intervalos: (914, 2)\n",
      "                - Valores finitos predicción: 914\n",
      "                \n",
      "2024-12-27 09:56:54,641 - INFO - \n",
      "                Predicciones generadas:\n",
      "                - Shape predicción: (914,)\n",
      "                - Shape intervalos: (914, 2)\n",
      "                - Valores finitos predicción: 914\n",
      "                \n",
      "2024-12-27 09:56:55,543 - __main__ - INFO - \n",
      "                Métricas finales:\n",
      "                - MSE: 0.000717\n",
      "                - MAE: 0.019976\n",
      "                - Cobertura: 0.826\n",
      "                - Puntos dentro de límites: 755\n",
      "                \n",
      "2024-12-27 09:56:55,543 - INFO - \n",
      "                Métricas finales:\n",
      "                - MSE: 0.000717\n",
      "                - MAE: 0.019976\n",
      "                - Cobertura: 0.826\n",
      "                - Puntos dentro de límites: 755\n",
      "                \n",
      "2024-12-27 09:56:57,731 - __main__ - INFO - Variable Distorsión armónica: IL1 (%I THD) procesada exitosamente\n",
      "2024-12-27 09:56:57,731 - INFO - Variable Distorsión armónica: IL1 (%I THD) procesada exitosamente\n",
      "2024-12-27 09:56:59,881 - __main__ - INFO - \n",
      "                Predicciones generadas:\n",
      "                - Shape predicción: (933,)\n",
      "                - Shape intervalos: (933, 2)\n",
      "                - Valores finitos predicción: 933\n",
      "                \n",
      "2024-12-27 09:56:59,881 - INFO - \n",
      "                Predicciones generadas:\n",
      "                - Shape predicción: (933,)\n",
      "                - Shape intervalos: (933, 2)\n",
      "                - Valores finitos predicción: 933\n",
      "                \n",
      "2024-12-27 09:57:00,751 - __main__ - INFO - \n",
      "                Métricas finales:\n",
      "                - MSE: 0.007599\n",
      "                - MAE: 0.048799\n",
      "                - Cobertura: 0.852\n",
      "                - Puntos dentro de límites: 795\n",
      "                \n",
      "2024-12-27 09:57:00,751 - INFO - \n",
      "                Métricas finales:\n",
      "                - MSE: 0.007599\n",
      "                - MAE: 0.048799\n",
      "                - Cobertura: 0.852\n",
      "                - Puntos dentro de límites: 795\n",
      "                \n",
      "2024-12-27 09:57:01,249 - __main__ - INFO - Variable Armónicos VL3: Armónico 5 (%VL3) procesada exitosamente\n",
      "2024-12-27 09:57:01,249 - INFO - Variable Armónicos VL3: Armónico 5 (%VL3) procesada exitosamente\n",
      "2024-12-27 09:57:17,628 - __main__ - INFO - \n",
      "                Predicciones generadas:\n",
      "                - Shape predicción: (912,)\n",
      "                - Shape intervalos: (912, 2)\n",
      "                - Valores finitos predicción: 912\n",
      "                \n",
      "2024-12-27 09:57:17,628 - INFO - \n",
      "                Predicciones generadas:\n",
      "                - Shape predicción: (912,)\n",
      "                - Shape intervalos: (912, 2)\n",
      "                - Valores finitos predicción: 912\n",
      "                \n",
      "2024-12-27 09:57:19,036 - __main__ - INFO - \n",
      "                Métricas finales:\n",
      "                - MSE: 0.001660\n",
      "                - MAE: 0.025454\n",
      "                - Cobertura: 0.875\n",
      "                - Puntos dentro de límites: 798\n",
      "                \n",
      "2024-12-27 09:57:19,036 - INFO - \n",
      "                Métricas finales:\n",
      "                - MSE: 0.001660\n",
      "                - MAE: 0.025454\n",
      "                - Cobertura: 0.875\n",
      "                - Puntos dentro de límites: 798\n",
      "                \n",
      "2024-12-27 09:57:20,462 - __main__ - INFO - Variable Armónicos IL1: Armónico 3 (%IL1) procesada exitosamente\n",
      "2024-12-27 09:57:20,462 - INFO - Variable Armónicos IL1: Armónico 3 (%IL1) procesada exitosamente\n",
      "2024-12-27 09:57:46,952 - __main__ - INFO - \n",
      "                Predicciones generadas:\n",
      "                - Shape predicción: (901,)\n",
      "                - Shape intervalos: (901, 2)\n",
      "                - Valores finitos predicción: 901\n",
      "                \n",
      "2024-12-27 09:57:46,952 - INFO - \n",
      "                Predicciones generadas:\n",
      "                - Shape predicción: (901,)\n",
      "                - Shape intervalos: (901, 2)\n",
      "                - Valores finitos predicción: 901\n",
      "                \n",
      "2024-12-27 09:57:47,172 - __main__ - INFO - \n",
      "                Métricas finales:\n",
      "                - MSE: 0.000290\n",
      "                - MAE: 0.013229\n",
      "                - Cobertura: 0.819\n",
      "                - Puntos dentro de límites: 738\n",
      "                \n",
      "2024-12-27 09:57:47,172 - INFO - \n",
      "                Métricas finales:\n",
      "                - MSE: 0.000290\n",
      "                - MAE: 0.013229\n",
      "                - Cobertura: 0.819\n",
      "                - Puntos dentro de límites: 738\n",
      "                \n",
      "2024-12-27 09:57:47,576 - __main__ - INFO - Variable Armónicos IL1: Armónico 2 (%IL1) procesada exitosamente\n",
      "2024-12-27 09:57:47,576 - INFO - Variable Armónicos IL1: Armónico 2 (%IL1) procesada exitosamente\n",
      "2024-12-27 09:57:55,172 - __main__ - INFO - \n",
      "            === Iniciando validación ===\n",
      "            Serie original:\n",
      "            - Shape: (914,)\n",
      "            - Valores finitos: 914\n",
      "            - Rango: [-0.273, 2.182]\n",
      "            \n",
      "2024-12-27 09:57:55,172 - INFO - \n",
      "            === Iniciando validación ===\n",
      "            Serie original:\n",
      "            - Shape: (914,)\n",
      "            - Valores finitos: 914\n",
      "            - Rango: [-0.273, 2.182]\n",
      "            \n",
      "2024-12-27 09:57:56,009 - __main__ - INFO - \n",
      "            Serie limpia:\n",
      "            - Shape: (914,)\n",
      "            - Rango índices: [2013-05-08 22:28:00, 2013-05-09 15:07:00]\n",
      "            \n",
      "2024-12-27 09:57:56,009 - INFO - \n",
      "            Serie limpia:\n",
      "            - Shape: (914,)\n",
      "            - Rango índices: [2013-05-08 22:28:00, 2013-05-09 15:07:00]\n",
      "            \n",
      "2024-12-27 09:58:16,688 - __main__ - INFO - \n",
      "            === Iniciando validación ===\n",
      "            Serie original:\n",
      "            - Shape: (940,)\n",
      "            - Valores finitos: 940\n",
      "            - Rango: [-1.000, 0.400]\n",
      "            \n",
      "2024-12-27 09:58:16,688 - INFO - \n",
      "            === Iniciando validación ===\n",
      "            Serie original:\n",
      "            - Shape: (940,)\n",
      "            - Valores finitos: 940\n",
      "            - Rango: [-1.000, 0.400]\n",
      "            \n",
      "2024-12-27 09:58:17,081 - __main__ - INFO - \n",
      "            Serie limpia:\n",
      "            - Shape: (940,)\n",
      "            - Rango índices: [2013-05-08 22:32:00, 2013-05-09 15:07:00]\n",
      "            \n",
      "2024-12-27 09:58:17,081 - INFO - \n",
      "            Serie limpia:\n",
      "            - Shape: (940,)\n",
      "            - Rango índices: [2013-05-08 22:32:00, 2013-05-09 15:07:00]\n",
      "            \n",
      "2024-12-27 09:58:24,869 - __main__ - INFO - \n",
      "                Predicciones generadas:\n",
      "                - Shape predicción: (914,)\n",
      "                - Shape intervalos: (914, 2)\n",
      "                - Valores finitos predicción: 914\n",
      "                \n",
      "2024-12-27 09:58:24,869 - INFO - \n",
      "                Predicciones generadas:\n",
      "                - Shape predicción: (914,)\n",
      "                - Shape intervalos: (914, 2)\n",
      "                - Valores finitos predicción: 914\n",
      "                \n",
      "2024-12-27 09:58:24,998 - __main__ - INFO - \n",
      "            === Iniciando validación ===\n",
      "            Serie original:\n",
      "            - Shape: (956,)\n",
      "            - Valores finitos: 956\n",
      "            - Rango: [-1.000, 0.400]\n",
      "            \n",
      "2024-12-27 09:58:24,998 - INFO - \n",
      "            === Iniciando validación ===\n",
      "            Serie original:\n",
      "            - Shape: (956,)\n",
      "            - Valores finitos: 956\n",
      "            - Rango: [-1.000, 0.400]\n",
      "            \n",
      "2024-12-27 09:58:25,463 - __main__ - INFO - \n",
      "                Métricas finales:\n",
      "                - MSE: 0.010397\n",
      "                - MAE: 0.063363\n",
      "                - Cobertura: 0.902\n",
      "                - Puntos dentro de límites: 824\n",
      "                \n",
      "2024-12-27 09:58:25,463 - INFO - \n",
      "                Métricas finales:\n",
      "                - MSE: 0.010397\n",
      "                - MAE: 0.063363\n",
      "                - Cobertura: 0.902\n",
      "                - Puntos dentro de límites: 824\n",
      "                \n",
      "2024-12-27 09:58:25,580 - __main__ - INFO - \n",
      "            Serie limpia:\n",
      "            - Shape: (956,)\n",
      "            - Rango índices: [2013-05-08 22:28:00, 2013-05-09 15:07:00]\n",
      "            \n",
      "2024-12-27 09:58:25,580 - INFO - \n",
      "            Serie limpia:\n",
      "            - Shape: (956,)\n",
      "            - Rango índices: [2013-05-08 22:28:00, 2013-05-09 15:07:00]\n",
      "            \n",
      "2024-12-27 09:58:25,580 - __main__ - INFO - Variable Armónicos IL2: Armónico 7 (%IL2) procesada exitosamente\n",
      "2024-12-27 09:58:25,580 - INFO - Variable Armónicos IL2: Armónico 7 (%IL2) procesada exitosamente\n",
      "2024-12-27 09:58:55,940 - __main__ - INFO - \n",
      "                Predicciones generadas:\n",
      "                - Shape predicción: (940,)\n",
      "                - Shape intervalos: (940, 2)\n",
      "                - Valores finitos predicción: 940\n",
      "                \n",
      "2024-12-27 09:58:55,940 - INFO - \n",
      "                Predicciones generadas:\n",
      "                - Shape predicción: (940,)\n",
      "                - Shape intervalos: (940, 2)\n",
      "                - Valores finitos predicción: 940\n",
      "                \n",
      "2024-12-27 09:58:56,193 - __main__ - INFO - \n",
      "                Métricas finales:\n",
      "                - MSE: 0.005319\n",
      "                - MAE: 0.042141\n",
      "                - Cobertura: 0.859\n",
      "                - Puntos dentro de límites: 807\n",
      "                \n",
      "2024-12-27 09:58:56,193 - INFO - \n",
      "                Métricas finales:\n",
      "                - MSE: 0.005319\n",
      "                - MAE: 0.042141\n",
      "                - Cobertura: 0.859\n",
      "                - Puntos dentro de límites: 807\n",
      "                \n",
      "2024-12-27 09:58:56,925 - __main__ - INFO - Variable Armónicos VL2: Armónico 5 (%VL2) procesada exitosamente\n",
      "2024-12-27 09:58:56,925 - INFO - Variable Armónicos VL2: Armónico 5 (%VL2) procesada exitosamente\n",
      "2024-12-27 09:58:57,392 - __main__ - INFO - \n",
      "            === Iniciando validación ===\n",
      "            Serie original:\n",
      "            - Shape: (906,)\n",
      "            - Valores finitos: 906\n",
      "            - Rango: [-0.100, 0.567]\n",
      "            \n",
      "2024-12-27 09:58:57,392 - INFO - \n",
      "            === Iniciando validación ===\n",
      "            Serie original:\n",
      "            - Shape: (906,)\n",
      "            - Valores finitos: 906\n",
      "            - Rango: [-0.100, 0.567]\n",
      "            \n",
      "2024-12-27 09:58:57,829 - __main__ - INFO - \n",
      "            Serie limpia:\n",
      "            - Shape: (906,)\n",
      "            - Rango índices: [2013-05-08 22:28:00, 2013-05-09 15:07:00]\n",
      "            \n",
      "2024-12-27 09:58:57,829 - INFO - \n",
      "            Serie limpia:\n",
      "            - Shape: (906,)\n",
      "            - Rango índices: [2013-05-08 22:28:00, 2013-05-09 15:07:00]\n",
      "            \n",
      "2024-12-27 09:59:03,408 - __main__ - INFO - \n",
      "                Predicciones generadas:\n",
      "                - Shape predicción: (956,)\n",
      "                - Shape intervalos: (956, 2)\n",
      "                - Valores finitos predicción: 956\n",
      "                \n",
      "2024-12-27 09:59:03,408 - INFO - \n",
      "                Predicciones generadas:\n",
      "                - Shape predicción: (956,)\n",
      "                - Shape intervalos: (956, 2)\n",
      "                - Valores finitos predicción: 956\n",
      "                \n",
      "2024-12-27 09:59:04,277 - __main__ - INFO - \n",
      "                Métricas finales:\n",
      "                - MSE: 0.004385\n",
      "                - MAE: 0.036657\n",
      "                - Cobertura: 0.867\n",
      "                - Puntos dentro de límites: 829\n",
      "                \n",
      "2024-12-27 09:59:04,277 - INFO - \n",
      "                Métricas finales:\n",
      "                - MSE: 0.004385\n",
      "                - MAE: 0.036657\n",
      "                - Cobertura: 0.867\n",
      "                - Puntos dentro de límites: 829\n",
      "                \n",
      "2024-12-27 09:59:04,447 - __main__ - INFO - Variable Armónicos VL1: Armónico 5 (%VL1) procesada exitosamente\n",
      "2024-12-27 09:59:04,447 - INFO - Variable Armónicos VL1: Armónico 5 (%VL1) procesada exitosamente\n",
      "2024-12-27 09:59:27,479 - __main__ - INFO - \n",
      "            === Iniciando validación ===\n",
      "            Serie original:\n",
      "            - Shape: (900,)\n",
      "            - Valores finitos: 900\n",
      "            - Rango: [-0.590, 0.811]\n",
      "            \n",
      "2024-12-27 09:59:27,479 - INFO - \n",
      "            === Iniciando validación ===\n",
      "            Serie original:\n",
      "            - Shape: (900,)\n",
      "            - Valores finitos: 900\n",
      "            - Rango: [-0.590, 0.811]\n",
      "            \n",
      "2024-12-27 09:59:27,636 - __main__ - INFO - \n",
      "            Serie limpia:\n",
      "            - Shape: (900,)\n",
      "            - Rango índices: [2013-05-08 22:28:00, 2013-05-09 15:07:00]\n",
      "            \n",
      "2024-12-27 09:59:27,636 - INFO - \n",
      "            Serie limpia:\n",
      "            - Shape: (900,)\n",
      "            - Rango índices: [2013-05-08 22:28:00, 2013-05-09 15:07:00]\n",
      "            \n",
      "2024-12-27 09:59:31,469 - __main__ - INFO - \n",
      "                Predicciones generadas:\n",
      "                - Shape predicción: (906,)\n",
      "                - Shape intervalos: (906, 2)\n",
      "                - Valores finitos predicción: 906\n",
      "                \n",
      "2024-12-27 09:59:31,469 - INFO - \n",
      "                Predicciones generadas:\n",
      "                - Shape predicción: (906,)\n",
      "                - Shape intervalos: (906, 2)\n",
      "                - Valores finitos predicción: 906\n",
      "                \n",
      "2024-12-27 09:59:32,816 - __main__ - INFO - \n",
      "                Métricas finales:\n",
      "                - MSE: 0.002193\n",
      "                - MAE: 0.031014\n",
      "                - Cobertura: 0.850\n",
      "                - Puntos dentro de límites: 770\n",
      "                \n",
      "2024-12-27 09:59:32,816 - INFO - \n",
      "                Métricas finales:\n",
      "                - MSE: 0.002193\n",
      "                - MAE: 0.031014\n",
      "                - Cobertura: 0.850\n",
      "                - Puntos dentro de límites: 770\n",
      "                \n",
      "2024-12-27 09:59:33,194 - __main__ - INFO - Variable Armónicos IL1: Armónico 7 (%IL1) procesada exitosamente\n",
      "2024-12-27 09:59:33,194 - INFO - Variable Armónicos IL1: Armónico 7 (%IL1) procesada exitosamente\n",
      "2024-12-27 09:59:52,115 - __main__ - INFO - \n",
      "            === Iniciando validación ===\n",
      "            Serie original:\n",
      "            - Shape: (900,)\n",
      "            - Valores finitos: 900\n",
      "            - Rango: [-1.416, 0.838]\n",
      "            \n",
      "2024-12-27 09:59:52,115 - INFO - \n",
      "            === Iniciando validación ===\n",
      "            Serie original:\n",
      "            - Shape: (900,)\n",
      "            - Valores finitos: 900\n",
      "            - Rango: [-1.416, 0.838]\n",
      "            \n",
      "2024-12-27 09:59:52,281 - __main__ - INFO - \n",
      "            Serie limpia:\n",
      "            - Shape: (900,)\n",
      "            - Rango índices: [2013-05-08 22:28:00, 2013-05-09 15:07:00]\n",
      "            \n",
      "2024-12-27 09:59:52,281 - INFO - \n",
      "            Serie limpia:\n",
      "            - Shape: (900,)\n",
      "            - Rango índices: [2013-05-08 22:28:00, 2013-05-09 15:07:00]\n",
      "            \n",
      "2024-12-27 10:00:01,296 - __main__ - INFO - \n",
      "                Predicciones generadas:\n",
      "                - Shape predicción: (900,)\n",
      "                - Shape intervalos: (900, 2)\n",
      "                - Valores finitos predicción: 900\n",
      "                \n",
      "2024-12-27 10:00:01,296 - INFO - \n",
      "                Predicciones generadas:\n",
      "                - Shape predicción: (900,)\n",
      "                - Shape intervalos: (900, 2)\n",
      "                - Valores finitos predicción: 900\n",
      "                \n",
      "2024-12-27 10:00:01,482 - __main__ - INFO - \n",
      "                Métricas finales:\n",
      "                - MSE: 0.004752\n",
      "                - MAE: 0.035943\n",
      "                - Cobertura: 0.909\n",
      "                - Puntos dentro de límites: 818\n",
      "                \n",
      "2024-12-27 10:00:01,482 - INFO - \n",
      "                Métricas finales:\n",
      "                - MSE: 0.004752\n",
      "                - MAE: 0.035943\n",
      "                - Cobertura: 0.909\n",
      "                - Puntos dentro de límites: 818\n",
      "                \n",
      "2024-12-27 10:00:01,524 - __main__ - INFO - Variable Corriente: L1 (A) procesada exitosamente\n",
      "2024-12-27 10:00:01,524 - INFO - Variable Corriente: L1 (A) procesada exitosamente\n",
      "2024-12-27 10:00:05,465 - __main__ - INFO - \n",
      "            === Iniciando validación ===\n",
      "            Serie original:\n",
      "            - Shape: (906,)\n",
      "            - Valores finitos: 906\n",
      "            - Rango: [-0.243, 0.838]\n",
      "            \n",
      "2024-12-27 10:00:05,465 - INFO - \n",
      "            === Iniciando validación ===\n",
      "            Serie original:\n",
      "            - Shape: (906,)\n",
      "            - Valores finitos: 906\n",
      "            - Rango: [-0.243, 0.838]\n",
      "            \n",
      "2024-12-27 10:00:05,770 - __main__ - INFO - \n",
      "            Serie limpia:\n",
      "            - Shape: (906,)\n",
      "            - Rango índices: [2013-05-08 22:31:00, 2013-05-09 15:07:00]\n",
      "            \n",
      "2024-12-27 10:00:05,770 - INFO - \n",
      "            Serie limpia:\n",
      "            - Shape: (906,)\n",
      "            - Rango índices: [2013-05-08 22:31:00, 2013-05-09 15:07:00]\n",
      "            \n",
      "2024-12-27 10:00:14,558 - __main__ - INFO - \n",
      "                Predicciones generadas:\n",
      "                - Shape predicción: (900,)\n",
      "                - Shape intervalos: (900, 2)\n",
      "                - Valores finitos predicción: 900\n",
      "                \n",
      "2024-12-27 10:00:14,558 - INFO - \n",
      "                Predicciones generadas:\n",
      "                - Shape predicción: (900,)\n",
      "                - Shape intervalos: (900, 2)\n",
      "                - Valores finitos predicción: 900\n",
      "                \n",
      "2024-12-27 10:00:14,925 - __main__ - INFO - \n",
      "                Métricas finales:\n",
      "                - MSE: 0.006729\n",
      "                - MAE: 0.050635\n",
      "                - Cobertura: 0.894\n",
      "                - Puntos dentro de límites: 805\n",
      "                \n",
      "2024-12-27 10:00:14,925 - INFO - \n",
      "                Métricas finales:\n",
      "                - MSE: 0.006729\n",
      "                - MAE: 0.050635\n",
      "                - Cobertura: 0.894\n",
      "                - Puntos dentro de límites: 805\n",
      "                \n",
      "2024-12-27 10:00:15,172 - __main__ - INFO - Variable Tensión: L2 - L3 (V) procesada exitosamente\n",
      "2024-12-27 10:00:15,172 - INFO - Variable Tensión: L2 - L3 (V) procesada exitosamente\n",
      "2024-12-27 10:00:21,050 - __main__ - INFO - \n",
      "                Predicciones generadas:\n",
      "                - Shape predicción: (906,)\n",
      "                - Shape intervalos: (906, 2)\n",
      "                - Valores finitos predicción: 906\n",
      "                \n",
      "2024-12-27 10:00:21,050 - INFO - \n",
      "                Predicciones generadas:\n",
      "                - Shape predicción: (906,)\n",
      "                - Shape intervalos: (906, 2)\n",
      "                - Valores finitos predicción: 906\n",
      "                \n",
      "2024-12-27 10:00:21,112 - __main__ - INFO - \n",
      "                Métricas finales:\n",
      "                - MSE: 0.003990\n",
      "                - MAE: 0.040773\n",
      "                - Cobertura: 0.900\n",
      "                - Puntos dentro de límites: 815\n",
      "                \n",
      "2024-12-27 10:00:21,112 - INFO - \n",
      "                Métricas finales:\n",
      "                - MSE: 0.003990\n",
      "                - MAE: 0.040773\n",
      "                - Cobertura: 0.900\n",
      "                - Puntos dentro de límites: 815\n",
      "                \n",
      "2024-12-27 10:00:21,144 - __main__ - INFO - Variable Armónicos IL1: Armónico 5 (%IL1) procesada exitosamente\n",
      "2024-12-27 10:00:21,144 - INFO - Variable Armónicos IL1: Armónico 5 (%IL1) procesada exitosamente\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumen Global:\n",
      "Total variables procesadas: 11\n",
      "Modelos válidos: 11\n",
      "\n",
      "Métricas promedio:\n",
      "  mse: 0.004\n",
      "  mae: 0.037\n",
      "  coverage: 0.868\n",
      "\n",
      "Cobertura:\n",
      "  Media: 0.868\n",
      "\n",
      "Validación global:\n",
      "Estado: ✓\n"
     ]
    }
   ],
   "source": [
    "# CELDA 4: Fase 3 - Aprendizaje de Línea Base\n",
    "\"\"\"\n",
    "Fase 3: Aprendizaje de Línea Base\n",
    "================================\n",
    "\n",
    "Objetivos:\n",
    "1. Establecer patrones normales de comportamiento para todas las variables clave\n",
    "2. Crear modelos de referencia adaptativos\n",
    "3. Definir límites dinámicos de operación\n",
    "4. Implementar detección de desviaciones\n",
    "5. Validar robustez del modelo base\n",
    "6. Preparar base para el sistema de prognosis\n",
    "\n",
    "Características principales:\n",
    "- Procesamiento paralelo de todas las variables clave\n",
    "- Límites dinámicos adaptativos\n",
    "- Validación robusta de modelos\n",
    "- Métricas agregadas para evaluación global\n",
    "- Preparación para detección temprana de fallas\n",
    "\"\"\"\n",
    "\n",
    "# Importaciones necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from typing import Dict, List, Tuple, Any, Optional, Callable\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import warnings\n",
    "from scipy.stats import norm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import concurrent.futures\n",
    "\n",
    "class BaselineLearner:\n",
    "    \"\"\"\n",
    "    Clase para el aprendizaje de línea base del sistema.\n",
    "    \n",
    "    Establece patrones normales de comportamiento y límites adaptativos\n",
    "    para todas las variables clave del sistema, preparando la base para\n",
    "    la detección temprana de fallas.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_periods: int = 24):\n",
    "        \"\"\"\n",
    "        Inicializa el aprendiz de línea base.\n",
    "        \n",
    "        Args:\n",
    "            n_periods: Número de períodos para estacionalidad (default=24 horas)\n",
    "        \"\"\"\n",
    "        self._setup_logging()\n",
    "        self.n_periods = n_periods\n",
    "        self.models = {}\n",
    "        self.limits = {}\n",
    "        self.stats = {}\n",
    "        self.validation = {}\n",
    "        \n",
    "        # Parámetros optimizados para el sistema\n",
    "        self.params = {\n",
    "            'confidence_level': 0.80,    # Nivel de confianza para límites\n",
    "            'min_samples': 50,           # Mínimo de muestras para modelado\n",
    "            'contamination': 0.1,        # Factor de contaminación para detección de outliers\n",
    "            'window_size': 24,           # Tamaño de ventana para límites dinámicos\n",
    "            'n_splits': 3,               # Número de splits para validación\n",
    "            'coverage_threshold': 0.5,    # Umbral mínimo de cobertura aceptable\n",
    "            'max_workers': 4,            # Máximo de workers para procesamiento paralelo\n",
    "            'maxiter': 300,              # Máximo de iteraciones para ajuste de modelo\n",
    "            'model_order': (1, 0, 1),    # Orden del modelo SARIMA\n",
    "            'seasonal_order': (0, 1, 1)  # Orden estacional del modelo\n",
    "        }\n",
    "\n",
    "    def _setup_logging(self):\n",
    "        \"\"\"Configura el sistema de logging.\"\"\"\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        if not self.logger.handlers:\n",
    "            handler = logging.StreamHandler()\n",
    "            formatter = logging.Formatter(\n",
    "                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "            )\n",
    "            handler.setFormatter(formatter)\n",
    "            self.logger.addHandler(handler)\n",
    "            self.logger.setLevel(logging.INFO)\n",
    "\n",
    "    def learn_baseline(self, data: pd.DataFrame, selected_vars: Dict[str, float]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Aprende la línea base para todas las variables seleccionadas.\n",
    "        \n",
    "        Args:\n",
    "            data: DataFrame con los datos históricos\n",
    "            selected_vars: Diccionario de variables seleccionadas y sus scores\n",
    "            \n",
    "        Returns:\n",
    "            Dict con resultados del aprendizaje\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.logger.info(f\"Iniciando aprendizaje de línea base para {len(selected_vars)} variables...\")\n",
    "            results = {\n",
    "                'models': {},\n",
    "                'limits': {},\n",
    "                'metrics': {},\n",
    "                'validation': {},\n",
    "                'summary': {}\n",
    "            }\n",
    "            \n",
    "            # Procesamiento paralelo de todas las variables\n",
    "            with ThreadPoolExecutor(max_workers=self.params['max_workers']) as executor:\n",
    "                future_to_var = {\n",
    "                    executor.submit(self._learn_variable_baseline, data[var], var): var \n",
    "                    for var in selected_vars\n",
    "                }\n",
    "                \n",
    "                for future in concurrent.futures.as_completed(future_to_var):\n",
    "                    var = future_to_var[future]\n",
    "                    try:\n",
    "                        model_results = future.result()\n",
    "                        if model_results:\n",
    "                            results['models'][var] = model_results['model']\n",
    "                            results['limits'][var] = model_results['limits']\n",
    "                            results['metrics'][var] = model_results['metrics']\n",
    "                            results['validation'][var] = model_results['validation']\n",
    "                            self.logger.info(f\"Variable {var} procesada exitosamente\")\n",
    "                    except Exception as e:\n",
    "                        self.logger.error(f\"Error procesando variable {var}: {str(e)}\")\n",
    "\n",
    "            # Agregar métricas globales y validación\n",
    "            results['summary'] = self._aggregate_metrics(results)\n",
    "            self._validate_results(results)\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en aprendizaje de línea base: {str(e)}\")\n",
    "            return None\n",
    "        \n",
    "    def _learn_variable_baseline(self, series: pd.Series, var_name: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Aprende la línea base para una variable específica.\n",
    "        \n",
    "        Args:\n",
    "            series: Serie temporal de la variable\n",
    "            var_name: Nombre de la variable\n",
    "            \n",
    "        Returns:\n",
    "            Dict con resultados del modelo\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.logger.debug(f\"Iniciando procesamiento de {var_name}\")\n",
    "            \n",
    "            # Limpieza y preparación\n",
    "            clean_series = self._remove_outliers(series)\n",
    "            stats = self._calculate_base_stats(clean_series)\n",
    "            \n",
    "            # Ajuste del modelo\n",
    "            model = self._fit_baseline_model(clean_series)\n",
    "            \n",
    "            if model is not None:\n",
    "                # Cálculo de límites y validación\n",
    "                limits = self._calculate_dynamic_limits(clean_series, stats)\n",
    "                residuals = self._analyze_residuals(model, clean_series)\n",
    "                validation = self._validate_variable_model(model, clean_series)\n",
    "                \n",
    "                return {\n",
    "                    'model': model,\n",
    "                    'limits': limits,\n",
    "                    'metrics': stats,\n",
    "                    'residuals': residuals,\n",
    "                    'validation': validation\n",
    "                }\n",
    "            return None\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en aprendizaje de variable {var_name}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def _remove_outliers(self, series: pd.Series) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Elimina outliers usando IsolationForest.\n",
    "        \n",
    "        Args:\n",
    "            series: Serie temporal a limpiar\n",
    "            \n",
    "        Returns:\n",
    "            Serie temporal sin outliers\n",
    "        \"\"\"\n",
    "        try:\n",
    "            iso = IsolationForest(\n",
    "                contamination=self.params['contamination'],\n",
    "                random_state=42,\n",
    "                n_jobs=-1  # Usar todos los cores disponibles\n",
    "            )\n",
    "            \n",
    "            X = series.values.reshape(-1, 1)\n",
    "            yhat = iso.fit_predict(X)\n",
    "            mask = yhat != -1\n",
    "            \n",
    "            cleaned_series = series[mask]\n",
    "            self.logger.debug(f\"Outliers removidos: {len(series) - len(cleaned_series)}\")\n",
    "            \n",
    "            return cleaned_series\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en remoción de outliers: {str(e)}\")\n",
    "            return series\n",
    "\n",
    "    def _analyze_residuals(self, model: Any, series: pd.Series) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Analiza los residuos del modelo para validar ajuste\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Obtener residuos del modelo de forma segura\n",
    "            if hasattr(model, 'resid'):\n",
    "                residuals = model.resid\n",
    "            else:\n",
    "                # Calcular residuos manualmente si no están disponibles\n",
    "                predictions = model.get_prediction(start=0).predicted_mean\n",
    "                residuals = series - predictions\n",
    "                \n",
    "            # Asegurarse de que los residuos son finitos\n",
    "            residuals = residuals[np.isfinite(residuals)]\n",
    "            \n",
    "            if len(residuals) == 0:\n",
    "                raise ValueError(\"No hay residuos válidos para analizar\")\n",
    "                \n",
    "            residual_metrics = {\n",
    "                'mean': float(np.mean(residuals)),\n",
    "                'std': float(np.std(residuals)),\n",
    "                'skew': float(stats.skew(residuals)),\n",
    "                'kurtosis': float(stats.kurtosis(residuals))\n",
    "            }\n",
    "            \n",
    "            # Calcular tests estadísticos de forma segura\n",
    "            try:\n",
    "                residual_metrics['jarque_bera'] = float(stats.jarque_bera(residuals)[0])\n",
    "            except:\n",
    "                residual_metrics['jarque_bera'] = np.inf\n",
    "                \n",
    "            try:\n",
    "                residual_metrics['ljung_box'] = float(\n",
    "                    sm.stats.diagnostic.acorr_ljungbox(residuals, lags=[10], return_df=False)[1][0]\n",
    "                )\n",
    "            except:\n",
    "                residual_metrics['ljung_box'] = 0.0\n",
    "                \n",
    "            # Actualizar métricas derivadas\n",
    "            residual_metrics.update({\n",
    "                'normality': residual_metrics['jarque_bera'] < 5.99,\n",
    "                'autocorr': residual_metrics['ljung_box'] > 0.05,\n",
    "                'stationarity': float(sm.tsa.stattools.adfuller(residuals)[1])\n",
    "            })\n",
    "            \n",
    "            return residual_metrics\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en análisis de residuos: {str(e)}\")\n",
    "            # Retornar valores por defecto en caso de error\n",
    "            return {\n",
    "                'mean': 0.0,\n",
    "                'std': np.inf,\n",
    "                'skew': 0.0,\n",
    "                'kurtosis': 0.0,\n",
    "                'jarque_bera': np.inf,\n",
    "                'ljung_box': 0.0,\n",
    "                'normality': False,\n",
    "                'autocorr': False,\n",
    "                'stationarity': 1.0\n",
    "            }\n",
    "        \n",
    "    def _validate_variable_model(self, model: Any, series: pd.Series) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Valida el modelo ajustado para una variable específica.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Debug inicial\n",
    "            self.logger.info(f\"\"\"\n",
    "            === Iniciando validación ===\n",
    "            Serie original:\n",
    "            - Shape: {series.shape}\n",
    "            - Valores finitos: {np.sum(np.isfinite(series))}\n",
    "            - Rango: [{series.min():.3f}, {series.max():.3f}]\n",
    "            \"\"\")\n",
    "            \n",
    "            # Asegurar que la serie tiene índice temporal\n",
    "            if not isinstance(series.index, pd.DatetimeIndex):\n",
    "                self.logger.warning(\"Serie sin índice temporal - usando RangeIndex\")\n",
    "                series.index = pd.date_range(\n",
    "                    start='2000-01-01', \n",
    "                    periods=len(series), \n",
    "                    freq='H'\n",
    "                )\n",
    "            \n",
    "            # Remover NaN/inf y verificar\n",
    "            valid_series = series[np.isfinite(series)].copy()\n",
    "            self.logger.info(f\"\"\"\n",
    "            Serie limpia:\n",
    "            - Shape: {valid_series.shape}\n",
    "            - Rango índices: [{valid_series.index.min()}, {valid_series.index.max()}]\n",
    "            \"\"\")\n",
    "            \n",
    "            if len(valid_series) == 0:\n",
    "                raise ValueError(\"No hay puntos válidos en la serie\")\n",
    "            \n",
    "            # Obtener predicciones\n",
    "            try:\n",
    "                # Ajustar nuevo modelo solo para el período de validación\n",
    "                validation_model = sm.tsa.SARIMAX(\n",
    "                    valid_series,\n",
    "                    order=self.params['model_order'],\n",
    "                    seasonal_order=self.params['seasonal_order'] + (self.n_periods,),\n",
    "                    enforce_stationarity=False,\n",
    "                    enforce_invertibility=False\n",
    "                ).fit(disp=False)\n",
    "                \n",
    "                # Generar predicciones in-sample\n",
    "                predictions = validation_model.get_prediction(\n",
    "                    start=valid_series.index[0],\n",
    "                    end=valid_series.index[-1]\n",
    "                )\n",
    "                \n",
    "                pred_mean = predictions.predicted_mean\n",
    "                conf_int = predictions.conf_int(alpha=1-self.params['confidence_level'])\n",
    "                \n",
    "                self.logger.info(f\"\"\"\n",
    "                Predicciones generadas:\n",
    "                - Shape predicción: {pred_mean.shape}\n",
    "                - Shape intervalos: {conf_int.shape}\n",
    "                - Valores finitos predicción: {np.sum(np.isfinite(pred_mean))}\n",
    "                \"\"\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"Error en predicciones: {str(e)}\")\n",
    "                raise\n",
    "            \n",
    "            # Alinear índices\n",
    "            valid_mask = (\n",
    "                pred_mean.index.isin(valid_series.index) &\n",
    "                conf_int.index.isin(valid_series.index)\n",
    "            )\n",
    "            \n",
    "            if np.sum(valid_mask) > 0:\n",
    "                # Calcular métricas\n",
    "                aligned_actual = valid_series[pred_mean.index[valid_mask]]\n",
    "                aligned_pred = pred_mean[valid_mask]\n",
    "                aligned_lower = conf_int.iloc[valid_mask, 0]\n",
    "                aligned_upper = conf_int.iloc[valid_mask, 1]\n",
    "                \n",
    "                mse = np.mean((aligned_actual - aligned_pred) ** 2)\n",
    "                mae = np.mean(np.abs(aligned_actual - aligned_pred))\n",
    "                \n",
    "                # Calcular cobertura\n",
    "                in_bounds = (\n",
    "                    (aligned_actual >= aligned_lower) & \n",
    "                    (aligned_actual <= aligned_upper)\n",
    "                )\n",
    "                coverage = float(np.mean(in_bounds))\n",
    "                \n",
    "                self.logger.info(f\"\"\"\n",
    "                Métricas finales:\n",
    "                - MSE: {mse:.6f}\n",
    "                - MAE: {mae:.6f}\n",
    "                - Cobertura: {coverage:.3f}\n",
    "                - Puntos dentro de límites: {np.sum(in_bounds)}\n",
    "                \"\"\")\n",
    "                \n",
    "                return {\n",
    "                    'mse': float(mse),\n",
    "                    'mae': float(mae),\n",
    "                    'coverage': float(coverage),\n",
    "                    'n_samples': int(np.sum(valid_mask)),\n",
    "                    'n_coverage_samples': int(np.sum(in_bounds))\n",
    "                }\n",
    "            \n",
    "            self.logger.warning(\"No hay puntos válidos alineados para calcular métricas\")\n",
    "            return {\n",
    "                'mse': np.inf,\n",
    "                'mae': np.inf,\n",
    "                'coverage': 0.0,\n",
    "                'n_samples': 0,\n",
    "                'n_coverage_samples': 0\n",
    "            }\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en validación: {str(e)}\")\n",
    "            return {\n",
    "                'mse': np.inf,\n",
    "                'mae': np.inf,\n",
    "                'coverage': 0.0,\n",
    "                'n_samples': 0,\n",
    "                'n_coverage_samples': 0\n",
    "            }\n",
    "       \n",
    "    def _calculate_base_stats(self, series: pd.Series) -> Dict[str, float]:\n",
    "        \"\"\"Calcula estadísticas base de la serie temporal.\"\"\"\n",
    "        try:\n",
    "            stats = {\n",
    "                'mean': float(series.mean()),\n",
    "                'std': float(series.std()),\n",
    "                'median': float(series.median()),\n",
    "                'q1': float(series.quantile(0.25)),\n",
    "                'q3': float(series.quantile(0.75)),\n",
    "                'min': float(series.min()),\n",
    "                'max': float(series.max())\n",
    "            }\n",
    "            \n",
    "            stats.update({\n",
    "                'iqr': stats['q3'] - stats['q1'],\n",
    "                'range': stats['max'] - stats['min'],\n",
    "                'cv': stats['std'] / stats['mean'] if stats['mean'] != 0 else np.inf\n",
    "            })\n",
    "            \n",
    "            return stats\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en cálculo de estadísticas: {str(e)}\")\n",
    "            return {}\n",
    "        \n",
    "    def _fit_baseline_model(self, series: pd.Series) -> Optional[Any]:\n",
    "        \"\"\"Ajusta modelo SARIMA a la serie temporal.\"\"\"\n",
    "        try:\n",
    "            if len(series) < self.params['min_samples']:\n",
    "                self.logger.warning(f\"Serie muy corta: {len(series)} < {self.params['min_samples']}\")\n",
    "                return None\n",
    "            \n",
    "            model = sm.tsa.SARIMAX(\n",
    "                series,\n",
    "                order=self.params['model_order'],\n",
    "                seasonal_order=self.params['seasonal_order'] + (self.n_periods,),\n",
    "                enforce_stationarity=False,\n",
    "                enforce_invertibility=False\n",
    "            )\n",
    "            \n",
    "            fitted_model = model.fit(\n",
    "                disp=False,\n",
    "                maxiter=self.params['maxiter'],\n",
    "                method='lbfgs',\n",
    "                low_memory=True\n",
    "            )\n",
    "            \n",
    "            return fitted_model\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en ajuste de modelo: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def _calculate_dynamic_limits(self, series: pd.Series, base_stats: Dict[str, float]) -> Dict[str, Any]:\n",
    "        \"\"\"Calcula límites dinámicos y estáticos.\"\"\"\n",
    "        try:\n",
    "            z_score = norm.ppf(self.params['confidence_level'])\n",
    "            \n",
    "            # Límites estáticos basados en estadísticas globales\n",
    "            static_limits = {\n",
    "                'upper': base_stats['mean'] + z_score * base_stats['std'],\n",
    "                'lower': base_stats['mean'] - z_score * base_stats['std']\n",
    "            }\n",
    "            \n",
    "            # Límites dinámicos basados en ventana móvil\n",
    "            rolling_mean = series.rolling(window=self.params['window_size']).mean()\n",
    "            rolling_std = series.rolling(window=self.params['window_size']).std()\n",
    "            \n",
    "            dynamic_upper = rolling_mean + z_score * rolling_std\n",
    "            dynamic_lower = rolling_mean - z_score * rolling_std\n",
    "            \n",
    "            return {\n",
    "                'static': static_limits,\n",
    "                'dynamic': {\n",
    "                    'upper': dynamic_upper.to_dict(),\n",
    "                    'lower': dynamic_lower.to_dict()\n",
    "                }\n",
    "            }\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en cálculo de límites: {str(e)}\")\n",
    "            return {}\n",
    "\n",
    "    def _summarize_coverage(self, results: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Genera resumen de cobertura para todas las variables.\"\"\"\n",
    "        try:\n",
    "            # Verificar que tenemos resultados válidos\n",
    "            if not results or 'validation' not in results:\n",
    "                return {\n",
    "                    'mean_coverage': 0.0,\n",
    "                    'variables_below_threshold': [],\n",
    "                    'coverage_threshold': self.params['coverage_threshold']\n",
    "                }\n",
    "            \n",
    "            # Obtener coberturas de cada variable\n",
    "            coverages = {}\n",
    "            for var, val in results['validation'].items():\n",
    "                if isinstance(val, dict) and 'coverage' in val:\n",
    "                    coverages[var] = val['coverage']\n",
    "            \n",
    "            # Identificar variables bajo el umbral\n",
    "            below_threshold = [\n",
    "                var for var, coverage in coverages.items() \n",
    "                if coverage < self.params['coverage_threshold']\n",
    "            ]\n",
    "            \n",
    "            # Calcular media de cobertura\n",
    "            mean_coverage = np.mean(list(coverages.values())) if coverages else 0.0\n",
    "            \n",
    "            return {\n",
    "                'mean_coverage': float(mean_coverage),\n",
    "                'variables_below_threshold': below_threshold,\n",
    "                'coverage_threshold': self.params['coverage_threshold']\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en resumen de cobertura: {str(e)}\")\n",
    "            return {\n",
    "                'mean_coverage': 0.0,\n",
    "                'variables_below_threshold': [],\n",
    "                'coverage_threshold': self.params['coverage_threshold']\n",
    "            }\n",
    "\n",
    "    def _aggregate_metrics(self, results: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Agrega métricas de todos los modelos.\"\"\"\n",
    "        try:\n",
    "            # Asegurarse de que hay resultados válidos\n",
    "            if not results or not results.get('models'):\n",
    "                raise ValueError(\"No hay resultados para agregar\")\n",
    "                \n",
    "            metrics = {\n",
    "                'total_variables': len(results['models']),\n",
    "                'valid_models': sum(1 for m in results['models'].values() if m is not None),\n",
    "            }\n",
    "            \n",
    "            # Calcular métricas promedio de forma segura\n",
    "            validation_values = [v for v in results.get('validation', {}).values() \n",
    "                            if isinstance(v, dict)]\n",
    "            \n",
    "            if validation_values:\n",
    "                metrics['average_metrics'] = {\n",
    "                    'mse': np.mean([v.get('mse', np.inf) \n",
    "                                for v in validation_values \n",
    "                                if np.isfinite(v.get('mse', np.inf))]),\n",
    "                    'mae': np.mean([v.get('mae', np.inf) \n",
    "                                for v in validation_values \n",
    "                                if np.isfinite(v.get('mae', np.inf))]),\n",
    "                    'coverage': np.mean([v.get('coverage', 0.0) \n",
    "                                    for v in validation_values \n",
    "                                    if np.isfinite(v.get('coverage', 0.0))])\n",
    "                }\n",
    "            else:\n",
    "                metrics['average_metrics'] = {\n",
    "                    'mse': np.inf,\n",
    "                    'mae': np.inf,\n",
    "                    'coverage': 0.0\n",
    "                }\n",
    "                \n",
    "            # Agregar resumen de cobertura\n",
    "            metrics['coverage_summary'] = self._summarize_coverage(results)\n",
    "            \n",
    "            return metrics\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en agregación de métricas: {str(e)}\")\n",
    "            return {\n",
    "                'total_variables': 0,\n",
    "                'valid_models': 0,\n",
    "                'average_metrics': {'mse': np.inf, 'mae': np.inf, 'coverage': 0.0},\n",
    "                'coverage_summary': {'mean_coverage': 0.0, 'variables_below_threshold': []}\n",
    "            }\n",
    "    def _validate_results(self, results: Dict[str, Any]):\n",
    "        \"\"\"Valida resultados globales y genera reporte.\"\"\"\n",
    "        try:\n",
    "            # Verificar que tenemos resultados válidos\n",
    "            if not results or 'summary' not in results:\n",
    "                results['validation'] = {\n",
    "                    'global': {\n",
    "                        'status': False,\n",
    "                        'warnings': ['No hay resultados válidos para validar'],\n",
    "                        'metrics': {},\n",
    "                        'coverage_summary': {}\n",
    "                    }\n",
    "                }\n",
    "                return\n",
    "                \n",
    "            validation = {\n",
    "                'status': True,\n",
    "                'warnings': [],\n",
    "                'metrics': results.get('summary', {}),\n",
    "                'coverage_summary': results.get('summary', {}).get('coverage_summary', {})\n",
    "            }\n",
    "            \n",
    "            # Validaciones específicas\n",
    "            total_vars = results['summary'].get('total_variables', 0)\n",
    "            valid_models = results['summary'].get('valid_models', 0)\n",
    "            \n",
    "            if valid_models < total_vars:\n",
    "                validation['status'] = False\n",
    "                validation['warnings'].append(\n",
    "                    f\"Solo {valid_models} de {total_vars} modelos son válidos\"\n",
    "                )\n",
    "            \n",
    "            coverage_summary = results['summary'].get('coverage_summary', {})\n",
    "            below_threshold = coverage_summary.get('variables_below_threshold', [])\n",
    "            \n",
    "            if below_threshold:\n",
    "                validation['warnings'].append(\n",
    "                    f\"Variables con baja cobertura: {', '.join(below_threshold)}\"\n",
    "                )\n",
    "            \n",
    "            results['validation']['global'] = validation\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en validación de resultados: {str(e)}\")\n",
    "            results['validation'] = {\n",
    "                'global': {\n",
    "                    'status': False,\n",
    "                    'warnings': [f'Error en validación: {str(e)}'],\n",
    "                    'metrics': {},\n",
    "                    'coverage_summary': {}\n",
    "                }\n",
    "            }\n",
    "\n",
    "def test_baseline_learning(data: pd.DataFrame, selected_vars: Dict[str, float]):\n",
    "    \"\"\"Función de prueba para el aprendizaje de línea base.\"\"\"\n",
    "    try:\n",
    "        print(\"\\n=== PRUEBA DE APRENDIZAJE DE LÍNEA BASE ===\\n\")\n",
    "        \n",
    "        learner = BaselineLearner()\n",
    "        results = learner.learn_baseline(data, selected_vars)\n",
    "        \n",
    "        if results:\n",
    "            print(\"\\nResumen Global:\")\n",
    "            print(f\"Total variables procesadas: {results['summary']['total_variables']}\")\n",
    "            print(f\"Modelos válidos: {results['summary']['valid_models']}\")\n",
    "            \n",
    "            print(f\"\\nMétricas promedio:\")\n",
    "            for metric, value in results['summary']['average_metrics'].items():\n",
    "                print(f\"  {metric}: {value:.3f}\")\n",
    "            \n",
    "            print(\"\\nCobertura:\")\n",
    "            coverage = results['summary']['coverage_summary']\n",
    "            print(f\"  Media: {coverage['mean_coverage']:.3f}\")\n",
    "            if coverage['variables_below_threshold']:\n",
    "                print(\"\\nVariables con baja cobertura:\")\n",
    "                for var in coverage['variables_below_threshold']:\n",
    "                    print(f\"  - {var}\")\n",
    "            \n",
    "            print(\"\\nValidación global:\")\n",
    "            global_validation = results['validation']['global']\n",
    "            print(f\"Estado: {'✓' if global_validation['status'] else '✗'}\")\n",
    "            \n",
    "            if global_validation['warnings']:\n",
    "                print(\"\\nAdvertencias:\")\n",
    "                for warning in global_validation['warnings']:\n",
    "                    print(f\"- {warning}\")\n",
    "            \n",
    "            return learner\n",
    "        else:\n",
    "            print(\"Error en aprendizaje de línea base\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error en prueba: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Ejecución condicional\n",
    "if 'processed_data' in globals() and 'variable_analyzer' in globals():\n",
    "    if variable_analyzer and variable_analyzer.results['selected_variables']:\n",
    "        recent_data = processed_data.iloc[-1000:]  # Últimos 1000 registros\n",
    "        baseline_learner = test_baseline_learning(\n",
    "            recent_data,\n",
    "            variable_analyzer.results['selected_variables']\n",
    "        )\n",
    "    else:\n",
    "        print(\"Error: No hay variables seleccionadas\")\n",
    "else:\n",
    "    print(\"Error: Ejecutar primero el análisis de variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-27 10:00:21,237 - __main__ - INFO - Iniciando entrenamiento para 11 variables\n",
      "2024-12-27 10:00:21,237 - INFO - Iniciando entrenamiento para 11 variables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PRUEBA DE SISTEMA DE PROGNOSIS ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-27 10:05:21,938 - __main__ - WARNING - Precisión baja para Armónicos IL1: Armónico 3 (%IL1): 0.680 (objetivo: 0.8)\n",
      "2024-12-27 10:05:21,938 - WARNING - Precisión baja para Armónicos IL1: Armónico 3 (%IL1): 0.680 (objetivo: 0.8)\n",
      "2024-12-27 10:05:21,941 - __main__ - WARNING - Recall bajo para Armónicos IL1: Armónico 3 (%IL1): 0.668 (objetivo: 0.75)\n",
      "2024-12-27 10:05:21,941 - WARNING - Recall bajo para Armónicos IL1: Armónico 3 (%IL1): 0.668 (objetivo: 0.75)\n",
      "2024-12-27 10:05:21,943 - __main__ - INFO - Validación completada para Armónicos IL1: Armónico 3 (%IL1)\n",
      "2024-12-27 10:05:21,943 - INFO - Validación completada para Armónicos IL1: Armónico 3 (%IL1)\n",
      "2024-12-27 10:05:21,946 - __main__ - WARNING - Precisión baja para Armónicos IL1: Armónico 2 (%IL1): 0.000 (objetivo: 0.8)\n",
      "2024-12-27 10:05:21,946 - WARNING - Precisión baja para Armónicos IL1: Armónico 2 (%IL1): 0.000 (objetivo: 0.8)\n",
      "2024-12-27 10:05:21,948 - __main__ - WARNING - Recall bajo para Armónicos IL1: Armónico 2 (%IL1): 0.000 (objetivo: 0.75)\n",
      "2024-12-27 10:05:21,948 - WARNING - Recall bajo para Armónicos IL1: Armónico 2 (%IL1): 0.000 (objetivo: 0.75)\n",
      "2024-12-27 10:05:21,949 - __main__ - INFO - Validación completada para Armónicos IL1: Armónico 2 (%IL1)\n",
      "2024-12-27 10:05:21,949 - INFO - Validación completada para Armónicos IL1: Armónico 2 (%IL1)\n",
      "2024-12-27 10:05:21,952 - __main__ - WARNING - Precisión baja para Distorsión armónica: IL1 (%I THD): 0.392 (objetivo: 0.8)\n",
      "2024-12-27 10:05:21,952 - WARNING - Precisión baja para Distorsión armónica: IL1 (%I THD): 0.392 (objetivo: 0.8)\n",
      "2024-12-27 10:05:21,956 - __main__ - WARNING - Recall bajo para Distorsión armónica: IL1 (%I THD): 0.387 (objetivo: 0.75)\n",
      "2024-12-27 10:05:21,956 - WARNING - Recall bajo para Distorsión armónica: IL1 (%I THD): 0.387 (objetivo: 0.75)\n",
      "2024-12-27 10:05:21,961 - __main__ - INFO - Validación completada para Distorsión armónica: IL1 (%I THD)\n",
      "2024-12-27 10:05:21,961 - INFO - Validación completada para Distorsión armónica: IL1 (%I THD)\n",
      "2024-12-27 10:05:21,963 - __main__ - WARNING - Precisión baja para Armónicos VL3: Armónico 5 (%VL3): 0.191 (objetivo: 0.8)\n",
      "2024-12-27 10:05:21,963 - WARNING - Precisión baja para Armónicos VL3: Armónico 5 (%VL3): 0.191 (objetivo: 0.8)\n",
      "2024-12-27 10:05:21,966 - __main__ - WARNING - Recall bajo para Armónicos VL3: Armónico 5 (%VL3): 0.200 (objetivo: 0.75)\n",
      "2024-12-27 10:05:21,966 - WARNING - Recall bajo para Armónicos VL3: Armónico 5 (%VL3): 0.200 (objetivo: 0.75)\n",
      "2024-12-27 10:05:21,967 - __main__ - INFO - Validación completada para Armónicos VL3: Armónico 5 (%VL3)\n",
      "2024-12-27 10:05:21,967 - INFO - Validación completada para Armónicos VL3: Armónico 5 (%VL3)\n",
      "2024-12-27 10:05:21,969 - __main__ - WARNING - Precisión baja para Armónicos VL2: Armónico 5 (%VL2): 0.197 (objetivo: 0.8)\n",
      "2024-12-27 10:05:21,969 - WARNING - Precisión baja para Armónicos VL2: Armónico 5 (%VL2): 0.197 (objetivo: 0.8)\n",
      "2024-12-27 10:05:21,970 - __main__ - WARNING - Recall bajo para Armónicos VL2: Armónico 5 (%VL2): 0.200 (objetivo: 0.75)\n",
      "2024-12-27 10:05:21,970 - WARNING - Recall bajo para Armónicos VL2: Armónico 5 (%VL2): 0.200 (objetivo: 0.75)\n",
      "2024-12-27 10:05:21,973 - __main__ - INFO - Validación completada para Armónicos VL2: Armónico 5 (%VL2)\n",
      "2024-12-27 10:05:21,973 - INFO - Validación completada para Armónicos VL2: Armónico 5 (%VL2)\n",
      "2024-12-27 10:05:22,067 - __main__ - WARNING - Precisión baja para Armónicos IL2: Armónico 7 (%IL2): 0.423 (objetivo: 0.8)\n",
      "2024-12-27 10:05:22,067 - WARNING - Precisión baja para Armónicos IL2: Armónico 7 (%IL2): 0.423 (objetivo: 0.8)\n",
      "2024-12-27 10:05:22,086 - __main__ - WARNING - Recall bajo para Armónicos IL2: Armónico 7 (%IL2): 0.554 (objetivo: 0.75)\n",
      "2024-12-27 10:05:22,086 - WARNING - Recall bajo para Armónicos IL2: Armónico 7 (%IL2): 0.554 (objetivo: 0.75)\n",
      "2024-12-27 10:05:22,092 - __main__ - WARNING - MSE alto para Armónicos IL2: Armónico 7 (%IL2): 0.3713\n",
      "2024-12-27 10:05:22,092 - WARNING - MSE alto para Armónicos IL2: Armónico 7 (%IL2): 0.3713\n",
      "2024-12-27 10:05:22,093 - __main__ - INFO - Validación completada para Armónicos IL2: Armónico 7 (%IL2)\n",
      "2024-12-27 10:05:22,093 - INFO - Validación completada para Armónicos IL2: Armónico 7 (%IL2)\n",
      "2024-12-27 10:05:22,095 - __main__ - WARNING - Precisión baja para Armónicos VL1: Armónico 5 (%VL1): 0.199 (objetivo: 0.8)\n",
      "2024-12-27 10:05:22,095 - WARNING - Precisión baja para Armónicos VL1: Armónico 5 (%VL1): 0.199 (objetivo: 0.8)\n",
      "2024-12-27 10:05:22,096 - __main__ - WARNING - Recall bajo para Armónicos VL1: Armónico 5 (%VL1): 0.197 (objetivo: 0.75)\n",
      "2024-12-27 10:05:22,096 - WARNING - Recall bajo para Armónicos VL1: Armónico 5 (%VL1): 0.197 (objetivo: 0.75)\n",
      "2024-12-27 10:05:22,099 - __main__ - INFO - Validación completada para Armónicos VL1: Armónico 5 (%VL1)\n",
      "2024-12-27 10:05:22,099 - INFO - Validación completada para Armónicos VL1: Armónico 5 (%VL1)\n",
      "2024-12-27 10:05:22,100 - __main__ - WARNING - Precisión baja para Armónicos IL1: Armónico 7 (%IL1): 0.461 (objetivo: 0.8)\n",
      "2024-12-27 10:05:22,100 - WARNING - Precisión baja para Armónicos IL1: Armónico 7 (%IL1): 0.461 (objetivo: 0.8)\n",
      "2024-12-27 10:05:22,102 - __main__ - WARNING - Recall bajo para Armónicos IL1: Armónico 7 (%IL1): 0.438 (objetivo: 0.75)\n",
      "2024-12-27 10:05:22,102 - WARNING - Recall bajo para Armónicos IL1: Armónico 7 (%IL1): 0.438 (objetivo: 0.75)\n",
      "2024-12-27 10:05:22,116 - __main__ - INFO - Validación completada para Armónicos IL1: Armónico 7 (%IL1)\n",
      "2024-12-27 10:05:22,116 - INFO - Validación completada para Armónicos IL1: Armónico 7 (%IL1)\n",
      "2024-12-27 10:05:22,127 - __main__ - WARNING - Precisión baja para Corriente: L1 (A): 0.000 (objetivo: 0.8)\n",
      "2024-12-27 10:05:22,127 - WARNING - Precisión baja para Corriente: L1 (A): 0.000 (objetivo: 0.8)\n",
      "2024-12-27 10:05:22,133 - __main__ - WARNING - Recall bajo para Corriente: L1 (A): 0.000 (objetivo: 0.75)\n",
      "2024-12-27 10:05:22,133 - WARNING - Recall bajo para Corriente: L1 (A): 0.000 (objetivo: 0.75)\n",
      "2024-12-27 10:05:22,140 - __main__ - INFO - Validación completada para Corriente: L1 (A)\n",
      "2024-12-27 10:05:22,140 - INFO - Validación completada para Corriente: L1 (A)\n",
      "2024-12-27 10:05:22,154 - __main__ - WARNING - Precisión baja para Armónicos IL1: Armónico 5 (%IL1): 0.391 (objetivo: 0.8)\n",
      "2024-12-27 10:05:22,154 - WARNING - Precisión baja para Armónicos IL1: Armónico 5 (%IL1): 0.391 (objetivo: 0.8)\n",
      "2024-12-27 10:05:22,164 - __main__ - WARNING - Recall bajo para Armónicos IL1: Armónico 5 (%IL1): 0.388 (objetivo: 0.75)\n",
      "2024-12-27 10:05:22,164 - WARNING - Recall bajo para Armónicos IL1: Armónico 5 (%IL1): 0.388 (objetivo: 0.75)\n",
      "2024-12-27 10:05:22,170 - __main__ - INFO - Validación completada para Armónicos IL1: Armónico 5 (%IL1)\n",
      "2024-12-27 10:05:22,170 - INFO - Validación completada para Armónicos IL1: Armónico 5 (%IL1)\n",
      "2024-12-27 10:05:22,174 - __main__ - WARNING - Precisión baja para Tensión: L2 - L3 (V): 0.199 (objetivo: 0.8)\n",
      "2024-12-27 10:05:22,174 - WARNING - Precisión baja para Tensión: L2 - L3 (V): 0.199 (objetivo: 0.8)\n",
      "2024-12-27 10:05:22,185 - __main__ - WARNING - Recall bajo para Tensión: L2 - L3 (V): 0.193 (objetivo: 0.75)\n",
      "2024-12-27 10:05:22,185 - WARNING - Recall bajo para Tensión: L2 - L3 (V): 0.193 (objetivo: 0.75)\n",
      "2024-12-27 10:05:22,191 - __main__ - INFO - Validación completada para Tensión: L2 - L3 (V)\n",
      "2024-12-27 10:05:22,191 - INFO - Validación completada para Tensión: L2 - L3 (V)\n",
      "2024-12-27 10:05:22,203 - __main__ - INFO - Entrenamiento completado exitosamente\n",
      "2024-12-27 10:05:22,203 - INFO - Entrenamiento completado exitosamente\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados de Entrenamiento:\n",
      "\n",
      "Armónicos IL1: Armónico 3 (%IL1):\n",
      "  Precisión: 0.680\n",
      "  Recall: 0.668\n",
      "  MSE: 0.0494\n",
      "\n",
      "Armónicos IL1: Armónico 2 (%IL1):\n",
      "  Precisión: 0.000\n",
      "  Recall: 0.000\n",
      "  MSE: 0.1949\n",
      "\n",
      "Distorsión armónica: IL1 (%I THD):\n",
      "  Precisión: 0.392\n",
      "  Recall: 0.387\n",
      "  MSE: 0.0584\n",
      "\n",
      "Armónicos VL3: Armónico 5 (%VL3):\n",
      "  Precisión: 0.191\n",
      "  Recall: 0.200\n",
      "  MSE: 0.0595\n",
      "\n",
      "Armónicos VL2: Armónico 5 (%VL2):\n",
      "  Precisión: 0.197\n",
      "  Recall: 0.200\n",
      "  MSE: 0.0724\n",
      "\n",
      "Armónicos IL2: Armónico 7 (%IL2):\n",
      "  Precisión: 0.423\n",
      "  Recall: 0.554\n",
      "  MSE: 0.3713\n",
      "\n",
      "Armónicos VL1: Armónico 5 (%VL1):\n",
      "  Precisión: 0.199\n",
      "  Recall: 0.197\n",
      "  MSE: 0.0184\n",
      "\n",
      "Armónicos IL1: Armónico 7 (%IL1):\n",
      "  Precisión: 0.461\n",
      "  Recall: 0.438\n",
      "  MSE: 0.0533\n",
      "\n",
      "Corriente: L1 (A):\n",
      "  Precisión: 0.000\n",
      "  Recall: 0.000\n",
      "  MSE: 0.0982\n",
      "\n",
      "Armónicos IL1: Armónico 5 (%IL1):\n",
      "  Precisión: 0.391\n",
      "  Recall: 0.388\n",
      "  MSE: 0.1890\n",
      "\n",
      "Tensión: L2 - L3 (V):\n",
      "  Precisión: 0.199\n",
      "  Recall: 0.193\n",
      "  MSE: 0.0741\n",
      "Error en pruebas: 'variable'\n"
     ]
    }
   ],
   "source": [
    "# CELDA 5: Fase 4 - Sistema de Prognosis Industrial\n",
    "\"\"\"\n",
    "Fase 4: Sistema de Prognosis Industrial\n",
    "=====================================\n",
    "\n",
    "Sistema de prognosis industrial con:\n",
    "1. Detección de anomalías y análisis de tendencias\n",
    "2. Evaluación frente a límites adaptativos\n",
    "3. Predicción y alertas tempranas\n",
    "4. Métricas de rendimiento y KPIs\n",
    "5. Visualización y reportes\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingRegressor, IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, precision_score, recall_score\n",
    "import logging\n",
    "from typing import Dict, List, Tuple, Any, Optional\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "@dataclass\n",
    "class PrognosisConfig:\n",
    "    \"\"\"Configuración del sistema de prognosis.\"\"\"\n",
    "    # Parámetros de entrenamiento\n",
    "    n_splits: int = 5\n",
    "    test_size: float = 0.2\n",
    "    confidence_level: float = 0.95\n",
    "    \n",
    "    # Ventanas temporales\n",
    "    window_size: int = 24\n",
    "    forecast_horizon: int = 12\n",
    "    lags: List[int] = None\n",
    "    \n",
    "    # Umbrales ajustados\n",
    "    alert_threshold: float = 0.8        # Aumentado para reducir falsos positivos\n",
    "    anomaly_contamination: float = 0.05 # Reducido para ser más selectivo\n",
    "    trend_threshold: float = 0.1        # Aumentado para detectar tendencias más significativas\n",
    "    \n",
    "    # Métricas objetivo ajustadas\n",
    "    target_precision: float = 0.80      # Más realista\n",
    "    target_recall: float = 0.75         # Más realista\n",
    "    max_false_positives: float = 0.1    # Aumentado ligeramente\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.lags is None:\n",
    "            self.lags = [1, 2, 3, 6, 12, 24]\n",
    "\n",
    "class PrognosisSystem:\n",
    "    \"\"\"Sistema de prognosis industrial.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: Optional[PrognosisConfig] = None):\n",
    "        \"\"\"Inicializa el sistema de prognosis.\"\"\"\n",
    "        self.config = config or PrognosisConfig()\n",
    "        self._setup_logging()\n",
    "        self._initialize_storage()\n",
    "        \n",
    "    def _setup_logging(self):\n",
    "        \"\"\"Configura sistema de logging.\"\"\"\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        if not self.logger.handlers:\n",
    "            handler = logging.StreamHandler()\n",
    "            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "            handler.setFormatter(formatter)\n",
    "            self.logger.addHandler(handler)\n",
    "            self.logger.setLevel(logging.INFO)\n",
    "\n",
    "    def _initialize_storage(self):\n",
    "        \"\"\"Inicializa almacenamiento de modelos y métricas.\"\"\"\n",
    "        self.models = {}\n",
    "        self.anomaly_detectors = {}\n",
    "        self.scalers = {}\n",
    "        self.trend_detectors = {}\n",
    "        self.metrics = {}\n",
    "        self.limits = {}\n",
    "        self.baselines = {}\n",
    "        self.predictions_history = {}\n",
    "        self.alerts_history = []\n",
    "\n",
    "    def train_models(self, data: pd.DataFrame, variables: List[str]) -> Dict[str, Any]:\n",
    "        \"\"\"Entrena modelos para las variables seleccionadas.\"\"\"\n",
    "        try:\n",
    "            self.logger.info(f\"Iniciando entrenamiento para {len(variables)} variables\")\n",
    "            training_results = {}\n",
    "            \n",
    "            for variable in variables:\n",
    "                results = self._train_single_model(data, variable)\n",
    "                training_results[variable] = results\n",
    "                \n",
    "            self._validate_training(training_results)\n",
    "            self.logger.info(\"Entrenamiento completado exitosamente\")\n",
    "            return training_results\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en entrenamiento: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _train_single_model(self, data: pd.DataFrame, variable: str) -> Dict[str, Any]:\n",
    "        \"\"\"Entrena modelo para una variable específica.\"\"\"\n",
    "        try:\n",
    "            # Preparar datos\n",
    "            X, y = self._prepare_features(data, variable)\n",
    "            \n",
    "            # Entrenar detector de anomalías\n",
    "            anomaly_detector = self._train_anomaly_detector(X)\n",
    "            normal_mask = anomaly_detector.predict(X) == 1\n",
    "            X_clean = X[normal_mask]\n",
    "            y_clean = y[normal_mask]\n",
    "            \n",
    "            # Escalar features\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X_clean)\n",
    "            \n",
    "            # Entrenar modelo predictivo\n",
    "            model = self._train_predictor(X_scaled, y_clean)\n",
    "            \n",
    "            # Calcular línea base\n",
    "            baseline = self._calculate_baseline(data[variable])\n",
    "            \n",
    "            # Validar y guardar\n",
    "            metrics = self._validate_model(model, X_scaled, y_clean)\n",
    "            \n",
    "            # Almacenar componentes\n",
    "            self.models[variable] = model\n",
    "            self.anomaly_detectors[variable] = anomaly_detector\n",
    "            self.scalers[variable] = scaler\n",
    "            self.metrics[variable] = metrics\n",
    "            self.baselines[variable] = baseline\n",
    "            \n",
    "            return {\n",
    "                'metrics': metrics,\n",
    "                'baseline': baseline,\n",
    "                'n_samples': len(y_clean)\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error entrenando {variable}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _prepare_features(self, data: pd.DataFrame, variable: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Prepara features mejorados para el modelo.\"\"\"\n",
    "        features = []\n",
    "        \n",
    "        # 1. Features temporales mejorados\n",
    "        hour = np.array(data.index.hour)\n",
    "        dayofweek = np.array(data.index.dayofweek)\n",
    "        month = np.array(data.index.month)\n",
    "        is_weekend = np.array(dayofweek >= 5, dtype=int)\n",
    "        \n",
    "        features.extend([\n",
    "            hour.reshape(-1, 1),\n",
    "            dayofweek.reshape(-1, 1),\n",
    "            month.reshape(-1, 1),\n",
    "            is_weekend.reshape(-1, 1),\n",
    "            np.sin(2 * np.pi * hour/24).reshape(-1, 1),\n",
    "            np.cos(2 * np.pi * hour/24).reshape(-1, 1)\n",
    "        ])\n",
    "        \n",
    "        # 2. Lags con validación\n",
    "        for lag in self.config.lags:\n",
    "            lag_values = data[variable].shift(lag).to_numpy()\n",
    "            features.append(lag_values.reshape(-1, 1))\n",
    "        \n",
    "        # 3. Estadísticas móviles mejoradas\n",
    "        rolling = data[variable].rolling(self.config.window_size)\n",
    "        features.extend([\n",
    "            rolling.mean().to_numpy().reshape(-1, 1),\n",
    "            rolling.std().to_numpy().reshape(-1, 1),\n",
    "            rolling.min().to_numpy().reshape(-1, 1),\n",
    "            rolling.max().to_numpy().reshape(-1, 1),\n",
    "            rolling.skew().to_numpy().reshape(-1, 1),\n",
    "            rolling.kurt().to_numpy().reshape(-1, 1)\n",
    "        ])\n",
    "        \n",
    "        # 4. Features de tendencia\n",
    "        rolling_diffs = data[variable].diff().rolling(self.config.window_size)\n",
    "        features.extend([\n",
    "            rolling_diffs.mean().to_numpy().reshape(-1, 1),\n",
    "            rolling_diffs.std().to_numpy().reshape(-1, 1)\n",
    "        ])\n",
    "        \n",
    "        # Combinar y limpiar\n",
    "        X = np.hstack(features)\n",
    "        y = data[variable].to_numpy()\n",
    "        \n",
    "        # Manejo mejorado de valores faltantes\n",
    "        mask = ~np.isnan(X).any(axis=1) & ~np.isnan(y)\n",
    "        X_clean = X[mask]\n",
    "        y_clean = y[mask]\n",
    "        \n",
    "        # Validación adicional\n",
    "        if len(X_clean) < self.config.window_size:\n",
    "            raise ValueError(f\"Insuficientes datos para variable {variable}\")\n",
    "            \n",
    "        return X_clean, y_clean\n",
    "\n",
    "    def _train_anomaly_detector(self, X: np.ndarray) -> IsolationForest:\n",
    "        \"\"\"Entrena detector de anomalías.\"\"\"\n",
    "        try:\n",
    "            detector = IsolationForest(\n",
    "                contamination=self.config.anomaly_contamination,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            detector.fit(X)\n",
    "            return detector\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en detector de anomalías: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _train_predictor(self, X: np.ndarray, y: np.ndarray) -> GradientBoostingRegressor:\n",
    "        \"\"\"Entrena modelo predictivo con configuración optimizada.\"\"\"\n",
    "        model = GradientBoostingRegressor(\n",
    "            n_estimators=200,          # Aumentado de 100\n",
    "            learning_rate=0.05,        # Reducido de 0.1\n",
    "            max_depth=4,              # Aumentado de 3\n",
    "            min_samples_split=5,      # Nuevo parámetro\n",
    "            min_samples_leaf=3,       # Nuevo parámetro\n",
    "            subsample=0.8,            # Nuevo parámetro\n",
    "            random_state=42,\n",
    "            validation_fraction=0.1    # Nuevo parámetro\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            model.fit(X, y)\n",
    "            return model\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en entrenamiento del predictor: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _calculate_baseline(self, series: pd.Series) -> Dict[str, float]:\n",
    "        \"\"\"Calcula línea base y límites.\"\"\"\n",
    "        stats_dict = {\n",
    "            'mean': float(series.mean()),\n",
    "            'std': float(series.std()),\n",
    "            'q25': float(series.quantile(0.25)),\n",
    "            'q75': float(series.quantile(0.75))\n",
    "        }\n",
    "        \n",
    "        stats_dict.update({\n",
    "            'lower_limit': stats_dict['q25'] - 1.5 * (stats_dict['q75'] - stats_dict['q25']),\n",
    "            'upper_limit': stats_dict['q75'] + 1.5 * (stats_dict['q75'] - stats_dict['q25'])\n",
    "        })\n",
    "        \n",
    "        return stats_dict\n",
    "\n",
    "    def _validate_model(self, model: GradientBoostingRegressor, X: np.ndarray, y: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"Valida modelo con cross-validation temporal.\"\"\"\n",
    "        cv = TimeSeriesSplit(n_splits=self.config.n_splits)\n",
    "        metrics = {\n",
    "            'mse': [],\n",
    "            'mae': [],\n",
    "            'precision': [],\n",
    "            'recall': []\n",
    "        }\n",
    "        \n",
    "        for train_idx, val_idx in cv.split(X):\n",
    "            X_train, X_val = X[train_idx], X[val_idx]\n",
    "            y_train, y_val = y[train_idx], y[val_idx]\n",
    "            \n",
    "            model.fit(X_train, y_train)\n",
    "            pred = model.predict(X_val)\n",
    "            \n",
    "            metrics['mse'].append(mean_squared_error(y_val, pred))\n",
    "            metrics['mae'].append(mean_absolute_error(y_val, pred))\n",
    "            \n",
    "            # Métricas de clasificación\n",
    "            thresh = np.percentile(y_train, 95)\n",
    "            y_binary = (y_val > thresh).astype(int)\n",
    "            pred_binary = (pred > thresh).astype(int)\n",
    "            \n",
    "            metrics['precision'].append(precision_score(y_binary, pred_binary))\n",
    "            metrics['recall'].append(recall_score(y_binary, pred_binary))\n",
    "        \n",
    "        return {k: float(np.mean(v)) for k, v in metrics.items()}\n",
    "    \n",
    "    def _validate_training(self, results: Dict[str, Dict[str, Any]]) -> None:\n",
    "        \"\"\"\n",
    "        Valida resultados del entrenamiento.\n",
    "        \n",
    "        Args:\n",
    "            results: Resultados por variable\n",
    "        \"\"\"\n",
    "        try:\n",
    "            for var, res in results.items():\n",
    "                metrics = res['metrics']\n",
    "                \n",
    "                # Verificar precisión\n",
    "                if metrics['precision'] < self.config.target_precision:\n",
    "                    self.logger.warning(\n",
    "                        f\"Precisión baja para {var}: {metrics['precision']:.3f} \"\n",
    "                        f\"(objetivo: {self.config.target_precision})\"\n",
    "                    )\n",
    "                \n",
    "                # Verificar recall\n",
    "                if metrics['recall'] < self.config.target_recall:\n",
    "                    self.logger.warning(\n",
    "                        f\"Recall bajo para {var}: {metrics['recall']:.3f} \"\n",
    "                        f\"(objetivo: {self.config.target_recall})\"\n",
    "                    )\n",
    "                \n",
    "                # Verificar MSE\n",
    "                if metrics['mse'] > np.mean([r['metrics']['mse'] for r in results.values()]) * 2:\n",
    "                    self.logger.warning(\n",
    "                        f\"MSE alto para {var}: {metrics['mse']:.4f}\"\n",
    "                    )\n",
    "                    \n",
    "                self.logger.info(f\"Validación completada para {var}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en validación de entrenamiento: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def predict(self, data: pd.DataFrame) -> Dict[str, Any]:\n",
    "        \"\"\"Realiza predicciones para todas las variables.\"\"\"\n",
    "        results = {\n",
    "            'predictions': {},\n",
    "            'alerts': [],\n",
    "            'timestamp': data.index[-1]\n",
    "        }\n",
    "        \n",
    "        for variable in self.models:\n",
    "            prediction = self._predict_variable(data, variable)\n",
    "            results['predictions'][variable] = prediction\n",
    "            \n",
    "            if self._should_generate_alert(prediction):\n",
    "                alert = self._generate_alert(variable, prediction)\n",
    "                results['alerts'].append(alert)\n",
    "        \n",
    "        self._update_history(results)\n",
    "        return results\n",
    "\n",
    "    def _predict_variable(self, data: pd.DataFrame, variable: str) -> Dict[str, Any]:\n",
    "        \"\"\"Realiza predicción para una variable.\"\"\"\n",
    "        try:\n",
    "            X, _ = self._prepare_features(data, variable)\n",
    "            X_scaled = self.scalers[variable].transform(X[-1:])\n",
    "            \n",
    "            value = float(self.models[variable].predict(X_scaled)[0])\n",
    "            intervals = self._get_prediction_intervals(self.models[variable], X_scaled)\n",
    "            anomaly_score = float(self.anomaly_detectors[variable].score_samples(X[-1:])[0])\n",
    "            \n",
    "            return {\n",
    "                'value': value,\n",
    "                'intervals': intervals,\n",
    "                'anomaly_score': anomaly_score,\n",
    "                'timestamp': data.index[-1]\n",
    "            }\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en predicción: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _get_prediction_intervals(self, model: GradientBoostingRegressor, X: np.ndarray) -> Dict[str, float]:\n",
    "        \"\"\"Calcula intervalos de predicción.\"\"\"\n",
    "        try:\n",
    "            pred = model.predict(X)\n",
    "            predictions = []\n",
    "            \n",
    "            for estimator in model.estimators_:\n",
    "                predictions.append(estimator[0].predict(X))\n",
    "            \n",
    "            predictions = np.array(predictions).flatten()\n",
    "            \n",
    "            lower = float(np.percentile(predictions, (1 - self.config.confidence_level) * 50))\n",
    "            upper = float(np.percentile(predictions, (1 + self.config.confidence_level) * 50))\n",
    "            \n",
    "            return {'lower': lower, 'upper': upper}\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error en cálculo de intervalos: {str(e)}\")\n",
    "            return {\n",
    "                'lower': float(pred[0] * 0.9),\n",
    "                'upper': float(pred[0] * 1.1)\n",
    "            }\n",
    "\n",
    "    def _should_generate_alert(self, prediction: Dict[str, Any]) -> bool:\n",
    "        \"\"\"Determina si se debe generar una alerta con criterios mejorados.\"\"\"\n",
    "        # 1. Score de anomalía más estricto\n",
    "        anomaly_alert = prediction['anomaly_score'] < -self.config.alert_threshold\n",
    "\n",
    "        # 2. Desviación del intervalo de predicción\n",
    "        value = prediction['value']\n",
    "        lower = prediction['intervals']['lower']\n",
    "        upper = prediction['intervals']['upper']\n",
    "        interval_deviation = (\n",
    "            value < lower - abs(lower * 0.1) or  # 10% de margen\n",
    "            value > upper + abs(upper * 0.1)\n",
    "        )\n",
    "\n",
    "        # 3. Cambio brusco respecto a histórico\n",
    "        if prediction['variable'] in self.predictions_history:\n",
    "            history = self.predictions_history[prediction['variable']]\n",
    "            if history:\n",
    "                last_value = history[-1]['value']\n",
    "                change_ratio = abs((value - last_value) / last_value)\n",
    "                sudden_change = change_ratio > 0.3  # 30% de cambio\n",
    "            else:\n",
    "                sudden_change = False\n",
    "        else:\n",
    "            sudden_change = False\n",
    "\n",
    "        return anomaly_alert or (interval_deviation and sudden_change)\n",
    "\n",
    "    def _generate_alert(self, variable: str, prediction: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Genera alerta basada en predicción.\"\"\"\n",
    "        severity = max(\n",
    "            -prediction['anomaly_score'],\n",
    "            abs(prediction['value'] - prediction['intervals']['upper']) / prediction['value'],\n",
    "            abs(prediction['value'] - prediction['intervals']['lower']) / prediction['value']\n",
    "        )\n",
    "            \n",
    "        return {\n",
    "            'timestamp': prediction['timestamp'],\n",
    "            'variable': variable,\n",
    "            'severity': float(severity),\n",
    "            'message': f\"Anomalía detectada en {variable}\",\n",
    "            'details': prediction\n",
    "        }\n",
    "\n",
    "    def _update_history(self, results: Dict[str, Any]) -> None:\n",
    "        \"\"\"Actualiza histórico de predicciones y alertas.\"\"\"\n",
    "        timestamp = results['timestamp']\n",
    "        \n",
    "        for var, pred in results['predictions'].items():\n",
    "            if var not in self.predictions_history:\n",
    "                self.predictions_history[var] = []\n",
    "            self.predictions_history[var].append({\n",
    "                'timestamp': timestamp,\n",
    "                'value': pred['value'],\n",
    "                'anomaly_score': pred['anomaly_score']\n",
    "            })\n",
    "        \n",
    "        self.alerts_history.extend(results['alerts'])\n",
    "        \n",
    "        # Mantener solo último día\n",
    "        cutoff = timestamp - pd.Timedelta(days=1)\n",
    "        for var in self.predictions_history:\n",
    "            self.predictions_history[var] = [\n",
    "                p for p in self.predictions_history[var]\n",
    "                if p['timestamp'] > cutoff\n",
    "            ]\n",
    "        self.alerts_history = [\n",
    "            a for a in self.alerts_history\n",
    "            if a['timestamp'] > cutoff\n",
    "        ]\n",
    "\n",
    "def test_prognosis_system(data: pd.DataFrame, variables: List[str]):\n",
    "    \"\"\"Prueba el sistema de prognosis.\"\"\"\n",
    "    print(\"\\n=== PRUEBA DE SISTEMA DE PROGNOSIS ===\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Inicializar y entrenar\n",
    "        system = PrognosisSystem()\n",
    "        training_results = system.train_models(data, variables)\n",
    "        \n",
    "        # Mostrar resultados de entrenamiento\n",
    "        print(\"\\nResultados de Entrenamiento:\")\n",
    "        for var, res in training_results.items():\n",
    "            metrics = res['metrics']\n",
    "            print(f\"\\n{var}:\")\n",
    "            print(f\"  Precisión: {metrics['precision']:.3f}\")\n",
    "            print(f\"  Recall: {metrics['recall']:.3f}\")\n",
    "            print(f\"  MSE: {metrics['mse']:.4f}\")\n",
    "        \n",
    "        # Realizar predicciones\n",
    "        recent_data = data.iloc[-100:]\n",
    "        results = system.predict(recent_data)\n",
    "        \n",
    "        # Mostrar predicciones\n",
    "        print(\"\\nPredicciones:\")\n",
    "        for var, pred in results['predictions'].items():\n",
    "            print(f\"\\n{var}:\")\n",
    "            print(f\"  Valor: {pred['value']:.3f}\")\n",
    "            print(f\"  Intervalo: [{pred['intervals']['lower']:.3f}, {pred['intervals']['upper']:.3f}]\")\n",
    "            print(f\"  Score Anomalía: {pred['anomaly_score']:.3f}\")\n",
    "        \n",
    "        if results['alerts']:\n",
    "            print(\"\\nAlertas:\")\n",
    "            for alert in results['alerts']:\n",
    "                print(f\"- {alert['message']} (Severidad: {alert['severity']:.2f})\")\n",
    "        \n",
    "        return system\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error en pruebas: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Ejecución condicional\n",
    "if 'processed_data' in globals() and 'variable_analyzer' in globals():\n",
    "    if processed_data is not None and variable_analyzer is not None:\n",
    "        prognosis_system = test_prognosis_system(\n",
    "            processed_data,\n",
    "            list(variable_analyzer.results['selected_variables'].keys())\n",
    "        )\n",
    "    else:\n",
    "        print(\"Error: Ejecutar primero fases anteriores\")\n",
    "else:\n",
    "    print(\"Error: Ejecutar primero fases anteriores\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
